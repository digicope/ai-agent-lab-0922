{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d18b9062-cba2-4a26-828c-73320928d46a",
   "metadata": {},
   "source": [
    "## ÏßàÎ¨∏ Ïú†ÌòïÎ≥Ñ ÎèÑÍµ¨ ÏûêÎèô ÏÑ†ÌÉù Î°úÏßÅ Íµ¨ÌòÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2340f2bb-c902-4b24-9e4a-8ff929201bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env ÌååÏùºÏùò ÎÇ¥Ïö© Î∂àÎü¨Ïò§Í∏∞\n",
    "load_dotenv(\"C:/env/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f93829-9e0c-4bf9-ae61-c127d98455bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 12*(3+4)/7\n",
      "‚Äî intent: math | reason: ÏÇ¨ÏπôÏó∞ÏÇ∞/ÏàòÏπò Í≥ÑÏÇ∞Ïù¥ Ìè¨Ìï®Îêú ÏßàÎ¨∏ÏûÖÎãàÎã§.\n",
      "Í≥ÑÏÇ∞ Í≤∞Í≥ºÎäî 12.0Ïù¥Îã§.\n",
      "------------------------------------------------------------\n",
      "Q: LangChain Î≤ÑÏ†Ñ ÌôïÏù∏ Î∞©Î≤ï ÏïåÎ†§Ï§ò\n",
      "‚Äî intent: faq | reason: ÏÑ§Ï†ï/Î≤ÑÏ†Ñ/Í∞úÎÖê/Í∞ÄÏù¥ÎìúÏóê ÎåÄÌïú ÏßàÎ¨∏Ïù¥ÎØÄÎ°ú FAQÎ°ú Î∂ÑÎ•òÎê®.\n",
      "LangChain Î≤ÑÏ†ÑÏùÑ ÌôïÏù∏ÌïòÎäî Î∞©Î≤ïÏùÄ Îã§ÏùåÍ≥º Í∞ôÎã§.\n",
      "\n",
      "1. Python ÌôòÍ≤ΩÏóêÏÑú Îã§Ïùå ÏΩîÎìúÎ•º Ïã§ÌñâÌïúÎã§:\n",
      "   ```python\n",
      "   import langchain\n",
      "   print(langchain.__version__)\n",
      "   ```\n",
      "\n",
      "Ïù¥ ÏΩîÎìúÎ•º ÌÜµÌï¥ ÌòÑÏû¨ ÏÑ§ÏπòÎêú LangChainÏùò Î≤ÑÏ†ÑÏùÑ ÌôïÏù∏Ìï† Ïàò ÏûàÎã§.\n",
      "------------------------------------------------------------\n",
      "Q: LangGraphÍ∞Ä Î¨¥ÏóáÏù∏ÏßÄ Ìïú Ï§ÑÎ°ú ÏÑ§Î™ÖÌï¥Ï§ò\n",
      "‚Äî intent: faq | reason: ÏÑ§Ï†ï/Î≤ÑÏ†Ñ/Í∞úÎÖê/Í∞ÄÏù¥ÎìúÏóê ÎåÄÌïú ÏßàÎ¨∏Ïù¥ÎØÄÎ°ú FAQÎ°ú Î∂ÑÎ•òÎê®.\n",
      "LangGraphÎäî Ïñ∏Ïñ¥ Î™®Îç∏ÏùÑ Í∏∞Î∞òÏúºÎ°ú Ìïú Í∑∏ÎûòÌîÑ Íµ¨Ï°∞Î•º ÌôúÏö©ÌïòÏó¨ ÏûêÏó∞Ïñ¥ Ï≤òÎ¶¨ ÏûëÏóÖÏùÑ ÏßÄÏõêÌïòÎäî ÎèÑÍµ¨Ïù¥Îã§.\n",
      "------------------------------------------------------------\n",
      "Q: RAG ÌååÏù¥ÌîÑÎùºÏù∏ Îã®Í≥Ñ ÏïåÎ†§Ï§ò\n",
      "‚Äî intent: faq | reason: RAG ÌååÏù¥ÌîÑÎùºÏù∏Ïùò Îã®Í≥ÑÏóê ÎåÄÌïú ÏÑ§Ï†ï Î∞è Í∞úÎÖêÏùÑ Î¨ªÎäî ÏßàÎ¨∏Ïù¥ÎØÄÎ°ú FAQÎ°ú Î∂ÑÎ•òÎê®.\n",
      "RAG ÌååÏù¥ÌîÑÎùºÏù∏Ïùò Îã®Í≥ÑÎäî Îã§ÏùåÍ≥º Í∞ôÎã§.\n",
      "\n",
      "1. **ÏßàÎ¨∏ ÏûÖÎ†•**: ÏÇ¨Ïö©ÏûêÍ∞Ä ÏßàÎ¨∏ÏùÑ ÏûÖÎ†•ÌïúÎã§.\n",
      "2. **Î¨∏ÏÑú Í≤ÄÏÉâ**: Í¥ÄÎ†® Î¨∏ÏÑúÎ•º Í≤ÄÏÉâÌïòÏó¨ ÌõÑÎ≥¥ Î™©Î°ùÏùÑ ÏÉùÏÑ±ÌïúÎã§.\n",
      "3. **Î¨∏ÏÑú ÏÑ†ÌÉù**: Í≤ÄÏÉâÎêú Î¨∏ÏÑú Ï§ëÏóêÏÑú Í∞ÄÏû• Í¥ÄÎ†®ÏÑ±Ïù¥ ÎÜíÏùÄ Î¨∏ÏÑúÎ•º ÏÑ†ÌÉùÌïúÎã§.\n",
      "4. **ÎãµÎ≥Ä ÏÉùÏÑ±**: ÏÑ†ÌÉùÎêú Î¨∏ÏÑúÎ•º Î∞îÌÉïÏúºÎ°ú ÎãµÎ≥ÄÏùÑ ÏÉùÏÑ±ÌïúÎã§.\n",
      "5. **Ï∂úÎ†•**: ÏµúÏ¢Ö ÎãµÎ≥ÄÏùÑ ÏÇ¨Ïö©ÏûêÏóêÍ≤å Ï†úÍ≥µÌïúÎã§.\n",
      "------------------------------------------------------------\n",
      "Q: ÌïòÎäòÏùÄ Ïôú ÌååÎûÄÍ∞ÄÏöî?\n",
      "‚Äî intent: faq | reason: ÌïòÎäòÏù¥ ÌååÎûÄ Ïù¥Ïú†Ïóê ÎåÄÌïú ÏÑ§Î™ÖÏùÑ ÏöîÍµ¨ÌïòÎäî ÏßàÎ¨∏ÏúºÎ°ú, Í≥ºÌïôÏ†Å Í∞úÎÖêÏóê ÎåÄÌïú Ï†ïÎ≥¥ ÏöîÏ≤≠.\n",
      "ÌïòÎäòÏù¥ ÌååÎûÄ Ïù¥Ïú†Îäî ÎåÄÍ∏∞ Ï§ëÏùò ÏÇ∞ÏÜåÏôÄ ÏßàÏÜå Î∂ÑÏûêÍ∞Ä ÌÉúÏñëÎπõÏùÑ ÏÇ∞ÎûÄÏãúÌÇ§Í∏∞ ÎïåÎ¨∏Ïù¥Îã§. ÌÉúÏñëÎπõÏùÄ Ïó¨Îü¨ ÏÉâÏùò ÎπõÏúºÎ°ú Íµ¨ÏÑ±ÎêòÏñ¥ ÏûàÏúºÎ©∞, ÌååÎûÄÏÉâ ÎπõÏù¥ Îã§Î•∏ ÏÉâÎ≥¥Îã§ Îçî ÎßéÏù¥ ÏÇ∞ÎûÄÎêúÎã§. Ïù¥Î°ú Ïù∏Ìï¥ ÌïòÎäòÏù¥ ÌååÎûÄÏÉâÏúºÎ°ú Î≥¥Ïù∏Îã§.\n",
      "------------------------------------------------------------\n",
      "Q: LangChainÏóêÏÑú RAG Íµ¨Ï∂ï ÌïµÏã¨ ÏöîÏïΩ\n",
      "‚Äî intent: faq | reason: ÏÑ§Ï†ï/Î≤ÑÏ†Ñ/Í∞úÎÖê/Í∞ÄÏù¥ÎìúÏóê ÎåÄÌïú ÏßàÎ¨∏Ïù¥ÎØÄÎ°ú FAQÎ°ú Î∂ÑÎ•òÎê®.\n",
      "LangChainÏóêÏÑú RAG(Ï†ïÎ≥¥ Í≤ÄÏÉâ Í∏∞Î∞ò ÏÉùÏÑ±) Íµ¨Ï∂ïÏùò ÌïµÏã¨ ÏöîÏïΩÏùÄ Îã§ÏùåÍ≥º Í∞ôÎã§.\n",
      "\n",
      "1. **Í∞úÎÖê Ïù¥Ìï¥**: RAGÎäî Ï†ïÎ≥¥ Í≤ÄÏÉâÍ≥º ÏÉùÏÑ± Î™®Îç∏ÏùÑ Í≤∞Ìï©ÌïòÏó¨ ÏßàÎ¨∏Ïóê ÎåÄÌïú ÎãµÎ≥ÄÏùÑ ÏÉùÏÑ±ÌïòÎäî Î∞©ÏãùÏù¥Îã§.\n",
      "2. **ÏÑ§Ï†ï**: LangChain ÎùºÏù¥Î∏åÎü¨Î¶¨Î•º ÏÑ§ÏπòÌïòÍ≥† ÌïÑÏöîÌïú Î™®ÎìàÏùÑ ÏûÑÌè¨Ìä∏ÌïúÎã§.\n",
      "3. **Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§ Ï§ÄÎπÑ**: Í≤ÄÏÉâÌï† Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§Î•º ÏÑ§Ï†ïÌïúÎã§. ÏòàÎ•º Îì§Ïñ¥, Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÎÇò APIÎ•º ÏÇ¨Ïö©Ìï† Ïàò ÏûàÎã§.\n",
      "4. **Î™®Îç∏ ÏÑ†ÌÉù**: ÏÇ¨Ïö©Ìï† ÏÉùÏÑ± Î™®Îç∏ÏùÑ ÏÑ†ÌÉùÌïòÍ≥† ÏÑ§Ï†ïÌïúÎã§.\n",
      "5. **ÌååÏù¥ÌîÑÎùºÏù∏ Íµ¨Ï∂ï**: Ï†ïÎ≥¥ Í≤ÄÏÉâÍ≥º ÏÉùÏÑ± Î™®Îç∏ÏùÑ Ïó∞Í≤∞ÌïòÎäî ÌååÏù¥ÌîÑÎùºÏù∏ÏùÑ Íµ¨Ï∂ïÌïúÎã§.\n",
      "6. **ÌÖåÏä§Ìä∏ Î∞è Ï°∞Ï†ï**: Íµ¨Ï∂ïÌïú RAG ÏãúÏä§ÌÖúÏùÑ ÌÖåÏä§Ìä∏ÌïòÍ≥† ÌïÑÏöîÏóê Îî∞Îùº Ï°∞Ï†ïÌïúÎã§.\n",
      "\n",
      "Ïù¥ Îã®Í≥ÑÎ•º Îî∞Îùº LangChainÏóêÏÑú RAGÎ•º Íµ¨Ï∂ïÌï† Ïàò ÏûàÎã§.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Filename: routed_tool_agent.py\n",
    "# LangChain 1.0 Í∏∞Ï§Ä ÏòàÏ†ú (2025-10)\n",
    "# Ïã§Ìñâ Ï†Ñ:  pip install langchain langchain-core langchain-openai langgraph pydantic\n",
    "# ÌôòÍ≤ΩÎ≥ÄÏàò:  export OPENAI_API_KEY=...  (Windows: set OPENAI_API_KEY=...)\n",
    "\n",
    "from __future__ import annotations\n",
    "from typing import Literal, TypedDict, List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "import operator\n",
    "import ast\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "########################################\n",
    "# 0) LLM ÏÑ§Ï†ï\n",
    "########################################\n",
    "# ÌïÑÏöî Ïãú Î™®Îç∏ Î≥ÄÍ≤Ω Í∞ÄÎä•: \"gpt-4o-mini\", \"gpt-4o\", \"gpt-4.1-mini\" Îì±\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "########################################\n",
    "# 1) ÎèÑÍµ¨ Ï†ïÏùò\n",
    "########################################\n",
    "\n",
    "# 1-1) ÏïàÏ†ÑÌïú ÏÇ¨ÏπôÏó∞ÏÇ∞ Í≥ÑÏÇ∞Í∏∞\n",
    "#      astÎ•º Ïù¥Ïö©Ìï¥ + - * / ( ) Î∞è Ï†ïÏàò/Ïã§ÏàòÎßå ÌóàÏö©ÌïúÎã§.\n",
    "# allowed_nodes = {\n",
    "#     ast.Expression, ast.BinOp, ast.UnaryOp, ast.Num, ast.Constant, ast.Load,\n",
    "#     ast.Add, ast.Sub, ast.Mult, ast.Div, ast.Pow, ast.USub, ast.UAdd, ast.Mod,\n",
    "#     ast.FloorDiv, ast.LParen if hasattr(ast, \"LParen\") else ast.AST,  # Ìò∏ÌôòÏÑ±\n",
    "# }\n",
    "\n",
    "allowed_nodes = {\n",
    "    ast.Expression, ast.BinOp, ast.UnaryOp, ast.Constant, ast.Load,\n",
    "    ast.Add, ast.Sub, ast.Mult, ast.Div, ast.Pow, ast.USub, ast.UAdd, ast.Mod,\n",
    "    ast.FloorDiv,\n",
    "}\n",
    "\n",
    "def _safe_eval(expr: str) -> float:\n",
    "    def _check(node):\n",
    "        if type(node) not in allowed_nodes:\n",
    "            raise ValueError(f\"ÌóàÏö©ÎêòÏßÄ ÏïäÎäî ÌëúÌòÑ: {type(node).__name__}\")\n",
    "        for child in ast.iter_child_nodes(node):\n",
    "            _check(child)\n",
    "\n",
    "    node = ast.parse(expr, mode=\"eval\")\n",
    "    _check(node)\n",
    "    return eval(compile(node, \"<expr>\", \"eval\"), {\"__builtins__\": {}})\n",
    "\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Í∞ÑÎã®Ìïú ÏàòÌïô Í≥ÑÏÇ∞ÏùÑ ÏàòÌñâÌïúÎã§. Ïòà: '12 * (3 + 4) / 7'\"\"\"\n",
    "    try:\n",
    "        value = _safe_eval(expression)\n",
    "        return f\"Í≥ÑÏÇ∞ Í≤∞Í≥º: {value}\"\n",
    "    except Exception as e:\n",
    "        return f\"Í≥ÑÏÇ∞ Ïã§Ìå®: {e}\"\n",
    "\n",
    "# 1-2) Î°úÏª¨ FAQ Í≤ÄÏÉâ ÎèÑÍµ¨ (ÏÉòÌîåÏö© Í∞ÑÎã® ÌÇ§ÏõåÎìú Îß§Ïπ≠)\n",
    "_FAQ = [\n",
    "    (\"OpenAI API ÌÇ§ ÏÑ§Ï†ï\", \"ÌôòÍ≤ΩÎ≥ÄÏàò OPENAI_API_KEYÎ•º ÏÑ§Ï†ïÌïúÎã§.\"),\n",
    "    (\"LangChain Î≤ÑÏ†Ñ ÌôïÏù∏\", \"import langchain; print(langchain.__version__)ÏùÑ ÏÇ¨Ïö©ÌïúÎã§.\"),\n",
    "    (\"RAG Í∞úÎÖê\", \"ÎÇ¥ Î¨∏ÏÑúÎ•º Î≤°ÌÑ∞ÌôîÌï¥ Í≤ÄÏÉâÌïòÍ≥† LLMÏù¥ ÏùëÎãµÏùÑ ÏÉùÏÑ±ÌïòÎäî Î∞©ÏãùÏù¥Îã§.\"),\n",
    "    (\"LangGraph\", \"ÏÉÅÌÉú Í∏∞Î∞ò Í∑∏ÎûòÌîÑ Ïã§ÌñâÏúºÎ°ú ÎÖ∏Îìú/Ïó£ÏßÄÎ°ú ÏõåÌÅ¨ÌîåÎ°úÏö∞Î•º Ï†ïÏùòÌïúÎã§.\"),\n",
    "]\n",
    "\n",
    "@tool\n",
    "def local_faq_search(query: str) -> str:\n",
    "    \"\"\"ÏÉòÌîå FAQÏóêÏÑú ÏßàÏùòÏñ¥Í∞Ä Ìè¨Ìï®Îêú Ìï≠Î™©ÏùÑ Ï∞æÏïÑ ÏöîÏïΩÌïúÎã§.\"\"\"\n",
    "    q = query.lower()\n",
    "    hits = [f\"- {k}: {v}\" for k, v in _FAQ if q in k.lower() or q in v.lower()]\n",
    "    if not hits:\n",
    "        return \"Í¥ÄÎ†® FAQÍ∞Ä ÏóÜÎã§.\"\n",
    "    return \"FAQ Í≤ÄÏÉâ Í≤∞Í≥º:\\n\" + \"\\n\".join(hits)\n",
    "\n",
    "# 1-3) Î°úÏª¨ ÌÇ§ÏõåÎìú Í≤ÄÏÉâ ÎèÑÍµ¨ (ÏÉòÌîå ÏΩîÌçºÏä§)\n",
    "_DOCS = [\n",
    "    \"LangChain 1.0ÏóêÏÑúÎäî import Í≤ΩÎ°úÍ∞Ä ÌÅ¨Í≤å Î≥ÄÍ≤ΩÎêòÏóàÎã§.\",\n",
    "    \"LangGraphÎäî Î∂ÑÍ∏∞/Î£®ÌîÑ/Ï§ëÎã®ÏùÑ Îã§Î£®Îäî ÏóêÏù¥Ï†ÑÌä∏ ÏõåÌÅ¨ÌîåÎ°úÏö∞Ïóê Ï†ÅÌï©ÌïòÎã§.\",\n",
    "    \"OpenAIÏùò Ìï®Ïàò Ìò∏Ï∂úÏùÑ ÌÜµÌï¥ ÎèÑÍµ¨Î•º ÏûêÎèô ÏÑ†ÌÉùÌïòÎèÑÎ°ù ÎßåÎì§ Ïàò ÏûàÎã§.\",\n",
    "    \"RAG ÌååÏù¥ÌîÑÎùºÏù∏ÏùÄ Î°úÎçî‚ÜíÏ≤≠ÌÅ¨‚ÜíÏûÑÎ≤†Îî©‚ÜíÎ≤°ÌÑ∞DB‚Üíretriever‚ÜíLLM ÏàúÏÑúÎ°ú Íµ¨ÏÑ±ÌïúÎã§.\",\n",
    "]\n",
    "\n",
    "@tool\n",
    "def local_keyword_search(query: str) -> str:\n",
    "    \"\"\"Í∞ÑÎã®Ìïú Î°úÏª¨ Î¨∏ÏÑú ÌÇ§ÏõåÎìú Í≤ÄÏÉâÏùÑ ÏàòÌñâÌïúÎã§.\"\"\"\n",
    "    q = query.lower()\n",
    "    hits = [f\"- {t}\" for t in _DOCS if q in t.lower()]\n",
    "    if not hits:\n",
    "        return \"Í≤ÄÏÉâ Í≤∞Í≥ºÍ∞Ä ÏóÜÎã§.\"\n",
    "    return \"Î°úÏª¨ Í≤ÄÏÉâ Í≤∞Í≥º:\\n\" + \"\\n\".join(hits)\n",
    "\n",
    "# ÌïÑÏöîÌïú Í≤ΩÏö∞ Ïô∏Î∂Ä ÏõπÍ≤ÄÏÉâ ÎèÑÍµ¨Î•º ÍµêÏ≤¥/Ï∂îÍ∞ÄÌï† Ïàò ÏûàÎã§.\n",
    "# Ïòà: tavily / ddg / requests Í∏∞Î∞ò Ïª§Ïä§ÌÖÄ Í≤ÄÏÉâ Îì±\n",
    "\n",
    "TOOLS = [calculator, local_faq_search, local_keyword_search]\n",
    "\n",
    "########################################\n",
    "# 2) ÏßàÎ¨∏ Î∂ÑÎ•ò Î™®Îç∏ (Íµ¨Ï°∞Ìôî Ï∂úÎ†•)\n",
    "########################################\n",
    "\n",
    "class IntentSchema(BaseModel):\n",
    "    intent: Literal[\n",
    "        \"math\",        # ÏàòÌïô/Í≥ÑÏÇ∞\n",
    "        \"faq\",         # FAQ/ÏÑ§Ï†ï/Í∞úÎÖê ÏßàÏùò\n",
    "        \"search\",      # ÏùºÎ∞ò Ï†ïÎ≥¥ Í≤ÄÏÉâ\n",
    "        \"chitchat\",    # Ïû°Îã¥/ÏùºÎ∞ò ÏÑ§Î™Ö\n",
    "    ] = Field(description=\"ÏÇ¨Ïö©Ïûê ÏßàÎ¨∏Ïùò Ïú†Ìòï\")\n",
    "    reason: str = Field(description=\"Ïù¥ Î∂ÑÎ•òÏóê ÎèÑÎã¨Ìïú Í∑ºÍ±∞ Ìïú Ï§Ñ\")\n",
    "\n",
    "# LLMÏóêÍ≤å Íµ¨Ï°∞Ìôî Ï∂úÎ†• Í∞ïÏ†ú\n",
    "classifier = llm.with_structured_output(IntentSchema)\n",
    "\n",
    "########################################\n",
    "# 3) Í∑∏ÎûòÌîÑ ÏÉÅÌÉú Î∞è ÎÖ∏Îìú Ìï®Ïàò\n",
    "########################################\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    intent: Optional[str]\n",
    "    reason: Optional[str]\n",
    "    tool_result: Optional[str]\n",
    "    final_answer: Optional[str]\n",
    "\n",
    "def classify_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"ÏßàÎ¨∏ÏùÑ IntentÎ°ú Î∂ÑÎ•òÌïúÎã§.\"\"\"\n",
    "    res = classifier.invoke(\n",
    "        f\"ÏßàÎ¨∏ Ïú†ÌòïÏùÑ Î∂ÑÎ•òÌïòÎùº.\\nÏßàÎ¨∏: {state['question']}\\n\"\n",
    "        \"Í∞ÄÎä•Ìïú ÏùòÎèÑ: math, faq, search, chitchat\\n\"\n",
    "        \"Í∑úÏπô:\\n\"\n",
    "        \"- ÏÇ¨ÏπôÏó∞ÏÇ∞/ÏàòÏπò Í≥ÑÏÇ∞Ïù¥Î©¥ math\\n\"\n",
    "        \"- ÏÑ§Ï†ï/Î≤ÑÏ†Ñ/Í∞úÎÖê/Í∞ÄÏù¥ÎìúÎ©¥ faq\\n\"\n",
    "        \"- Î∞∞Í≤ΩÏßÄÏãù/ÏùºÎ∞òÏ†ïÎ≥¥ Ï∞æÍ∏∞Îäî search\\n\"\n",
    "        \"- Í∑∏ Ïô∏Îäî chitchat\"\n",
    "    )\n",
    "    state[\"intent\"] = res.intent\n",
    "    state[\"reason\"] = res.reason\n",
    "    return state\n",
    "\n",
    "def math_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Í≥ÑÏÇ∞Í∏∞ ÎèÑÍµ¨ Ï≤¥Ïù∏ Ïã§Ìñâ.\"\"\"\n",
    "    expr = state[\"question\"]\n",
    "    result = calculator.invoke({\"expression\": expr})\n",
    "    state[\"tool_result\"] = result\n",
    "    return state\n",
    "\n",
    "def faq_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"FAQ ÎèÑÍµ¨ Ï≤¥Ïù∏ Ïã§Ìñâ.\"\"\"\n",
    "    result = local_faq_search.invoke({\"query\": state[\"question\"]})\n",
    "    state[\"tool_result\"] = result\n",
    "    return state\n",
    "\n",
    "def search_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Î°úÏª¨ ÌÇ§ÏõåÎìú Í≤ÄÏÉâ ÎèÑÍµ¨ Ï≤¥Ïù∏ Ïã§Ìñâ.\"\"\"\n",
    "    result = local_keyword_search.invoke({\"query\": state[\"question\"]})\n",
    "    state[\"tool_result\"] = result\n",
    "    return state\n",
    "\n",
    "def chitchat_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"ÎèÑÍµ¨ ÏóÜÏù¥ LLM ÏßÅÏ†ë ÏùëÎãµ.\"\"\"\n",
    "    answer = llm.invoke(\n",
    "        \"Îã§Ïùå ÏßàÎ¨∏Ïóê Í∞ÑÍ≤∞ÌïòÍ≤å ÌïúÍµ≠Ïñ¥Î°ú ÎãµÌïòÎùº.\\n\"\n",
    "        \"Ï¢ÖÍ≤∞ÏùÄ ~Ïù¥Îã§/~ÌïúÎã§Î°ú ÌïúÎã§.\\n\"\n",
    "        f\"ÏßàÎ¨∏: {state['question']}\"\n",
    "    ).content\n",
    "    state[\"tool_result\"] = answer\n",
    "    return state\n",
    "\n",
    "def compose_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"ÏµúÏ¢Ö ÏùëÎãµ ÏÉùÏÑ±. ÎèÑÍµ¨ Í≤∞Í≥ºÏôÄ Î∂ÑÎ•ò Í∑ºÍ±∞Î•º Î∞îÌÉïÏúºÎ°ú Ï†ïÎ¶¨.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "Îã§Ïùå ÎÇ¥Ïö©ÏùÑ Î∞îÌÉïÏúºÎ°ú ÏµúÏ¢Ö ÎãµÎ≥ÄÏùÑ ÌïúÍµ≠Ïñ¥Î°ú Ï†ïÎ¶¨ÌïòÎùº.\n",
    "- Ï¢ÖÍ≤∞ÏùÄ ~Ïù¥Îã§/~ÌïúÎã§Î°ú ÌïúÎã§.\n",
    "- Î∂àÌïÑÏöîÌïú Ïû•ÏãùÏùÄ ÌïòÏßÄ ÏïäÎäîÎã§.\n",
    "- ÌïµÏã¨ Î®ºÏ†Ä, ÌïÑÏöîÌïú Í≤ΩÏö∞ Í∞ÑÎã®Ìïú Îã®Í≥Ñ/ÏΩîÎìú/Îã§Ïùå ÌñâÎèôÏùÑ Ï†úÏãúÌïúÎã§.\n",
    "\n",
    "ÏßàÎ¨∏: {state['question']}\n",
    "Î∂ÑÎ•ò: {state.get('intent')}\n",
    "Í∑ºÍ±∞: {state.get('reason')}\n",
    "ÎèÑÍµ¨Í≤∞Í≥º:\n",
    "{state.get('tool_result') or 'ÏóÜÏùå'}\n",
    "\"\"\"\n",
    "    state[\"final_answer\"] = llm.invoke(prompt).content\n",
    "    return state\n",
    "\n",
    "########################################\n",
    "# 4) Í∑∏ÎûòÌîÑ Íµ¨ÏÑ±\n",
    "########################################\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"classify\", RunnableLambda(classify_node))\n",
    "graph.add_node(\"math\", RunnableLambda(math_node))\n",
    "graph.add_node(\"faq\", RunnableLambda(faq_node))\n",
    "graph.add_node(\"search\", RunnableLambda(search_node))\n",
    "graph.add_node(\"chitchat\", RunnableLambda(chitchat_node))\n",
    "graph.add_node(\"compose\", RunnableLambda(compose_node))\n",
    "\n",
    "def route_from_intent(state: AgentState) -> str:\n",
    "    intent = state.get(\"intent\")\n",
    "    if intent == \"math\":\n",
    "        return \"math\"\n",
    "    if intent == \"faq\":\n",
    "        return \"faq\"\n",
    "    if intent == \"search\":\n",
    "        return \"search\"\n",
    "    return \"chitchat\"\n",
    "\n",
    "graph.set_entry_point(\"classify\")\n",
    "graph.add_conditional_edges(\"classify\", route_from_intent)\n",
    "graph.add_edge(\"math\", \"compose\")\n",
    "graph.add_edge(\"faq\", \"compose\")\n",
    "graph.add_edge(\"search\", \"compose\")\n",
    "graph.add_edge(\"chitchat\", \"compose\")\n",
    "graph.set_finish_point(\"compose\")\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "########################################\n",
    "# 5) Í∞ÑÎã® Ïã§Ìñâ ÏòàÏãú\n",
    "########################################\n",
    "if __name__ == \"__main__\":\n",
    "    examples = [\n",
    "        \"12*(3+4)/7\",                                   # math\n",
    "        \"LangChain Î≤ÑÏ†Ñ ÌôïÏù∏ Î∞©Î≤ï ÏïåÎ†§Ï§ò\",                # faq\n",
    "        \"LangGraphÍ∞Ä Î¨¥ÏóáÏù∏ÏßÄ Ìïú Ï§ÑÎ°ú ÏÑ§Î™ÖÌï¥Ï§ò\",          # faq\n",
    "        \"RAG ÌååÏù¥ÌîÑÎùºÏù∏ Îã®Í≥Ñ ÏïåÎ†§Ï§ò\",                     # faq ÎòêÎäî search\n",
    "        \"ÌïòÎäòÏùÄ Ïôú ÌååÎûÄÍ∞ÄÏöî?\",                            # chitchat\n",
    "        \"LangChainÏóêÏÑú RAG Íµ¨Ï∂ï ÌïµÏã¨ ÏöîÏïΩ\"                # search\n",
    "    ]\n",
    "    for q in examples:\n",
    "        out = app.invoke({\"question\": q})\n",
    "        print(\"Q:\", q)\n",
    "        print(\"‚Äî intent:\", out.get(\"intent\"), \"| reason:\", out.get(\"reason\"))\n",
    "        print(out[\"final_answer\"])\n",
    "        print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d50e42-6700-40b2-b8c8-117f146d881d",
   "metadata": {},
   "source": [
    "## Í≥†Í∏â ÏßàÎ¨∏ Ïú†ÌòïÎ≥Ñ ÎèÑÍµ¨ ÏûêÎèô ÏÑ†ÌÉù ÏóêÏù¥Ï†ÑÌä∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d16c32e-a3a3-42e5-bbe9-076e11810bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Í≥†Í∏â ÏßàÎ¨∏ Ïú†ÌòïÎ≥Ñ ÎèÑÍµ¨ ÏûêÎèô ÏÑ†ÌÉù ÏóêÏù¥Ï†ÑÌä∏\n",
      "============================================================\n",
      "Ï¢ÖÎ£å: 'quit' | ÎèÑÏõÄÎßê: 'help'\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üí¨ ÏßàÎ¨∏:  Îâ¥Ïöï ÎÇ†Ïî®Îäî?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§î Î∂ÑÏÑù Ï§ë...\n",
      "ÏÑ†ÌÉùÎêú ÎèÑÍµ¨: weather_tool (Ïã†Î¢∞ÎèÑ: 0.80)\n",
      "ÏÑ†ÌÉù Ïù¥Ïú†: ÎÇ†Ïî® Í¥ÄÎ†® ÌÇ§ÏõåÎìú Í∞êÏßÄ\n",
      "\n",
      "üìã ÎãµÎ≥Ä:\n",
      "üîß ÎèÑÍµ¨: weather_tool\n",
      "üéØ Ïã†Î¢∞ÎèÑ: 0.80\n",
      "üí≠ Ïù¥Ïú†: ÎÇ†Ïî® Í¥ÄÎ†® ÌÇ§ÏõåÎìú Í∞êÏßÄ\n",
      "üìù Í≤∞Í≥º: Îâ¥ÏöïÏùò ÌòÑÏû¨ ÎÇ†Ïî®: Clear +7¬∞C 60% ‚Üô13km/h 0.0mm\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üí¨ ÏßàÎ¨∏:  ÏïàÎÖïÌïòÏÑ∏ÏöîÎ•º ÏòÅÏñ¥Î°ú Î≤àÏó≠Ìï¥Ï§ò\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§î Î∂ÑÏÑù Ï§ë...\n",
      "ÏÑ†ÌÉùÎêú ÎèÑÍµ¨: translation_tool (Ïã†Î¢∞ÎèÑ: 0.80)\n",
      "ÏÑ†ÌÉù Ïù¥Ïú†: Î≤àÏó≠ Í¥ÄÎ†® ÌÇ§ÏõåÎìú Í∞êÏßÄ\n",
      "\n",
      "üìã ÎãµÎ≥Ä:\n",
      "üîß ÎèÑÍµ¨: translation_tool\n",
      "üéØ Ïã†Î¢∞ÎèÑ: 0.80\n",
      "üí≠ Ïù¥Ïú†: Î≤àÏó≠ Í¥ÄÎ†® ÌÇ§ÏõåÎìú Í∞êÏßÄ\n",
      "üìù Í≤∞Í≥º: 'ÏïàÎÖïÌïòÏÑ∏Ïöî'Î•º ÏòÅÏñ¥Î°ú Î≤àÏó≠: Hello\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üí¨ ÏßàÎ¨∏:  2 + 3 * 4 Í≥ÑÏÇ∞Ìï¥Ï§ò\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§î Î∂ÑÏÑù Ï§ë...\n",
      "ÏÑ†ÌÉùÎêú ÎèÑÍµ¨: calculator_tool (Ïã†Î¢∞ÎèÑ: 0.80)\n",
      "ÏÑ†ÌÉù Ïù¥Ïú†: Í≥ÑÏÇ∞ Í¥ÄÎ†® ÌÇ§ÏõåÎìú Í∞êÏßÄ\n",
      "\n",
      "üìã ÎãµÎ≥Ä:\n",
      "üîß ÎèÑÍµ¨: calculator_tool\n",
      "üéØ Ïã†Î¢∞ÎèÑ: 0.80\n",
      "üí≠ Ïù¥Ïú†: Í≥ÑÏÇ∞ Í¥ÄÎ†® ÌÇ§ÏõåÎìú Í∞êÏßÄ\n",
      "üìù Í≤∞Í≥º: Í≥ÑÏÇ∞ Í≤∞Í≥º: 2+3*4 = 14\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üí¨ ÏßàÎ¨∏:  Ïï†Ìîå Ï£ºÏãù Ï†ïÎ≥¥ ÏïåÎ†§Ï§ò\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§î Î∂ÑÏÑù Ï§ë...\n",
      "ÏÑ†ÌÉùÎêú ÎèÑÍµ¨: web_search_tool (Ïã†Î¢∞ÎèÑ: 0.70)\n",
      "ÏÑ†ÌÉù Ïù¥Ïú†: Í≤ÄÏÉâ Í¥ÄÎ†® ÌÇ§ÏõåÎìú Í∞êÏßÄ\n",
      "\n",
      "üìã ÎãµÎ≥Ä:\n",
      "üîß ÎèÑÍµ¨: web_search_tool\n",
      "üéØ Ïã†Î¢∞ÎèÑ: 0.70\n",
      "üí≠ Ïù¥Ïú†: Í≤ÄÏÉâ Í¥ÄÎ†® ÌÇ§ÏõåÎìú Í∞êÏßÄ\n",
      "üìù Í≤∞Í≥º: 'Ïï†Ìîå Ï£ºÏãù Ï†ïÎ≥¥ ÏïåÎ†§Ï§ò' Í≤ÄÏÉâ Í≤∞Í≥º:\n",
      "1. Ïï†Ìîå (Apple) Ï£ºÍ∞Ä - Investing.com\n",
      "   ÎÇ¥Ïö©: Ïï†Ìîå (Apple) Ï£ºÏãù Ïùò Í∞ÄÍ≤©, Ï∞®Ìä∏, Í∏∞Ïà†Ï†Å Î∂ÑÏÑù, Í≥ºÍ±∞ Îç∞Ïù¥ÌÑ∞ Îì± Ïï†Ìîå Ïóê ÎåÄÌïú ÏûêÏÑ∏Ìïú Ï†ïÎ≥¥Î•º ÏñªÏùÑ Ïàò ÏûàÏäµÎãàÎã§....\n",
      "   ÎßÅÌÅ¨: https://kr.investing.com/equities/apple-computer-inc\n",
      "\n",
      "2. Ïï†Ìîå (AAPL) Ï£ºÍ∞Ä Î∞è Îâ¥Ïä§ - Google Finance\n",
      "   ÎÇ¥Ïö©: ÏµúÍ∑º Ïï†Ìîå (AAPL)Ïùò Ïã§ÏãúÍ∞Ñ ÏãúÏÑ∏, Ïù¥Ï†Ñ Ïã§Ï†Å, Ï∞®Ìä∏Î•º ÎπÑÎ°ØÌïú Í∏àÏúµ Ï†ïÎ≥¥Î•º ÌôïÏù∏ÌïòÏó¨ Ï∂©Î∂ÑÌïú Ï†ïÎ≥¥Î•º Î∞îÌÉïÏúºÎ°ú Ï£ºÏãù Í±∞ÎûòÏôÄ Ìà¨ÏûêÎ•º Í≤∞Ï†ïÌïòÏÑ∏Ïöî....\n",
      "   ÎßÅÌÅ¨: https://www.google.com/finance/quote/AAPL:NASDAQ?hl=ko\n",
      "\n",
      "3. Ïï†Ìîå Ï£ºÏãù Ï∞®Ìä∏ ‚Äî NASDAQ:AAPL Ï£ºÍ∞Ä ‚Äî TradingView\n",
      "   ÎÇ¥Ïö©: ÎùºÏù¥Î∏å Ïï†Ìîå Ï£ºÏãùÌöåÏÇ¨ Ï∞®Ìä∏Î•º Î≥¥Î©¥ÏÑú Ïä§ÌÉÅ ÌîÑÎùºÏù¥Ïä§ Ïï°ÏÖòÏùÑ Îî∞ÎùºÍ∞Ä Î≥¥Ïã≠ÏãúÏò§. ÎßàÏºì ÌîÑÎ¶¨ÎîïÏÖò, AAPL ÌååÏù¥ÎÇ∏ÏÖú Î∞è ÎßàÏºì Îâ¥Ïä§Î•º Ï∞æÏïÑ Î≥¥Ïã≠ÏãúÏò§....\n",
      "   ÎßÅÌÅ¨: https://kr.tradingview.com/symbols/NASDAQ-AAPL/\n",
      "\n",
      "4. ÏãúÏÑ∏ Î∞è Îâ¥Ïä§ ÏöîÏïΩ - Benzinga Apple Inc. (AAPL) Stock Price, News, Quote & History - Yahoo ... Ïï†Ìîå (AAPL) Ï£ºÍ∞Ä Î∞è Ï∞®Ìä∏ | Ïò§ÎäòÏùò Ïã§ÏãúÍ∞Ñ AAPL ÏãúÏÑ∏ - Mitrade AAPL ‚Äì Ïï†Ìîå Ï£ºÍ∞Ä Î∞è Ï∞®Ìä∏ - StockScan\n",
      "   ÎÇ¥Ïö©: ÎãπÏã†ÏùÄ Ïñ¥Îñ§ Ïò®ÎùºÏù∏ Ï§ëÍ∞úÏóÖÏ≤¥Î•º ÌÜµÌï¥ NASDAQ:AAPL Ï£ºÏãù ÏùÑ Íµ¨Îß§Ìï† Ïàò ÏûàÏäµÎãàÎã§. Ïö∞Î¶¨Ïùò ÏµúÍ≥†Ïùò Ï£ºÏãù Ï§ëÍ∞úÏóÖÏ≤¥ Î™©Î°ùÏùÑ ÌôïÏù∏ÌïòÏÑ∏Ïöî. Find the latest Apple In...\n",
      "   ÎßÅÌÅ¨: https://kr.benzinga.com/quote/AAPL\n",
      "\n",
      "5. Apple Inc. (AAPL) Stock Price, News, Quote & History - Yahoo ...\n",
      "   ÎÇ¥Ïö©: Find the latest Apple Inc. (AAPL) stock quote, history, news and other vital information to help you...\n",
      "   ÎßÅÌÅ¨: https://finance.yahoo.com/quote/AAPL/?fr=sycsrp_catchall\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üí¨ ÏßàÎ¨∏:  ÏïàÎÖïÌïòÏÑ∏Ïöî\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§î Î∂ÑÏÑù Ï§ë...\n",
      "ÏÑ†ÌÉùÎêú ÎèÑÍµ¨: general_chat (Ïã†Î¢∞ÎèÑ: 0.50)\n",
      "ÏÑ†ÌÉù Ïù¥Ïú†: ÏùºÎ∞ò ÎåÄÌôîÎ°ú Î∂ÑÎ•ò\n",
      "\n",
      "üìã ÎãµÎ≥Ä:\n",
      "üîß ÎèÑÍµ¨: general_chat\n",
      "üéØ Ïã†Î¢∞ÎèÑ: 0.50\n",
      "üí≠ Ïù¥Ïú†: ÏùºÎ∞ò ÎåÄÌôîÎ°ú Î∂ÑÎ•ò\n",
      "üìù Í≤∞Í≥º: ÏïàÎÖïÌïòÏÑ∏Ïöî! Ïñ¥ÎñªÍ≤å ÎèÑÏôÄÎìúÎ¶¥ÍπåÏöî?\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üí¨ ÏßàÎ¨∏:  ÌååÏù¥Ïç¨Ïóê ÎåÄÌï¥ Í≤ÄÏÉâÌï¥Ï§ò\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§î Î∂ÑÏÑù Ï§ë...\n",
      "ÏÑ†ÌÉùÎêú ÎèÑÍµ¨: web_search_tool (Ïã†Î¢∞ÎèÑ: 0.70)\n",
      "ÏÑ†ÌÉù Ïù¥Ïú†: Í≤ÄÏÉâ Í¥ÄÎ†® ÌÇ§ÏõåÎìú Í∞êÏßÄ\n",
      "\n",
      "üìã ÎãµÎ≥Ä:\n",
      "üîß ÎèÑÍµ¨: web_search_tool\n",
      "üéØ Ïã†Î¢∞ÎèÑ: 0.70\n",
      "üí≠ Ïù¥Ïú†: Í≤ÄÏÉâ Í¥ÄÎ†® ÌÇ§ÏõåÎìú Í∞êÏßÄ\n",
      "üìù Í≤∞Í≥º: 'ÌååÏù¥Ïç¨Ïóê ÎåÄÌï¥ Í≤ÄÏÉâÌï¥Ï§ò' Í≤ÄÏÉâ Í≤∞Í≥º:\n",
      "1. Step1. ÌååÏù¥Ïç¨Ïóê ÎåÄÌï¥ ÏïåÏïÑÎ≥¥Ïûê. - Î≤®Î°úÍ∑∏\n",
      "   ÎÇ¥Ïö©: Î™©Ï∞®1. Python ÏÜåÍ∞ú2. PythonÏùò Ïû•Ï†ê3. PythonÏùò ÌôúÏö© Î∂ÑÏïº4. Python EditorÏùò Ï¢ÖÎ•ò Ïù¥Î≤à Ïû•ÏóêÏÑúÎäî ÌååÏù¥ Ïç¨ Ïóê ÎåÄÌïú Î™®Îì† Í≤É, ÌôúÏö©Î∂ÑÏïº, Í∞úÎ∞ú too...\n",
      "   ÎßÅÌÅ¨: https://velog.io/@justdotheg/1Ìé∏-Python-ÌîÑÎ°úÍ∑∏ÎûòÎ∞ç-Í∏∞Ï¥à-ÌïôÏäµÎ∞©Î≤ï\n",
      "\n",
      "2. ÌååÏù¥Ïç¨Ïóê ÎåÄÌïú ÏôÑÎ≤Ω Ï†ïÎ¶¨: ÏãúÍ∞ÑÏùÄ ÏóÜÏßÄÎßå, Î∞∞Ïö∞Í≥† Ïã∂ÏùÄ ÎãπÏã†ÏùÑ ÏúÑÌïòÏó¨\n",
      "   ÎÇ¥Ïö©: Jun 29, 2023 ¬∑ ÌååÏù¥ Ïç¨ Ïóê ÎåÄÌï¥ Í≥µÎ∂ÄÌï†ÏàòÎ°ù, Î™®Î•¥Îäî ÏßÄÏãùÏù¥ ÎÇòÏò§Í≥† Í∑∏ ÏßÄÏãùÏùÑ Ï∞æÍ∏∞ ÏúÑÌï¥ Í≥ÑÏÜç ÏãúÍ∞ÑÏùÑ Ìà¨ÏûêÌï¥Ïïº ÌïòÎãàÍπåÏöî. Ïù¥ Í∏ÄÏùÄ Î∞îÏÅòÏßÄÎßå, Î∞∞Ïö∞Í≥† Ïã∂ÏùÄ Î∂ÑÎì§ÏùÑ ÏúÑÌï¥ Ìåå...\n",
      "   ÎßÅÌÅ¨: https://kevinitcoding.tistory.com/entry/ÌååÏù¥Ïç¨Ïóê-ÎåÄÌïú-ÏôÑÎ≤Ω-Ï†ïÎ¶¨-ÏãúÍ∞ÑÏùÄ-ÏóÜÏßÄÎßå-Î∞∞Ïö∞Í≥†-Ïã∂ÏùÄ-ÎãπÏã†ÏùÑ-ÏúÑÌïòÏó¨\n",
      "\n",
      "3. ÌååÏù¥Ïç¨Ïóê ÎåÄÌïú Í∏∞Î≥∏Ï†ÅÏù∏ ÏÑ§Î™Ö Î∞è Í∞úÎ∞úÎèÑÍµ¨ÏôÄ ÎùºÏù¥Î∏åÎü¨Î¶¨ | LeeSponse\n",
      "   ÎÇ¥Ïö©: Apr 4, 2024 ¬∑ Home / Python / ÌååÏù¥ Ïç¨ Ïóê ÎåÄÌïú Í∏∞Î≥∏Ï†ÅÏù∏ ÏÑ§Î™Ö Î∞è Í∞úÎ∞úÎèÑÍµ¨ÏôÄ ÎùºÏù¥Î∏åÎü¨Î¶¨...\n",
      "   ÎßÅÌÅ¨: https://leesponse.github.io/python/Python/\n",
      "\n",
      "4. ÌååÏù¥Ïç¨Ïóê ÎåÄÌï¥ ÏïåÏïÑÎ≥¥Ïûê! - ÎÑ§Ïù¥Î≤Ñ Î∏îÎ°úÍ∑∏\n",
      "   ÎÇ¥Ïö©: ÏùºÏÉÅ ÌååÏù¥ Ïç¨ Ïóê ÎåÄÌï¥ ÏïåÏïÑÎ≥¥Ïûê! ÌòÑÏû¨ „Éª 35Î∂Ñ Ï†Ñ URL Î≥µÏÇ¨ Ïù¥ÏõÉÏ∂îÍ∞Ä ÌååÏù¥ Ïç¨ Ïùò ÌÉÑÏÉùÍ≥º ÌäπÏßï...\n",
      "   ÎßÅÌÅ¨: https://blog.naver.com/ju_present/223984981634\n",
      "\n",
      "5. ÌååÏù¥Ïç¨ (Python) Î∞îÎ°ú ÏïåÍ∏∞ ‚Äì ÌäπÏßï, Ïû•Ï†ê, ÌôúÏö© ÏÇ¨Î°Ä | Í∞ÄÎπÑÏïÑ ÎùºÏù¥Î∏å...\n",
      "   ÎÇ¥Ïö©: ÏïÑÎûòÏóêÏÑúÎäî ÌååÏù¥ Ïç¨ Ïùò ÌäπÏßï Î∞è Ïû•Ï†ê, Í∑∏Î¶¨Í≥† ÌôúÏö© ÏÇ¨Î°ÄÏóê ÎåÄÌï¥ ÏïåÏïÑÎ≥¥ÎèÑÎ°ù ÌïòÍ≤†ÏäµÎãàÎã§. ÌååÏù¥ Ïç¨ ÏÜåÍ∞ú...\n",
      "   ÎßÅÌÅ¨: https://library.gabia.com/contents/9256/\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üí¨ ÏßàÎ¨∏:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëã ÏóêÏù¥Ï†ÑÌä∏Î•º Ï¢ÖÎ£åÌï©ÎãàÎã§.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Í≥†Í∏â ÏßàÎ¨∏ Ïú†ÌòïÎ≥Ñ ÎèÑÍµ¨ ÏûêÎèô ÏÑ†ÌÉù ÏóêÏù¥Ï†ÑÌä∏\n",
    "- Ïã§Ï†ú API Ïó∞Îèô\n",
    "- ÎåÄÌôî Î©îÎ™®Î¶¨ Í∏∞Îä•\n",
    "- Îçî Ï†ïÍµêÌïú ÏßàÎ¨∏ Î∂ÑÎ•ò\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from typing import List, Dict, Any, Optional\n",
    "from datetime import datetime, timedelta\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from ddgs import DDGS\n",
    "import re\n",
    "\n",
    "class AdvancedQuestionClassifier:\n",
    "    \"\"\"Í≥†Í∏â ÏßàÎ¨∏ Î∂ÑÎ•òÍ∏∞ - Îçî Ï†ïÍµêÌïú Î∂ÑÎ•òÏôÄ Ïª®ÌÖçÏä§Ìä∏ Ïù¥Ìï¥\"\"\"\n",
    "    \n",
    "    def __init__(self, openai_api_key: str):\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=\"gpt-4o\",  # Îçî Ï†ïÌôïÌïú Î∂ÑÎ•òÎ•º ÏúÑÌï¥ GPT-4 ÏÇ¨Ïö©\n",
    "            api_key=openai_api_key,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        self.classification_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"ÎãπÏã†ÏùÄ ÏßàÎ¨∏ÏùÑ Î∂ÑÏÑùÌïòÏó¨ Ï†ÅÏ†àÌïú ÎèÑÍµ¨Î•º ÏÑ†ÌÉùÌïòÎäî Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§.\n",
    "\n",
    "ÏÇ¨Ïö© Í∞ÄÎä•Ìïú ÎèÑÍµ¨Îì§:\n",
    "1. weather_tool - ÎÇ†Ïî® Í¥ÄÎ†® ÏßàÎ¨∏ (ÏßÄÏó≠Î™Ö Ìè¨Ìï®)\n",
    "2. news_search_tool - Îâ¥Ïä§, Îâ¥Ïä§ Í≤ÄÏÉâ Í¥ÄÎ†®\n",
    "3. calculator_tool - ÏàòÌïô Í≥ÑÏÇ∞, ÏÇ∞Ïà† Ïó∞ÏÇ∞\n",
    "4. web_search_tool - ÏùºÎ∞òÏ†ÅÏù∏ Ï†ïÎ≥¥ Í≤ÄÏÉâ, Ï°∞ÏÇ¨\n",
    "5. translation_tool - Ïñ∏Ïñ¥ Î≤àÏó≠\n",
    "6. stock_tool - Ï£ºÏãù, Ìà¨Ïûê Í¥ÄÎ†® Ï†ïÎ≥¥\n",
    "7. general_chat - ÏùºÎ∞òÏ†ÅÏù∏ ÎåÄÌôî, Ïù∏ÏÇ¨, Í∞êÏ†ï ÌëúÌòÑ\n",
    "\n",
    "ÏßàÎ¨∏ÏùÑ Î∂ÑÏÑùÌïòÍ≥† Îã§Ïùå Ï†ïÎ≥¥Î•º JSON ÌòïÏãùÏúºÎ°ú Ï†úÍ≥µÌïòÏÑ∏Ïöî:\n",
    "{\n",
    "    \"tool\": \"ÏÑ†ÌÉùÎêú_ÎèÑÍµ¨Î™Ö\",\n",
    "    \"confidence\": 0.0-1.0,\n",
    "    \"reason\": \"ÏÑ†ÌÉù Ïù¥Ïú†\",\n",
    "    \"parameters\": {\n",
    "        \"param1\": \"Ï∂îÏ∂úÎêú_Í∞í1\",\n",
    "        \"param2\": \"Ï∂îÏ∂úÎêú_Í∞í2\"\n",
    "    }\n",
    "}\"\"\"),\n",
    "            (\"human\", \"ÏßàÎ¨∏: {question}\")\n",
    "        ])\n",
    "    \n",
    "    def classify_question(self, question: str) -> Dict[str, Any]:\n",
    "        \"\"\"ÏßàÎ¨∏ÏùÑ Î∂ÑÏÑùÌïòÏó¨ Ï†ÅÏ†àÌïú ÎèÑÍµ¨ÏôÄ Îß§Í∞úÎ≥ÄÏàòÎ•º ÏÑ†ÌÉù\"\"\"\n",
    "        try:\n",
    "            response = self.llm.invoke(\n",
    "                self.classification_prompt.format_messages(question=question)\n",
    "            )\n",
    "            \n",
    "            content = response.content.strip()\n",
    "            \n",
    "            # JSON Î∏îÎ°ù Ï†úÍ±∞\n",
    "            if '```json' in content:\n",
    "                start = content.find('```json') + 7\n",
    "                end = content.find('```', start)\n",
    "                if end != -1:\n",
    "                    content = content[start:end].strip()\n",
    "            elif '```' in content:\n",
    "                start = content.find('```') + 3\n",
    "                end = content.find('```', start)\n",
    "                if end != -1:\n",
    "                    content = content[start:end].strip()\n",
    "            \n",
    "            # JSON ÌååÏã± ÏãúÎèÑ\n",
    "            try:\n",
    "                result = json.loads(content)\n",
    "                return result\n",
    "            except json.JSONDecodeError:\n",
    "                # JSON ÌååÏã± Ïã§Ìå® Ïãú Í∞ÑÎã®Ìïú Ìå®ÌÑ¥ Îß§Ïπ≠ÏúºÎ°ú ÎåÄÏ≤¥\n",
    "                return self._fallback_classification(question, content)\n",
    "                \n",
    "        except Exception as e:\n",
    "            # Î∂ÑÎ•ò Ïò§Î•ò Î©îÏãúÏßÄ Ï†úÍ±∞ - ÌÇ§ÏõåÎìú Í∏∞Î∞ò Î∂ÑÎ•òÎ°ú ÎåÄÏ≤¥\n",
    "            return self._fallback_classification(question, \"\")\n",
    "    \n",
    "    def _fallback_classification(self, question: str, content: str) -> Dict[str, Any]:\n",
    "        \"\"\"JSON ÌååÏã± Ïã§Ìå® Ïãú Í∞ÑÎã®Ìïú Ìå®ÌÑ¥ Îß§Ïπ≠ÏúºÎ°ú Î∂ÑÎ•ò\"\"\"\n",
    "        question_lower = question.lower()\n",
    "        \n",
    "        if any(word in question_lower for word in ['ÎÇ†Ïî®', 'weather', 'Í∏∞Ïò®', 'Ïò®ÎèÑ']):\n",
    "            return {\n",
    "                \"tool\": \"weather_tool\",\n",
    "                \"confidence\": 0.8,\n",
    "                \"reason\": \"ÎÇ†Ïî® Í¥ÄÎ†® ÌÇ§ÏõåÎìú Í∞êÏßÄ\",\n",
    "                \"parameters\": {\"location\": self._extract_location(question)}\n",
    "            }\n",
    "        elif any(word in question_lower for word in ['Îâ¥Ïä§', 'news', 'Í∏∞ÏÇ¨']):\n",
    "            return {\n",
    "                \"tool\": \"news_search_tool\",\n",
    "                \"confidence\": 0.8,\n",
    "                \"reason\": \"Îâ¥Ïä§ Í¥ÄÎ†® ÌÇ§ÏõåÎìú Í∞êÏßÄ\",\n",
    "                \"parameters\": {\"query\": question}\n",
    "            }\n",
    "        elif any(word in question_lower for word in ['Í≥ÑÏÇ∞', 'ÎçîÌïòÍ∏∞', 'ÎπºÍ∏∞', 'Í≥±ÌïòÍ∏∞', 'ÎÇòÎàÑÍ∏∞', '+', '-', '*', '/']):\n",
    "            return {\n",
    "                \"tool\": \"calculator_tool\",\n",
    "                \"confidence\": 0.8,\n",
    "                \"reason\": \"Í≥ÑÏÇ∞ Í¥ÄÎ†® ÌÇ§ÏõåÎìú Í∞êÏßÄ\",\n",
    "                \"parameters\": {\"expression\": self._extract_expression(question)}\n",
    "            }\n",
    "        elif any(word in question_lower for word in ['Í≤ÄÏÉâ', 'Ï∞æÏïÑ', 'ÏïåÎ†§', 'Ï†ïÎ≥¥']):\n",
    "            return {\n",
    "                \"tool\": \"web_search_tool\",\n",
    "                \"confidence\": 0.7,\n",
    "                \"reason\": \"Í≤ÄÏÉâ Í¥ÄÎ†® ÌÇ§ÏõåÎìú Í∞êÏßÄ\",\n",
    "                \"parameters\": {\"query\": question}\n",
    "            }\n",
    "        elif any(word in question_lower for word in ['Î≤àÏó≠', 'translate', 'ÏòÅÏñ¥', 'english']):\n",
    "            return {\n",
    "                \"tool\": \"translation_tool\",\n",
    "                \"confidence\": 0.8,\n",
    "                \"reason\": \"Î≤àÏó≠ Í¥ÄÎ†® ÌÇ§ÏõåÎìú Í∞êÏßÄ\",\n",
    "                \"parameters\": {\"text\": self._extract_translation_text(question), \"target_language\": \"ÏòÅÏñ¥\"}\n",
    "            }\n",
    "        elif any(word in question_lower for word in ['Ï£ºÏãù', 'stock', 'Ï£ºÍ∞Ä', 'Ìà¨Ïûê']):\n",
    "            return {\n",
    "                \"tool\": \"stock_tool\",\n",
    "                \"confidence\": 0.8,\n",
    "                \"reason\": \"Ï£ºÏãù Í¥ÄÎ†® ÌÇ§ÏõåÎìú Í∞êÏßÄ\",\n",
    "                \"parameters\": {\"symbol\": \"AAPL\"}\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"tool\": \"general_chat\",\n",
    "                \"confidence\": 0.5,\n",
    "                \"reason\": \"ÏùºÎ∞ò ÎåÄÌôîÎ°ú Î∂ÑÎ•ò\",\n",
    "                \"parameters\": {}\n",
    "            }\n",
    "    \n",
    "    def _extract_expression(self, question: str) -> str:\n",
    "        \"\"\"ÏßàÎ¨∏ÏóêÏÑú ÏàòÌïô ÌëúÌòÑÏãù Ï∂îÏ∂ú\"\"\"\n",
    "        import re\n",
    "        # Îçî Ï†ïÌôïÌïú ÏàòÌïô ÌëúÌòÑÏãù Ï∂îÏ∂ú\n",
    "        # Ïà´Ïûê, Ïó∞ÏÇ∞Ïûê, Í¥ÑÌò∏, Í≥µÎ∞±ÏùÑ Ìè¨Ìï®Ìïú Ìå®ÌÑ¥\n",
    "        pattern = r'[\\d\\+\\-\\*\\/\\(\\)\\.\\s]+'\n",
    "        matches = re.findall(pattern, question)\n",
    "        \n",
    "        if matches:\n",
    "            # Í∞ÄÏû• Í∏¥ Îß§ÏπòÎ•º ÏÑ†ÌÉù (Îçî ÏôÑÏ†ÑÌïú ÌëúÌòÑÏãù)\n",
    "            longest_match = max(matches, key=len).strip()\n",
    "            # Í≥µÎ∞± Ï†úÍ±∞\n",
    "            expression = longest_match.replace(' ', '')\n",
    "            return expression\n",
    "        \n",
    "        # Ìå®ÌÑ¥ Îß§Ïπ≠Ïù¥ Ïã§Ìå®ÌïòÎ©¥ ÏßàÎ¨∏ÏóêÏÑú Ïà´ÏûêÏôÄ Ïó∞ÏÇ∞ÏûêÎßå Ï∂îÏ∂ú\n",
    "        expression = re.sub(r'[^\\d\\+\\-\\*\\/\\(\\)\\.]', '', question)\n",
    "        return expression if expression else question\n",
    "    \n",
    "    def _extract_location(self, question: str) -> str:\n",
    "        \"\"\"ÏßàÎ¨∏ÏóêÏÑú ÏßÄÏó≠Î™Ö Ï∂îÏ∂ú\"\"\"\n",
    "        # ÌïúÍµ≠ ÎèÑÏãúÎì§\n",
    "        korean_cities = ['ÏÑúÏö∏', 'Î∂ÄÏÇ∞', 'ÎåÄÍµ¨', 'Ïù∏Ï≤ú', 'Í¥ëÏ£º', 'ÎåÄÏ†Ñ', 'Ïö∏ÏÇ∞', 'ÏÑ∏Ï¢Ö', 'ÏàòÏõê', 'ÏÑ±ÎÇ®', 'Í≥†Ïñë', 'Ïö©Ïù∏', 'Ï≤≠Ï£º', 'Ï≤úÏïà', 'Ï†ÑÏ£º', 'Ìè¨Ìï≠', 'Ï†úÏ£º']\n",
    "        \n",
    "        # Ìï¥Ïô∏ ÎèÑÏãúÎì§\n",
    "        international_cities = ['Îâ¥Ïöï', 'New York', 'Îü∞Îçò', 'London', 'ÎèÑÏøÑ', 'Tokyo', 'Î≤†Ïù¥Ïßï', 'Beijing', 'ÌååÎ¶¨', 'Paris', 'ÏãúÎìúÎãà', 'Sydney', 'Î°úÏä§Ïï§Ï†§Î†àÏä§', 'Los Angeles', 'LA']\n",
    "        \n",
    "        # Î™®Îì† ÎèÑÏãú Î™©Î°ù\n",
    "        all_locations = korean_cities + international_cities\n",
    "        \n",
    "        for location in all_locations:\n",
    "            if location in question:\n",
    "                return location\n",
    "        \n",
    "        return \"ÏÑúÏö∏\"  # Í∏∞Î≥∏Í∞í\n",
    "    \n",
    "    def _extract_translation_text(self, question: str) -> str:\n",
    "        \"\"\"ÏßàÎ¨∏ÏóêÏÑú Î≤àÏó≠Ìï† ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú\"\"\"\n",
    "        import re\n",
    "        \n",
    "        # \"XXXÎ•º ÏòÅÏñ¥Î°ú Î≤àÏó≠Ìï¥Ï§ò\" Ìå®ÌÑ¥ÏóêÏÑú ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú\n",
    "        patterns = [\n",
    "            r'(.+?)Î•º\\s*ÏòÅÏñ¥Î°ú\\s*Î≤àÏó≠',\n",
    "            r'(.+?)ÏùÑ\\s*ÏòÅÏñ¥Î°ú\\s*Î≤àÏó≠',\n",
    "            r'(.+?)Î•º\\s*englishÎ°ú\\s*Î≤àÏó≠',\n",
    "            r'(.+?)ÏùÑ\\s*englishÎ°ú\\s*Î≤àÏó≠',\n",
    "            r'(.+?)Î•º\\s*Î≤àÏó≠',\n",
    "            r'(.+?)ÏùÑ\\s*Î≤àÏó≠'\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, question)\n",
    "            if match:\n",
    "                text = match.group(1).strip()\n",
    "                # Î∂àÌïÑÏöîÌïú Îã®Ïñ¥ Ï†úÍ±∞\n",
    "                text = text.replace('ÏùÑ', '').replace('Î•º', '').strip()\n",
    "                return text\n",
    "        \n",
    "        # Ìå®ÌÑ¥ Îß§Ïπ≠Ïù¥ Ïã§Ìå®ÌïòÎ©¥ ÏßàÎ¨∏ Ï†ÑÏ≤¥ÏóêÏÑú ÌïúÍ∏ÄÎßå Ï∂îÏ∂ú\n",
    "        korean_text = re.findall(r'[Í∞Ä-Ìû£]+', question)\n",
    "        if korean_text:\n",
    "            return korean_text[0]\n",
    "        \n",
    "        return question\n",
    "\n",
    "# API ÌÇ§ ÏóÜÏù¥ ÏÇ¨Ïö© Í∞ÄÎä•Ìïú ÎèÑÍµ¨Îì§\n",
    "@tool\n",
    "def weather_tool(location: str) -> str:\n",
    "    \"\"\"Ïã§Ï†ú ÎÇ†Ïî® Ï†ïÎ≥¥Î•º Ï†úÍ≥µÌï©ÎãàÎã§.\"\"\"\n",
    "    try:\n",
    "        # wttr.in Î¨¥Î£å ÎÇ†Ïî® API ÏÇ¨Ïö© (API ÌÇ§ Î∂àÌïÑÏöî)\n",
    "        url = f\"https://wttr.in/{location}?format=%C+%t+%h+%w+%p\"\n",
    "        response = requests.get(url, timeout=10)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            weather_data = response.text.strip()\n",
    "            return f\"{location}Ïùò ÌòÑÏû¨ ÎÇ†Ïî®: {weather_data}\"\n",
    "        else:\n",
    "            return f\"{location}Ïùò ÎÇ†Ïî® Ï†ïÎ≥¥Î•º Í∞ÄÏ†∏Ïò¨ Ïàò ÏóÜÏäµÎãàÎã§.\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"ÎÇ†Ïî® Ï†ïÎ≥¥ Ï°∞Ìöå Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}\"\n",
    "\n",
    "@tool\n",
    "def news_search_tool(query: str) -> str:\n",
    "    \"\"\"Ïã§Ï†ú Îâ¥Ïä§ Í≤ÄÏÉâ Í≤∞Í≥ºÎ•º Ï†úÍ≥µÌï©ÎãàÎã§.\"\"\"\n",
    "    try:\n",
    "        # DuckDuckGoÎ•º ÏÇ¨Ïö©Ìïú Îâ¥Ïä§ Í≤ÄÏÉâ (API ÌÇ§ Î∂àÌïÑÏöî)\n",
    "        with DDGS() as ddgs:\n",
    "            results = list(ddgs.news(query, max_results=5))\n",
    "            \n",
    "            if results:\n",
    "                news_text = f\"'{query}' Í¥ÄÎ†® ÏµúÏã† Îâ¥Ïä§:\\n\"\n",
    "                for i, article in enumerate(results, 1):\n",
    "                    title = article.get('title', 'Ï†úÎ™© ÏóÜÏùå')\n",
    "                    url = article.get('url', '')\n",
    "                    news_text += f\"{i}. {title}\\n   ÎßÅÌÅ¨: {url}\\n\"\n",
    "                return news_text\n",
    "            else:\n",
    "                return f\"'{query}' Í¥ÄÎ†® Îâ¥Ïä§Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.\"\n",
    "                \n",
    "    except Exception as e:\n",
    "        return f\"Îâ¥Ïä§ Í≤ÄÏÉâ Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}\"\n",
    "\n",
    "@tool\n",
    "def calculator_tool(expression: str) -> str:\n",
    "    \"\"\"ÏïàÏ†ÑÌïú ÏàòÌïô Í≥ÑÏÇ∞ÏùÑ ÏàòÌñâÌï©ÎãàÎã§.\"\"\"\n",
    "    try:\n",
    "        # ÌóàÏö©Îêú ÏàòÌïô Ïó∞ÏÇ∞ÏûêÏôÄ Ìï®ÏàòÎßå ÏÇ¨Ïö©\n",
    "        allowed_chars = set('0123456789+-*/.() ')\n",
    "        if not all(c in allowed_chars for c in expression):\n",
    "            return \"ÌóàÏö©ÎêòÏßÄ ÏïäÎäî Î¨∏ÏûêÍ∞Ä Ìè¨Ìï®ÎêòÏñ¥ ÏûàÏäµÎãàÎã§.\"\n",
    "        \n",
    "        # ÏúÑÌóòÌïú Ìï®ÏàòÎì§ Ï†úÍ±∞\n",
    "        dangerous_functions = ['eval', 'exec', 'import', '__']\n",
    "        if any(func in expression.lower() for func in dangerous_functions):\n",
    "            return \"Î≥¥ÏïàÏÉÅ ÌóàÏö©ÎêòÏßÄ ÏïäÎäî Ìï®ÏàòÍ∞Ä Ìè¨Ìï®ÎêòÏñ¥ ÏûàÏäµÎãàÎã§.\"\n",
    "        \n",
    "        result = eval(expression)\n",
    "        return f\"Í≥ÑÏÇ∞ Í≤∞Í≥º: {expression} = {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Í≥ÑÏÇ∞ Ïò§Î•ò: {e}\"\n",
    "\n",
    "@tool\n",
    "def web_search_tool(query: str) -> str:\n",
    "    \"\"\"Ïõπ Í≤ÄÏÉâ Í≤∞Í≥ºÎ•º Ï†úÍ≥µÌï©ÎãàÎã§.\"\"\"\n",
    "    try:\n",
    "        # DuckDuckGoÎ•º ÏÇ¨Ïö©Ìïú Ïõπ Í≤ÄÏÉâ (API ÌÇ§ Î∂àÌïÑÏöî)\n",
    "        with DDGS() as ddgs:\n",
    "            results = list(ddgs.text(query, max_results=5))\n",
    "            \n",
    "            if results:\n",
    "                search_text = f\"'{query}' Í≤ÄÏÉâ Í≤∞Í≥º:\\n\"\n",
    "                for i, result in enumerate(results, 1):\n",
    "                    title = result.get('title', 'Ï†úÎ™© ÏóÜÏùå')\n",
    "                    body = result.get('body', 'ÎÇ¥Ïö© ÏóÜÏùå')\n",
    "                    url = result.get('href', '')\n",
    "                    search_text += f\"{i}. {title}\\n   ÎÇ¥Ïö©: {body[:100]}...\\n   ÎßÅÌÅ¨: {url}\\n\\n\"\n",
    "                return search_text\n",
    "            else:\n",
    "                return f\"'{query}' Í¥ÄÎ†® Ï†ïÎ≥¥Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.\"\n",
    "                \n",
    "    except Exception as e:\n",
    "        return f\"Ïõπ Í≤ÄÏÉâ Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}\"\n",
    "\n",
    "@tool\n",
    "def translation_tool(text: str, target_language: str = \"ÏòÅÏñ¥\") -> str:\n",
    "    \"\"\"ÌÖçÏä§Ìä∏Î•º Îã§Î•∏ Ïñ∏Ïñ¥Î°ú Î≤àÏó≠Ìï©ÎãàÎã§.\"\"\"\n",
    "    try:\n",
    "        # ÌôïÏû•Îêú Î≤àÏó≠ ÏÇ¨Ï†Ñ\n",
    "        translations = {\n",
    "            # Ïù∏ÏÇ¨Îßê\n",
    "            \"ÏïàÎÖïÌïòÏÑ∏Ïöî\": \"Hello\",\n",
    "            \"ÏïàÎÖï\": \"Hi\",\n",
    "            \"ÏïàÎÖïÌûàÍ∞ÄÏÑ∏Ïöî\": \"Goodbye\",\n",
    "            \"ÏïàÎÖïÌûàÍ≥ÑÏÑ∏Ïöî\": \"Goodbye\",\n",
    "            \"Ï¢ãÏùÄÏïÑÏπ®\": \"Good morning\",\n",
    "            \"Ï¢ãÏùÄÏ†ÄÎÖÅ\": \"Good evening\",\n",
    "            \"Ï¢ãÏùÄÎ∞§\": \"Good night\",\n",
    "            \n",
    "            # Í∞êÏÇ¨/ÏÇ¨Í≥º\n",
    "            \"Í∞êÏÇ¨Ìï©ÎãàÎã§\": \"Thank you\",\n",
    "            \"Í≥†ÎßàÏõåÏöî\": \"Thank you\",\n",
    "            \"Í≥†ÎßôÏäµÎãàÎã§\": \"Thank you\",\n",
    "            \"ÎØ∏ÏïàÌï¥Ïöî\": \"I'm sorry\",\n",
    "            \"Ï£ÑÏÜ°Ìï©ÎãàÎã§\": \"I'm sorry\",\n",
    "            \"Í¥úÏ∞ÆÏïÑÏöî\": \"It's okay\",\n",
    "            \n",
    "            # Í∞êÏ†ï\n",
    "            \"ÏÇ¨ÎûëÌï¥Ïöî\": \"I love you\",\n",
    "            \"Ï¢ãÏïÑÌï¥Ïöî\": \"I like you\",\n",
    "            \"ÌñâÎ≥µÌï¥Ïöî\": \"I'm happy\",\n",
    "            \"Ïä¨ÌçºÏöî\": \"I'm sad\",\n",
    "            \"ÌôîÎÇòÏöî\": \"I'm angry\",\n",
    "            \"Í∏∞ÎªêÏöî\": \"I'm glad\",\n",
    "            \n",
    "            # ÎèÑÏõÄ/ÏöîÏ≤≠\n",
    "            \"ÎèÑÏôÄÏ£ºÏÑ∏Ïöî\": \"Please help me\",\n",
    "            \"ÎèÑÏôÄÏ§ò\": \"Help me\",\n",
    "            \"Î∂ÄÌÉÅÌï¥Ïöî\": \"Please\",\n",
    "            \"Ï†úÎ∞ú\": \"Please\",\n",
    "            \n",
    "            # ÏùºÏÉÅ\n",
    "            \"ÏûòÏßÄÎÇ¥ÏÑ∏Ïöî\": \"Take care\",\n",
    "            \"Í±¥Í∞ïÌïòÏÑ∏Ïöî\": \"Stay healthy\",\n",
    "            \"Ï°∞Ïã¨ÌïòÏÑ∏Ïöî\": \"Be careful\",\n",
    "            \"ÌôîÏù¥ÌåÖ\": \"Fighting\",\n",
    "            \"ÌûòÎÇ¥ÏÑ∏Ïöî\": \"Cheer up\",\n",
    "            \n",
    "            # ÏùåÏãù\n",
    "            \"ÎßõÏûàÏñ¥Ïöî\": \"It's delicious\",\n",
    "            \"Î∞∞Í≥†ÌååÏöî\": \"I'm hungry\",\n",
    "            \"Î™©ÎßêÎùºÏöî\": \"I'm thirsty\",\n",
    "            \n",
    "            # ÎÇ†Ïî®\n",
    "            \"ÎÇ†Ïî®Í∞ÄÏ¢ãÏïÑÏöî\": \"The weather is nice\",\n",
    "            \"ÎπÑÍ∞ÄÏôÄÏöî\": \"It's raining\",\n",
    "            \"ÎààÏù¥ÏôÄÏöî\": \"It's snowing\",\n",
    "            \"Ï∂•Îã§\": \"It's cold\",\n",
    "            \"Îç•Îã§\": \"It's hot\",\n",
    "            \n",
    "            # Ïà´Ïûê\n",
    "            \"ÌïòÎÇò\": \"one\",\n",
    "            \"Îëò\": \"two\", \n",
    "            \"ÏÖã\": \"three\",\n",
    "            \"ÎÑ∑\": \"four\",\n",
    "            \"Îã§ÏÑØ\": \"five\",\n",
    "            \"Ïó¨ÏÑØ\": \"six\",\n",
    "            \"ÏùºÍ≥±\": \"seven\",\n",
    "            \"Ïó¨Îçü\": \"eight\",\n",
    "            \"ÏïÑÌôâ\": \"nine\",\n",
    "            \"Ïó¥\": \"ten\"\n",
    "        }\n",
    "        \n",
    "        # ÌÖçÏä§Ìä∏ Ï†ïÎ¶¨ (Í≥µÎ∞± Ï†úÍ±∞)\n",
    "        clean_text = text.replace(' ', '').replace('\\n', '')\n",
    "        \n",
    "        if clean_text in translations:\n",
    "            return f\"'{text}'Î•º {target_language}Î°ú Î≤àÏó≠: {translations[clean_text]}\"\n",
    "        else:\n",
    "            # Î∂ÄÎ∂Ñ Îß§Ïπ≠ ÏãúÎèÑ\n",
    "            for korean, english in translations.items():\n",
    "                if korean in clean_text:\n",
    "                    return f\"'{text}'ÏóêÏÑú '{korean}'Î•º {target_language}Î°ú Î≤àÏó≠: {english}\"\n",
    "            \n",
    "            return f\"'{text}'Ïùò Î≤àÏó≠ÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. Îçî Ï†ïÍµêÌïú Î≤àÏó≠ÏùÑ ÏúÑÌï¥ÏÑúÎäî Î≤àÏó≠ APIÍ∞Ä ÌïÑÏöîÌï©ÎãàÎã§.\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Î≤àÏó≠ Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}\"\n",
    "\n",
    "@tool\n",
    "def stock_tool(symbol: str) -> str:\n",
    "    \"\"\"Ï£ºÏãù Ï†ïÎ≥¥Î•º Ï†úÍ≥µÌï©ÎãàÎã§.\"\"\"\n",
    "    try:\n",
    "        # Í∞ÑÎã®Ìïú Ï£ºÏãù Ï†ïÎ≥¥ (API ÌÇ§ ÏóÜÏù¥ ÏÇ¨Ïö© Í∞ÄÎä•Ìïú Í∏∞Î≥∏ Ï†ïÎ≥¥)\n",
    "        stock_info = {\n",
    "            \"AAPL\": \"Apple Inc. - Í∏∞Ïà† Ï£ºÏãù\",\n",
    "            \"GOOGL\": \"Alphabet Inc. - Íµ¨Í∏Ä Î™®ÌöåÏÇ¨\",\n",
    "            \"MSFT\": \"Microsoft Corporation - ÎßàÏù¥ÌÅ¨Î°úÏÜåÌîÑÌä∏\",\n",
    "            \"TSLA\": \"Tesla Inc. - Ï†ÑÍ∏∞Ï∞® ÌöåÏÇ¨\",\n",
    "            \"AMZN\": \"Amazon.com Inc. - ÏïÑÎßàÏ°¥\",\n",
    "            \"META\": \"Meta Platforms Inc. - ÌéòÏù¥Ïä§Î∂Å\",\n",
    "            \"NVDA\": \"NVIDIA Corporation - Î∞òÎèÑÏ≤¥ ÌöåÏÇ¨\"\n",
    "        }\n",
    "        \n",
    "        if symbol.upper() in stock_info:\n",
    "            return f\"{symbol.upper()} Ï£ºÏãù Ï†ïÎ≥¥: {stock_info[symbol.upper()]}\\nÏã§ÏãúÍ∞Ñ Í∞ÄÍ≤© Ï†ïÎ≥¥Î•º ÏúÑÌï¥ÏÑúÎäî Ï£ºÏãù APIÍ∞Ä ÌïÑÏöîÌï©ÎãàÎã§.\"\n",
    "        else:\n",
    "            return f\"{symbol} Ï£ºÏãù Ï†ïÎ≥¥Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. ÏßÄÏõêÎêòÎäî Ï£ºÏãù: {', '.join(stock_info.keys())}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Ï£ºÏãù Ï†ïÎ≥¥ Ï°∞Ìöå Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}\"\n",
    "\n",
    "class AdvancedToolSelectorAgent:\n",
    "    \"\"\"Í≥†Í∏â ÏßàÎ¨∏ Ïú†ÌòïÎ≥Ñ ÎèÑÍµ¨ ÏûêÎèô ÏÑ†ÌÉù ÏóêÏù¥Ï†ÑÌä∏\"\"\"\n",
    "    \n",
    "    def __init__(self, openai_api_key: str):\n",
    "        self.classifier = AdvancedQuestionClassifier(openai_api_key)\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            api_key=openai_api_key,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        # ÎèÑÍµ¨ Îß§Ìïë\n",
    "        self.tools = {\n",
    "            \"weather_tool\": weather_tool,\n",
    "            \"news_search_tool\": news_search_tool,\n",
    "            \"calculator_tool\": calculator_tool,\n",
    "            \"web_search_tool\": web_search_tool,\n",
    "            \"translation_tool\": translation_tool,\n",
    "            \"stock_tool\": stock_tool\n",
    "        }\n",
    "        \n",
    "        # ÏùºÎ∞ò ÎåÄÌôîÏö© ÌîÑÎ°¨ÌîÑÌä∏\n",
    "        self.chat_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"ÎãπÏã†ÏùÄ ÎèÑÏõÄÏù¥ ÎêòÎäî AI Ïñ¥ÏãúÏä§ÌÑ¥Ìä∏ÏûÖÎãàÎã§. \n",
    "ÏÇ¨Ïö©ÏûêÏùò ÏßàÎ¨∏Ïóê ÏπúÏ†àÌïòÍ≥† Ï†ïÌôïÌïòÍ≤å ÎãµÎ≥ÄÌï¥Ï£ºÏÑ∏Ïöî.\"\"\"),\n",
    "            (\"human\", \"{question}\")\n",
    "        ])\n",
    "    \n",
    "    def process_question(self, question: str) -> Dict[str, Any]:\n",
    "        \"\"\"ÏßàÎ¨∏ÏùÑ Ï≤òÎ¶¨ÌïòÍ≥† Ï†ÅÏ†àÌïú ÎèÑÍµ¨Î•º ÏÇ¨Ïö©ÌïòÏó¨ ÎãµÎ≥ÄÏùÑ ÏÉùÏÑ±\"\"\"\n",
    "        \n",
    "        # 1. ÏßàÎ¨∏ Ïú†Ìòï Î∂ÑÎ•ò\n",
    "        classification = self.classifier.classify_question(question)\n",
    "        selected_tool = classification[\"tool\"]\n",
    "        confidence = classification[\"confidence\"]\n",
    "        reason = classification[\"reason\"]\n",
    "        parameters = classification[\"parameters\"]\n",
    "        \n",
    "        print(f\"ÏÑ†ÌÉùÎêú ÎèÑÍµ¨: {selected_tool} (Ïã†Î¢∞ÎèÑ: {confidence:.2f})\")\n",
    "        print(f\"ÏÑ†ÌÉù Ïù¥Ïú†: {reason}\")\n",
    "        \n",
    "        # 2. ÎèÑÍµ¨ Ïã§Ìñâ ÎòêÎäî ÏùºÎ∞ò ÎåÄÌôî\n",
    "        if selected_tool in self.tools and confidence > 0.6:\n",
    "            try:\n",
    "                tool_func = self.tools[selected_tool]\n",
    "                \n",
    "                # Îß§Í∞úÎ≥ÄÏàò Ï§ÄÎπÑ\n",
    "                if selected_tool == \"weather_tool\":\n",
    "                    location = parameters.get(\"location\", \"ÏÑúÏö∏\")\n",
    "                    result = tool_func.invoke({\"location\": location})\n",
    "                elif selected_tool == \"news_search_tool\":\n",
    "                    query = parameters.get(\"query\", question)\n",
    "                    result = tool_func.invoke({\"query\": query})\n",
    "                elif selected_tool == \"calculator_tool\":\n",
    "                    expression = parameters.get(\"expression\", question)\n",
    "                    result = tool_func.invoke({\"expression\": expression})\n",
    "                elif selected_tool == \"web_search_tool\":\n",
    "                    query = parameters.get(\"query\", question)\n",
    "                    result = tool_func.invoke({\"query\": query})\n",
    "                elif selected_tool == \"translation_tool\":\n",
    "                    text = parameters.get(\"text\", question)\n",
    "                    target_lang = parameters.get(\"target_language\", \"ÏòÅÏñ¥\")\n",
    "                    result = tool_func.invoke({\"text\": text, \"target_language\": target_lang})\n",
    "                elif selected_tool == \"stock_tool\":\n",
    "                    symbol = parameters.get(\"symbol\", \"AAPL\")\n",
    "                    result = tool_func.invoke({\"symbol\": symbol})\n",
    "                \n",
    "                return {\n",
    "                    \"tool_used\": selected_tool,\n",
    "                    \"confidence\": confidence,\n",
    "                    \"reason\": reason,\n",
    "                    \"result\": result,\n",
    "                    \"success\": True\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = f\"ÎèÑÍµ¨ Ïã§Ìñâ Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}\"\n",
    "                \n",
    "                return {\n",
    "                    \"tool_used\": selected_tool,\n",
    "                    \"confidence\": confidence,\n",
    "                    \"reason\": reason,\n",
    "                    \"result\": error_msg,\n",
    "                    \"success\": False\n",
    "                }\n",
    "        else:\n",
    "            # ÏùºÎ∞ò ÎåÄÌôî\n",
    "            try:\n",
    "                response = self.llm.invoke(\n",
    "                    self.chat_prompt.format_messages(question=question)\n",
    "                )\n",
    "                \n",
    "                return {\n",
    "                    \"tool_used\": \"general_chat\",\n",
    "                    \"confidence\": confidence,\n",
    "                    \"reason\": reason,\n",
    "                    \"result\": response.content,\n",
    "                    \"success\": True\n",
    "                }\n",
    "            except Exception as e:\n",
    "                error_msg = f\"ÎåÄÌôî Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}\"\n",
    "                \n",
    "                return {\n",
    "                    \"tool_used\": \"general_chat\",\n",
    "                    \"confidence\": confidence,\n",
    "                    \"reason\": reason,\n",
    "                    \"result\": error_msg,\n",
    "                    \"success\": False\n",
    "                }\n",
    "    \n",
    "\n",
    "def main():\n",
    "    \"\"\"Î©îÏù∏ Ïã§Ìñâ Ìï®Ïàò\"\"\"\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not openai_api_key:\n",
    "        print(\"‚ùå OPENAI_API_KEY ÌôòÍ≤Ω Î≥ÄÏàòÎ•º ÏÑ§Ï†ïÌï¥Ï£ºÏÑ∏Ïöî.\")\n",
    "        return\n",
    "    \n",
    "    agent = AdvancedToolSelectorAgent(openai_api_key)\n",
    "    \n",
    "    print(\"üöÄ Í≥†Í∏â ÏßàÎ¨∏ Ïú†ÌòïÎ≥Ñ ÎèÑÍµ¨ ÏûêÎèô ÏÑ†ÌÉù ÏóêÏù¥Ï†ÑÌä∏\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Ï¢ÖÎ£å: 'quit' | ÎèÑÏõÄÎßê: 'help'\")\n",
    "    print()\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            question = input(\"üí¨ ÏßàÎ¨∏: \").strip()\n",
    "            \n",
    "            if question.lower() in ['quit', 'exit', 'Ï¢ÖÎ£å']:\n",
    "                print(\"üëã ÏóêÏù¥Ï†ÑÌä∏Î•º Ï¢ÖÎ£åÌï©ÎãàÎã§.\")\n",
    "                break\n",
    "            \n",
    "            if question.lower() == 'help':\n",
    "                print(\"\"\"\n",
    "üîß ÏÇ¨Ïö© Í∞ÄÎä•Ìïú ÏßàÎ¨∏ Ïú†Ìòï:\n",
    "- üå§Ô∏è ÎÇ†Ïî®: \"ÏÑúÏö∏ ÎÇ†Ïî® Ïñ¥Îïå?\", \"Îâ¥Ïöï ÎÇ†Ïî®Îäî?\"\n",
    "- üì∞ Îâ¥Ïä§: \"ÏµúÏã† Îâ¥Ïä§ ÏïåÎ†§Ï§ò\", \"AI Îâ¥Ïä§ Í≤ÄÏÉâÌï¥Ï§ò\"\n",
    "- üßÆ Í≥ÑÏÇ∞: \"2 + 3 * 4 Í≥ÑÏÇ∞Ìï¥Ï§ò\", \"ÏõêÏùò ÎÑìÏù¥ Íµ¨Ìï¥Ï§ò\"\n",
    "- üîç Í≤ÄÏÉâ: \"ÌååÏù¥Ïç¨Ïóê ÎåÄÌï¥ Í≤ÄÏÉâÌï¥Ï§ò\", \"Î®∏Ïã†Îü¨Îãù Ï†ïÎ≥¥ Ï∞æÏïÑÏ§ò\"\n",
    "- üåê Î≤àÏó≠: \"ÏïàÎÖïÌïòÏÑ∏ÏöîÎ•º ÏòÅÏñ¥Î°ú Î≤àÏó≠Ìï¥Ï§ò\"\n",
    "- üìà Ï£ºÏãù: \"Ïï†Ìîå Ï£ºÏãù Ï†ïÎ≥¥ ÏïåÎ†§Ï§ò\", \"TSLA Ï£ºÍ∞Ä ÌôïÏù∏Ìï¥Ï§ò\"\n",
    "- üí¨ ÏùºÎ∞ò ÎåÄÌôî: \"ÏïàÎÖïÌïòÏÑ∏Ïöî\", \"Ïò§Îäò Í∏∞Î∂ÑÏù¥ Ïñ¥Îïå?\"\n",
    "                \"\"\")\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            if not question:\n",
    "                continue\n",
    "            \n",
    "            print(\"ü§î Î∂ÑÏÑù Ï§ë...\")\n",
    "            result = agent.process_question(question)\n",
    "            \n",
    "            print(f\"\\nüìã ÎãµÎ≥Ä:\")\n",
    "            print(f\"üîß ÎèÑÍµ¨: {result['tool_used']}\")\n",
    "            print(f\"üéØ Ïã†Î¢∞ÎèÑ: {result['confidence']:.2f}\")\n",
    "            print(f\"üí≠ Ïù¥Ïú†: {result['reason']}\")\n",
    "            print(f\"üìù Í≤∞Í≥º: {result['result']}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nüëã ÏóêÏù¥Ï†ÑÌä∏Î•º Ï¢ÖÎ£åÌï©ÎãàÎã§.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Ïò§Î•ò Î∞úÏÉù: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefbe586-b766-4d61-b0e3-80f8145cd2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CrewAI)",
   "language": "python",
   "name": "crewai-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
