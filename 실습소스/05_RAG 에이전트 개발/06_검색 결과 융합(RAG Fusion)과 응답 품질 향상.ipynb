{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e2639bd-7543-4dc8-b7ba-470b6b30ef93",
   "metadata": {},
   "source": [
    "## 검색 결과 융합(RAG Fusion)과 응답 품질 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80cf6406-807e-46f6-a9e2-a4d2b0e10b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일의 내용 불러오기\n",
    "load_dotenv(\"C:/env/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b1926ba-8f0b-4149-9693-4f78593c5d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 최종 응답 ===\n",
      "RAG Fusion은 정보 검색의 한 방법으로, 여러 검색 결과를 융합하여 문맥을 생성하는 기술입니다. 이 기술은 대규모 데이터셋에서 관련 정보를 효과적으로 추출하고, 이를 바탕으로 더 정확하고 유의미한 응답을 생성하는 데 중점을 둡니다. RAG는 \"Retrieval-Augmented Generation\"의 약자로, 검색(retrieval)과 생성(generation) 모델을 결합하여 작동합니다.\n",
      "\n",
      "RAG Fusion이 응답 품질을 향상시키는 방법은 다음과 같습니다:\n",
      "\n",
      "1. **정보의 다양성**: 여러 검색 결과를 통합하여 다양한 관점을 포함한 응답을 생성합니다. 이는 사용자가 요청한 정보에 대해 보다 포괄적이고 균형 잡힌 답변을 제공할 수 있게 합니다.\n",
      "\n",
      "2. **정확성 향상**: 검색된 정보의 정확성을 높임으로써, 생성된 응답의 신뢰성을 강화합니다. RAG는 최신 정보와 관련된 데이터를 검색하여, 사용자가 필요로 하는 정확한 정보를 기반으로 응답을 생성합니다.\n",
      "\n",
      "3. **문맥 이해**: 검색된 정보를 바탕으로 문맥을 형성하여, 단순한 사실 나열이 아닌, 사용자의 질문에 대한 깊이 있는 이해를 바탕으로 한 응답을 제공합니다. 이는 사용자가 원하는 정보를 보다 명확하게 전달하는 데 기여합니다.\n",
      "\n",
      "4. **적응성**: 다양한 데이터 소스에서 정보를 검색하고 융합할 수 있기 때문에, 변화하는 정보 환경에 적응하여 최신 정보를 반영한 응답을 생성할 수 있습니다.\n",
      "\n",
      "결론적으로, RAG Fusion은 검색과 생성 모델의 결합을 통해 정보의 정확성과 다양성을 높이고, 문맥을 이해하여 보다 유의미한 응답을 생성함으로써 응답 품질을 향상시키는 기술입니다.\n"
     ]
    }
   ],
   "source": [
    "# 🔸 LangChain v1.0 기준 Fusion RAG + Answer Refine Agent 예제\n",
    "# pip install langchain langchain-openai langchain-community faiss-cpu python-dotenv\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 1) LLM 및 임베딩 모델 초기화\n",
    "# -------------------------------------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2) 샘플 문서 및 벡터스토어 초기화\n",
    "# -------------------------------------------------------\n",
    "docs = [\n",
    "    Document(page_content=\"인공지능은 인간의 학습 능력과 추론을 모방하는 기술이다.\"),\n",
    "    Document(page_content=\"머신러닝은 데이터를 이용해 스스로 패턴을 학습하는 인공지능의 한 분야이다.\"),\n",
    "    Document(page_content=\"RAG는 검색과 생성 모델을 결합해 응답의 정확성을 높인다.\"),\n",
    "    Document(page_content=\"Fusion RAG는 여러 검색 결과를 결합해 응답 품질을 높이는 방법이다.\"),\n",
    "]\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3) Fusion RAG 도구 정의\n",
    "# -------------------------------------------------------\n",
    "@tool\n",
    "def fusion_rag_search(query: str) -> str:\n",
    "    \"\"\"Fusion RAG 방식으로 여러 쿼리 검색 결과를 융합하여 문맥을 반환한다.\"\"\"\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "    sub_queries = [\n",
    "        query,\n",
    "        f\"{query} 관련 개념을 설명하라\",\n",
    "        f\"{query}의 작동 원리를 요약하라\",\n",
    "    ]\n",
    "\n",
    "    all_results = []\n",
    "    for q in sub_queries:\n",
    "        results = retriever.invoke(q)\n",
    "        all_results.extend(results)\n",
    "\n",
    "    # 중복 제거\n",
    "    unique_texts = list({d.page_content for d in all_results})\n",
    "    fused_context = \"\\n\".join(unique_texts)\n",
    "\n",
    "    return f\"[융합 문맥]\\n{fused_context}\"\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 4) 응답 품질 향상 도구 정의\n",
    "# -------------------------------------------------------\n",
    "@tool\n",
    "def answer_refiner(context: str, question: str) -> str:\n",
    "    \"\"\"Fusion된 문맥을 기반으로 고품질 응답을 생성한다.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    아래 문맥을 참고하여 질문에 대해 명확하고 근거 있는 답변을 작성하라.\n",
    "\n",
    "    [문맥]\n",
    "    {context}\n",
    "\n",
    "    [질문]\n",
    "    {question}\n",
    "\n",
    "    답변:\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 5) 에이전트 생성 (LangChain v1.0 형식)\n",
    "# -------------------------------------------------------\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[fusion_rag_search, answer_refiner],\n",
    "    system_prompt=\"사용자의 요청을 해결하기 위해 필요시 Fusion RAG과 품질 향상 도구를 사용하라.\"\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 6) 실행: v1에서는 messages 리스트로 전달\n",
    "# -------------------------------------------------------\n",
    "result = agent.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"RAG Fusion이 무엇이며 응답 품질을 어떻게 향상시키는가?\"}\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n=== 최종 응답 ===\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79981940-cece-4dd4-98ac-6c3e6380461a",
   "metadata": {},
   "source": [
    "### RAG Fusion활용 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "591e54b3-9a77-426b-8aac-e7b33411b136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Fusion RAG + Answer Refine Agent 예제 시작\n",
      "==================================================\n",
      "📚 지식 베이스 구축 중...\n",
      "✅ 8개 문서가 벡터스토어에 저장되었습니다.\n",
      "🤖 Fusion RAG 에이전트가 생성되었습니다.\n",
      "\n",
      "📝 테스트 질문 실행\n",
      "==================================================\n",
      "\n",
      "🔍 질문 1: RAG Fusion이 무엇이며 응답 품질을 어떻게 향상시키는가?\n",
      "------------------------------\n",
      "💡 응답: RAG Fusion은 Retrieval-Augmented Generation의 한 형태로, 여러 검색 결과를 통합하여 응답의 품질을 높이는 방법입니다. 이 기술은 다양한 관점에서 쿼리를 수행하여 더 포괄적이고 정확한 정보를 수집하는 데 중점을 둡니다.\n",
      "\n",
      "### RAG Fusion의 작동 원리\n",
      "\n",
      "1. **다양한 쿼리 수행**: RAG Fusion은 사용자가 입력한 질문에 대해 여러 가지 관점에서 쿼리를 생성합니다. 예를 들어, \"기후 변화의 원인은 무엇인가?\"라는 질문에 대해 \"기후 변화의 과학적 원인\", \"사회적 요인\", \"경제적 영향\" 등 다양한 측면에서 정보를 검색합니다.\n",
      "\n",
      "2. **검색 결과 통합**: 각 쿼리에서 얻은 검색 결과를 결합하여, 중복된 정보는 제거하고 서로 보완적인 정보를 통합합니다. 이를 통해 보다 풍부하고 다각적인 응답을 생성할 수 있습니다.\n",
      "\n",
      "3. **응답 생성**: 통합된 정보를 바탕으로 최종 응답을 생성합니다. 이 과정에서 RAG는 생성 모델을 활용하여 자연스러운 언어로 응답을 구성하며, 정보의 정확성과 신뢰성을 높입니다.\n",
      "\n",
      "### 응답 품질 향상 방법\n",
      "\n",
      "- **정보의 포괄성**: 다양한 쿼리를 통해 수집된 정보는 단일 출처에서 얻은 정보보다 더 포괄적입니다. 예를 들어, 기후 변화에 대한 질문에 대해 여러 관점에서 정보를 제공함으로써 사용자는 보다 깊이 있는 이해를 할 수 있습니다.\n",
      "\n",
      "- **신뢰성 증가**: 여러 출처에서 수집된 정보를 통합함으로써, 특정 출처의 오류나 편향을 줄일 수 있습니다. 이는 사용자가 보다 신뢰할 수 있는 정보를 제공받는 데 기여합니다.\n",
      "\n",
      "- **다양한 시각 제공**: RAG Fusion은 단순히 정보를 나열하는 것이 아니라, 서로 다른 관점에서의 분석을 통해 사용자가 문제를 다각도로 이해할 수 있도록 돕습니다. 예를 들어, 기후 변화의 경제적 영향과 사회적 반응을 함께 제시함으로써, 사용자는 보다 균형 잡힌 시각을 가질 수 있습니다.\n",
      "\n",
      "결론적으로, RAG Fusion은 다양한 검색 결과를 결합하여 응답의 품질을 향상시키는 혁신적인 방법으로, 정보의 포괄성, 신뢰성, 그리고 다양한 시각을 제공하는 데 중점을 두고 있습니다. 이러한 접근 방식은 특히 복잡한 질문에 대한 응답을 생성할 때 유용합니다.\n",
      "--------------------------------------------------\n",
      "\n",
      "🔍 질문 2: 머신러닝과 딥러닝의 차이점은 무엇인가?\n",
      "------------------------------\n",
      "💡 응답: 머신러닝과 딥러닝은 인공지능의 두 가지 주요 분야로, 각각의 특징과 적용 방식에서 차이를 보입니다. 아래에서 이 두 분야의 차이점을 설명하겠습니다.\n",
      "\n",
      "### 1. 정의 및 범위\n",
      "- **머신러닝**: 머신러닝은 데이터를 통해 패턴을 학습하는 알고리즘의 집합으로, 지도학습, 비지도학습, 강화학습 등 다양한 학습 방법을 포함합니다. 상대적으로 적은 양의 데이터로도 효과적으로 학습할 수 있는 알고리즘을 사용합니다.\n",
      "- **딥러닝**: 딥러닝은 머신러닝의 하위 분야로, 인공신경망을 기반으로 하여 데이터에서 복잡한 패턴을 학습합니다. 대량의 데이터와 강력한 컴퓨팅 파워를 필요로 하며, 주로 이미지 인식, 자연어 처리와 같은 복잡한 문제를 해결하는 데 사용됩니다.\n",
      "\n",
      "### 2. 데이터 요구량\n",
      "- **머신러닝**: 일반적으로 적은 양의 데이터로도 학습이 가능하며, 예를 들어, 선형 회귀나 결정 트리와 같은 알고리즘은 몇 백 개의 데이터 포인트로도 유의미한 결과를 도출할 수 있습니다.\n",
      "- **딥러닝**: 대량의 데이터가 필요합니다. 예를 들어, 이미지 분류 문제에서 딥러닝 모델은 수만 장의 이미지로 훈련되어야 높은 정확도를 달성할 수 있습니다.\n",
      "\n",
      "### 3. 모델의 복잡성\n",
      "- **머신러닝**: 상대적으로 간단한 모델을 사용하며, 해석이 용이한 경우가 많습니다. 예를 들어, 로지스틱 회귀 모델은 결과를 쉽게 해석할 수 있습니다.\n",
      "- **딥러닝**: 복잡한 인공신경망 구조를 사용하여 여러 층을 통해 데이터를 처리합니다. 이로 인해 모델의 해석이 어려워질 수 있지만, 더 복잡한 패턴을 학습할 수 있는 장점이 있습니다.\n",
      "\n",
      "### 4. 적용 분야\n",
      "- **머신러닝**: 금융, 의료, 마케팅 등 다양한 분야에서 사용되며, 예를 들어, 고객 세분화나 사기 탐지와 같은 문제에 효과적입니다.\n",
      "- **딥러닝**: 이미지 인식, 음성 인식, 자연어 처리 등에서 뛰어난 성능을 발휘하며, 자율주행차의 이미지 인식 시스템이나 챗봇의 자연어 처리에 활용됩니다.\n",
      "\n",
      "### 결론\n",
      "머신러닝과 딥러닝은 각각의 장단점이 있으며, 특정 문제에 따라 적합한 방법을 선택하는 것이 중요합니다. 머신러닝은 적은 데이터로도 효과적인 결과를 도출할 수 있는 반면, 딥러닝은 대량의 데이터와 복잡한 문제 해결에 강점을 가지고 있습니다. 이러한 차이점을 이해하고 활용하는 것이 인공지능 기술을 효과적으로 적용하는 데 도움이 됩니다.\n",
      "--------------------------------------------------\n",
      "\n",
      "🔍 질문 3: 벡터 데이터베이스의 역할과 장점은 무엇인가?\n",
      "------------------------------\n",
      "💡 응답: 벡터 데이터베이스의 역할과 장점은 다음과 같이 정리할 수 있습니다.\n",
      "\n",
      "### 1. 역할\n",
      "벡터 데이터베이스는 고차원 벡터를 저장하고 검색하는 시스템으로, 다양한 데이터 유형(텍스트, 이미지, 오디오 등)을 임베딩하여 의미적 유사성을 측정하는 데 사용됩니다. 이를 통해 사용자는 데이터 간의 관계를 보다 직관적으로 이해하고 활용할 수 있습니다. 예를 들어, 텍스트 데이터의 경우, 문서나 문장을 벡터로 변환하여 유사한 주제를 가진 문서를 쉽게 검색할 수 있습니다.\n",
      "\n",
      "### 2. 장점\n",
      "- **효율적인 검색**: 벡터 데이터베이스는 대량의 데이터를 빠르게 검색할 수 있는 구조를 가지고 있습니다. 예를 들어, FAISS는 대규모 데이터셋에서 유사한 벡터를 빠르게 찾을 수 있도록 최적화되어 있습니다.\n",
      "  \n",
      "- **의미적 유사성 측정**: 벡터 공간에서의 거리 계산을 통해 데이터 간의 의미적 유사성을 평가할 수 있습니다. 예를 들어, 이미지 검색 시스템에서 사용자가 특정 이미지를 업로드하면, 벡터 데이터베이스는 유사한 이미지를 찾아 반환할 수 있습니다.\n",
      "\n",
      "- **다양한 데이터 유형 지원**: 텍스트, 이미지, 오디오 등 다양한 데이터 유형을 지원하여, 여러 분야에서 활용할 수 있습니다. 예를 들어, Weaviate는 다양한 데이터 유형을 통합하여 의미적 검색을 가능하게 합니다.\n",
      "\n",
      "- **확장성**: 벡터 데이터베이스는 대규모 데이터셋을 처리할 수 있는 구조를 가지고 있어, 데이터가 증가하더라도 성능 저하 없이 운영할 수 있습니다. Pinecone은 클라우드 기반으로 확장성을 제공하여, 필요에 따라 리소스를 조정할 수 있습니다.\n",
      "\n",
      "### 결론\n",
      "벡터 데이터베이스는 고차원 벡터를 효율적으로 저장하고 검색하는 데 필수적인 역할을 하며, 데이터 간의 의미적 유사성을 측정할 수 있는 장점을 제공합니다. 이를 통해 다양한 데이터 유형을 효과적으로 관리하고 활용할 수 있는 기반을 마련해 줍니다. 이러한 특성 덕분에 벡터 데이터베이스는 인공지능, 머신러닝, 추천 시스템 등 다양한 분야에서 중요한 도구로 자리잡고 있습니다.\n",
      "--------------------------------------------------\n",
      "\n",
      "🔍 질문 4: LangChain 에이전트의 작동 원리를 설명하라\n",
      "------------------------------\n",
      "💡 응답: LangChain 에이전트의 작동 원리는 다음과 같은 단계로 구성됩니다:\n",
      "\n",
      "1. **입력 처리**: 에이전트는 사용자의 입력을 받아들입니다. 이 입력은 자연어 형태로 제공되며, 에이전트는 이를 이해하기 위해 임베딩 기술을 사용하여 입력을 고차원 벡터로 변환합니다. 이 과정에서 의미적 유사성을 파악할 수 있어, 에이전트는 입력의 맥락을 이해하게 됩니다.\n",
      "\n",
      "2. **계획 수립**: 입력이 처리된 후, 에이전트는 주어진 작업을 수행하기 위한 계획을 수립합니다. 이 단계에서는 사용자의 요구사항을 분석하고, 필요한 도구나 리소스를 결정합니다. 예를 들어, 사용자가 \"날씨를 알려줘\"라고 요청하면, 에이전트는 날씨 정보를 제공하기 위해 외부 API를 호출하는 계획을 세울 수 있습니다.\n",
      "\n",
      "3. **도구 선택**: 계획이 수립되면, 에이전트는 필요한 도구를 선택합니다. LangChain은 다양한 도구와 API를 통합할 수 있는 기능을 제공하므로, 에이전트는 상황에 맞는 최적의 도구를 선택하여 작업을 수행합니다. 예를 들어, 날씨 정보를 제공하기 위해 기상 API를 선택할 수 있습니다.\n",
      "\n",
      "4. **실행**: 선택된 도구를 사용하여 실제 작업을 수행합니다. 이 단계에서는 에이전트가 외부 API에 요청을 보내고, 그 결과를 받아옵니다. 예를 들어, 기상 API에 요청을 보내고, 현재 날씨 정보를 받아오는 과정이 포함됩니다.\n",
      "\n",
      "5. **결과 평가 및 피드백**: 작업이 완료되면, 에이전트는 결과를 평가하고 사용자가 원하는 정보가 정확하게 제공되었는지를 확인합니다. 만약 결과가 만족스럽지 않다면, 에이전트는 이전 단계로 돌아가 계획을 수정하거나 다른 도구를 선택할 수 있습니다. 이 사이클은 반복되며, 에이전트는 점점 더 나은 결과를 제공하기 위해 학습합니다.\n",
      "\n",
      "이러한 구조를 통해 LangChain 에이전트는 복잡한 작업을 효율적으로 수행할 수 있으며, 사용자의 요구에 맞춰 지속적으로 개선될 수 있습니다. 불확실한 정보는 에이전트가 외부 데이터에 의존하기 때문에, API의 가용성이나 정확성에 따라 결과가 달라질 수 있다는 점입니다.\n",
      "--------------------------------------------------\n",
      "\n",
      "💬 대화형 모드 (종료하려면 'quit' 입력)\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "질문을 입력하세요:  랭체인이 뭐지?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤔 답변 생성 중...\n",
      "\n",
      "💡 응답: 랭체인(LangChain)은 대형 언어 모델(LLM) 애플리케이션 개발을 위한 강력한 프레임워크입니다. 이 프레임워크는 개발자들이 다양한 AI 작업을 보다 효율적으로 수행할 수 있도록 돕는 여러 기능을 제공합니다. 주요 기능은 다음과 같습니다:\n",
      "\n",
      "1. **체인(Chain)**: 여러 작업을 순차적으로 연결하여 실행할 수 있는 기능입니다. 예를 들어, 사용자가 질문을 입력하면, 랭체인은 질문을 이해하고 정보를 검색한 후 최종적으로 답변을 생성하는 과정을 체인으로 구성할 수 있습니다.\n",
      "\n",
      "2. **에이전트(Agent)**: 특정 작업을 수행하기 위해 필요한 여러 단계를 자동으로 처리하는 기능입니다. 고객 지원 챗봇을 개발할 때, 에이전트는 사용자의 질문을 분석하고 적절한 답변을 찾거나 필요한 경우 다른 시스템에 연결하여 정보를 가져오는 등의 작업을 수행할 수 있습니다.\n",
      "\n",
      "3. **메모리(Memory)**: 이전의 대화나 작업 내용을 기억하여 사용자와의 상호작용을 개인화하고 일관되게 만들어 줍니다. 예를 들어, 사용자가 이전에 문의했던 내용을 기억하고 후속 질문을 할 때 더 정확하고 관련성 높은 답변을 제공할 수 있습니다.\n",
      "\n",
      "이러한 기능들을 통해 랭체인은 개발자들이 복잡한 AI 애플리케이션을 보다 쉽게 구축하고 관리할 수 있도록 지원합니다. 자연어 처리(NLP)와 관련된 다양한 프로젝트에서 유용하게 사용될 수 있으며, 자동화된 고객 서비스, 콘텐츠 생성, 데이터 분석 등의 분야에서 활용될 수 있습니다. \n",
      "\n",
      "결론적으로, 랭체인은 LLM을 활용한 애플리케이션 개발을 위한 유용한 도구로, 다양한 기능을 통해 개발자들이 보다 효율적으로 작업할 수 있도록 돕습니다.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "질문을 입력하세요:  RAG의 기능은?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤔 답변 생성 중...\n",
      "\n",
      "💡 응답: RAG(Retrieval-Augmented Generation)의 기능은 주로 두 가지로 요약할 수 있습니다: 정보 검색과 생성 모델의 결합을 통한 응답의 정확성 및 신뢰성 향상입니다. 이를 통해 RAG는 사용자가 요청하는 정보에 대해 보다 포괄적이고 신뢰할 수 있는 답변을 제공합니다.\n",
      "\n",
      "1. **정보 검색 기능**: RAG는 사용자의 쿼리에 대해 관련된 정보를 검색하는 기능을 가지고 있습니다. 예를 들어, 사용자가 \"기후 변화의 원인\"에 대한 질문을 했을 때, RAG는 다양한 데이터베이스나 문서에서 기후 변화와 관련된 정보를 검색하여 그 결과를 기반으로 응답을 생성합니다. 이 과정에서 여러 관점의 정보를 수집하여 보다 균형 잡힌 답변을 제공합니다.\n",
      "\n",
      "2. **응답 생성 기능**: 검색된 정보를 바탕으로 RAG는 자연어 생성 모델을 활용하여 사용자가 이해하기 쉬운 형태로 응답을 작성합니다. 예를 들어, 검색된 정보가 \"온실가스 배출\", \"산업화\", \"산림 파괴\"와 같은 여러 원인에 대한 내용이라면, RAG는 이를 종합하여 \"기후 변화는 주로 온실가스 배출, 산업화, 그리고 산림 파괴와 같은 여러 요인에 의해 발생합니다.\"와 같은 형태로 응답을 생성할 수 있습니다.\n",
      "\n",
      "결론적으로, RAG는 정보 검색과 생성의 두 가지 기능을 결합하여 사용자가 원하는 정보를 보다 정확하고 신뢰성 있게 제공하는 기술입니다. 이러한 기능은 특히 복잡한 질문에 대한 답변을 요구하는 상황에서 유용하게 활용될 수 있습니다.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "질문을 입력하세요:  임베딩은?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤔 답변 생성 중...\n",
      "\n",
      "💡 응답: 임베딩(Embedding)은 텍스트, 이미지, 오디오 등 다양한 형태의 데이터를 고차원 벡터로 변환하는 기술입니다. 이 과정에서 각 데이터는 특정한 의미를 가지는 벡터로 표현되며, 이러한 벡터는 데이터 간의 의미적 유사성을 벡터 공간에서 측정할 수 있게 해줍니다. 즉, 비슷한 의미를 가진 데이터는 벡터 공간에서 가까운 위치에 배치되고, 서로 다른 의미를 가진 데이터는 멀리 떨어지게 됩니다.\n",
      "\n",
      "### 구체적인 예시\n",
      "예를 들어, \"고양이\"와 \"강아지\"라는 단어의 임베딩 벡터는 서로 가까운 위치에 있을 것입니다. 반면 \"고양이\"와 \"자동차\"의 벡터는 멀리 떨어져 있을 것입니다. 이러한 임베딩은 자연어 처리(NLP) 분야에서 단어의 의미를 이해하고, 문장 간의 유사성을 평가하는 데 매우 유용합니다.\n",
      "\n",
      "### 임베딩의 활용\n",
      "임베딩은 검색 엔진, 추천 시스템, 감정 분석 등 다양한 분야에서 활용됩니다. 예를 들어, 추천 시스템에서는 사용자의 과거 행동 데이터를 임베딩하여 비슷한 취향을 가진 다른 사용자와의 유사성을 기반으로 콘텐츠를 추천할 수 있습니다.\n",
      "\n",
      "### 벡터 데이터베이스\n",
      "임베딩된 벡터를 효율적으로 저장하고 검색하기 위해 벡터 데이터베이스가 사용됩니다. FAISS, Pinecone, Weaviate와 같은 시스템은 대량의 고차원 벡터를 빠르게 검색할 수 있는 기능을 제공합니다. 이러한 데이터베이스는 대규모 데이터셋에서 유사한 항목을 찾는 데 필수적입니다.\n",
      "\n",
      "결론적으로, 임베딩은 데이터의 의미를 수치적으로 표현하고, 이를 통해 다양한 응용 프로그램에서 데이터 간의 관계를 이해하고 활용할 수 있게 해주는 중요한 기술입니다.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "질문을 입력하세요:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👋 프로그램을 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "🔸 LangChain v1.0 기준 Fusion RAG + Answer Refine Agent 예제\n",
    "검색 결과 융합(RAG Fusion)과 응답 품질 향상 에이전트 구현\n",
    "\n",
    "주요 기능:\n",
    "1. Fusion RAG: 여러 쿼리로 검색하여 결과를 융합\n",
    "2. Answer Refine Agent: 융합된 문맥을 기반으로 고품질 응답 생성\n",
    "3. LangChain v1.0 에이전트 프레임워크 활용\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "class FusionRAGAgent:\n",
    "    \"\"\"Fusion RAG와 Answer Refine Agent를 결합한 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"gpt-4o-mini\", embedding_model: str = \"text-embedding-3-small\"):\n",
    "        \"\"\"\n",
    "        Fusion RAG Agent 초기화\n",
    "        \n",
    "        Args:\n",
    "            model_name: 사용할 LLM 모델명\n",
    "            embedding_model: 사용할 임베딩 모델명\n",
    "        \"\"\"\n",
    "        self.llm = ChatOpenAI(model=model_name, temperature=0.2)\n",
    "        self.embeddings = OpenAIEmbeddings(model=embedding_model)\n",
    "        self.vectorstore = None\n",
    "        self.agent = None\n",
    "        \n",
    "    def setup_knowledge_base(self, documents: List[Document]):\n",
    "        \"\"\"\n",
    "        지식 베이스 설정\n",
    "        \n",
    "        Args:\n",
    "            documents: 벡터스토어에 저장할 문서 리스트\n",
    "        \"\"\"\n",
    "        print(\"📚 지식 베이스 구축 중...\")\n",
    "        self.vectorstore = FAISS.from_documents(documents, self.embeddings)\n",
    "        print(f\"✅ {len(documents)}개 문서가 벡터스토어에 저장되었습니다.\")\n",
    "        \n",
    "    def create_fusion_rag_tool(self):\n",
    "        \"\"\"Fusion RAG 검색 도구 생성\"\"\"\n",
    "        \n",
    "        @tool\n",
    "        def fusion_rag_search(query: str) -> str:\n",
    "            \"\"\"\n",
    "            Fusion RAG 방식으로 여러 쿼리 검색 결과를 융합하여 문맥을 반환한다.\n",
    "            \n",
    "            Args:\n",
    "                query: 검색할 질문\n",
    "                \n",
    "            Returns:\n",
    "                융합된 문맥 정보\n",
    "            \"\"\"\n",
    "            if not self.vectorstore:\n",
    "                return \"벡터스토어가 초기화되지 않았습니다.\"\n",
    "                \n",
    "            retriever = self.vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "            \n",
    "            # 다양한 관점의 서브 쿼리 생성\n",
    "            sub_queries = [\n",
    "                query,\n",
    "                f\"{query} 관련 개념을 설명하라\",\n",
    "                f\"{query}의 작동 원리를 요약하라\",\n",
    "                f\"{query}의 장단점은 무엇인가\",\n",
    "                f\"{query}의 실제 활용 사례는 무엇인가\"\n",
    "            ]\n",
    "            \n",
    "            all_results = []\n",
    "            for q in sub_queries:\n",
    "                try:\n",
    "                    results = retriever.invoke(q)\n",
    "                    all_results.extend(results)\n",
    "                except Exception as e:\n",
    "                    print(f\"쿼리 '{q}' 검색 중 오류: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # 중복 제거 및 문맥 융합\n",
    "            unique_texts = list({d.page_content for d in all_results})\n",
    "            fused_context = \"\\n\".join(unique_texts)\n",
    "            \n",
    "            return f\"[융합 문맥]\\n{fused_context}\\n\\n[검색된 문서 수: {len(unique_texts)}개]\"\n",
    "        \n",
    "        return fusion_rag_search\n",
    "    \n",
    "    def create_answer_refiner_tool(self):\n",
    "        \"\"\"응답 품질 향상 도구 생성\"\"\"\n",
    "        \n",
    "        @tool\n",
    "        def answer_refiner(context: str, question: str) -> str:\n",
    "            \"\"\"\n",
    "            Fusion된 문맥을 기반으로 고품질 응답을 생성한다.\n",
    "            \n",
    "            Args:\n",
    "                context: 융합된 문맥 정보\n",
    "                question: 원본 질문\n",
    "                \n",
    "            Returns:\n",
    "                개선된 응답\n",
    "            \"\"\"\n",
    "            prompt = f\"\"\"\n",
    "            아래 문맥을 참고하여 질문에 대해 명확하고 근거 있는 답변을 작성하라.\n",
    "            \n",
    "            답변 작성 시 다음 사항을 고려하라:\n",
    "            1. 문맥의 정보를 충분히 활용하라\n",
    "            2. 구체적이고 실용적인 예시를 포함하라\n",
    "            3. 명확한 구조로 답변을 구성하라\n",
    "            4. 불확실한 정보는 명시하라\n",
    "            \n",
    "            [문맥]\n",
    "            {context}\n",
    "            \n",
    "            [질문]\n",
    "            {question}\n",
    "            \n",
    "            답변:\n",
    "            \"\"\"\n",
    "            \n",
    "            try:\n",
    "                response = self.llm.invoke(prompt)\n",
    "                return response.content\n",
    "            except Exception as e:\n",
    "                return f\"응답 생성 중 오류가 발생했습니다: {e}\"\n",
    "        \n",
    "        return answer_refiner\n",
    "    \n",
    "    def create_agent(self):\n",
    "        \"\"\"Fusion RAG 에이전트 생성\"\"\"\n",
    "        \n",
    "        # 도구 생성\n",
    "        fusion_rag_tool = self.create_fusion_rag_tool()\n",
    "        answer_refiner_tool = self.create_answer_refiner_tool()\n",
    "        \n",
    "        # 시스템 프롬프트 정의\n",
    "        system_prompt = \"\"\"\n",
    "        당신은 Fusion RAG와 Answer Refine Agent를 활용하는 지능형 질의응답 시스템입니다.\n",
    "        \n",
    "        작업 순서:\n",
    "        1. 사용자의 질문을 분석한다\n",
    "        2. fusion_rag_search 도구를 사용해 관련 문맥을 검색하고 융합한다\n",
    "        3. answer_refiner 도구를 사용해 융합된 문맥을 기반으로 고품질 응답을 생성한다\n",
    "        4. 최종 응답을 사용자에게 제공한다\n",
    "        \n",
    "        항상 근거 있는 답변을 제공하고, 불확실한 정보는 명시하라.\n",
    "        \"\"\"\n",
    "        \n",
    "        # 에이전트 생성\n",
    "        self.agent = create_agent(\n",
    "            model=self.llm,\n",
    "            tools=[fusion_rag_tool, answer_refiner_tool],\n",
    "            system_prompt=system_prompt\n",
    "        )\n",
    "        \n",
    "        print(\"🤖 Fusion RAG 에이전트가 생성되었습니다.\")\n",
    "    \n",
    "    def query(self, question: str) -> str:\n",
    "        \"\"\"\n",
    "        질문에 대한 응답 생성\n",
    "        \n",
    "        Args:\n",
    "            question: 사용자 질문\n",
    "            \n",
    "        Returns:\n",
    "            에이전트의 응답\n",
    "        \"\"\"\n",
    "        if not self.agent:\n",
    "            return \"에이전트가 초기화되지 않았습니다. create_agent()를 먼저 호출하세요.\"\n",
    "        \n",
    "        try:\n",
    "            result = self.agent.invoke({\n",
    "                \"messages\": [\n",
    "                    HumanMessage(content=question)\n",
    "                ]\n",
    "            })\n",
    "            \n",
    "            # 마지막 AI 메시지의 내용 반환\n",
    "            for message in reversed(result[\"messages\"]):\n",
    "                if isinstance(message, AIMessage):\n",
    "                    return message.content\n",
    "            \n",
    "            return \"응답을 생성할 수 없습니다.\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"질의응답 처리 중 오류가 발생했습니다: {e}\"\n",
    "\n",
    "\n",
    "def create_sample_documents() -> List[Document]:\n",
    "    \"\"\"샘플 문서 생성\"\"\"\n",
    "    return [\n",
    "        Document(page_content=\"인공지능(AI)은 인간의 학습 능력과 추론을 모방하는 기술이다. 머신러닝, 딥러닝, 자연어처리 등의 하위 분야를 포함한다.\"),\n",
    "        Document(page_content=\"머신러닝은 데이터를 이용해 스스로 패턴을 학습하는 인공지능의 한 분야이다. 지도학습, 비지도학습, 강화학습으로 분류된다.\"),\n",
    "        Document(page_content=\"RAG(Retrieval-Augmented Generation)는 검색과 생성 모델을 결합해 응답의 정확성과 신뢰성을 높이는 기술이다.\"),\n",
    "        Document(page_content=\"Fusion RAG는 여러 검색 결과를 결합해 응답 품질을 높이는 방법이다. 다양한 관점의 쿼리를 통해 더 포괄적인 정보를 수집한다.\"),\n",
    "        Document(page_content=\"벡터 데이터베이스는 고차원 벡터를 효율적으로 저장하고 검색하는 시스템이다. FAISS, Pinecone, Weaviate 등이 대표적이다.\"),\n",
    "        Document(page_content=\"임베딩은 텍스트를 고차원 벡터로 변환하는 기술이다. 의미적 유사성을 벡터 공간에서 측정할 수 있게 해준다.\"),\n",
    "        Document(page_content=\"LangChain은 LLM 애플리케이션 개발을 위한 프레임워크이다. 체인, 에이전트, 메모리 등의 기능을 제공한다.\"),\n",
    "        Document(page_content=\"에이전트는 도구를 사용해 복잡한 작업을 수행하는 AI 시스템이다. 계획 수립, 도구 선택, 실행, 평가의 사이클을 반복한다.\"),\n",
    "    ]\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    print(\"🚀 Fusion RAG + Answer Refine Agent 예제 시작\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Fusion RAG Agent 초기화\n",
    "    agent = FusionRAGAgent()\n",
    "    \n",
    "    # 2. 샘플 문서로 지식 베이스 구축\n",
    "    documents = create_sample_documents()\n",
    "    agent.setup_knowledge_base(documents)\n",
    "    \n",
    "    # 3. 에이전트 생성\n",
    "    agent.create_agent()\n",
    "    \n",
    "    # 4. 테스트 질문들\n",
    "    test_questions = [\n",
    "        \"RAG Fusion이 무엇이며 응답 품질을 어떻게 향상시키는가?\",\n",
    "        \"머신러닝과 딥러닝의 차이점은 무엇인가?\",\n",
    "        \"벡터 데이터베이스의 역할과 장점은 무엇인가?\",\n",
    "        \"LangChain 에이전트의 작동 원리를 설명하라\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n📝 테스트 질문 실행\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, question in enumerate(test_questions, 1):\n",
    "        print(f\"\\n🔍 질문 {i}: {question}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        response = agent.query(question)\n",
    "        print(f\"💡 응답: {response}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # 5. 대화형 모드\n",
    "    print(\"\\n💬 대화형 모드 (종료하려면 'quit' 입력)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"\\n질문을 입력하세요: \").strip()\n",
    "            \n",
    "            if user_input.lower() in ['quit', 'exit', '종료']:\n",
    "                print(\"👋 프로그램을 종료합니다.\")\n",
    "                break\n",
    "            \n",
    "            if not user_input:\n",
    "                continue\n",
    "                \n",
    "            print(\"\\n🤔 답변 생성 중...\")\n",
    "            response = agent.query(user_input)\n",
    "            print(f\"\\n💡 응답: {response}\")\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n👋 프로그램을 종료합니다.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ 오류가 발생했습니다: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# 질문 예시\n",
    "# 랭체인이 뭐지?\n",
    "# RAG의 기능은?\n",
    "# 임베딩은?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee7b4fa-1d98-4517-aac2-18585c6404f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
