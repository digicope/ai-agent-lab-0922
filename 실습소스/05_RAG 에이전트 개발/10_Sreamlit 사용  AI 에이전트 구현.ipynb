{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52664426-8bab-4298-b3af-c61b1f1159d7",
   "metadata": {},
   "source": [
    "# Sreamlit ì‚¬ìš© ì›¹ ì±—ë´‡ê³¼ AI ì—ì´ì „íŠ¸ êµ¬í˜„\n",
    "\n",
    "- Streamlitì€ íŒŒì´ì¬ë§Œìœ¼ë¡œ ëŒ€í™”í˜• ì›¹ ì•±ì„ ì‰½ê²Œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ì˜¤í”ˆì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬ì´ë‹¤. <br>\n",
    "ë²„íŠ¼, ìŠ¬ë¼ì´ë”, ì…ë ¥ì°½ ê°™ì€ UIë¥¼ ê°„ë‹¨í•œ ì½”ë“œë¡œ ì¶”ê°€í•  ìˆ˜ ìˆê³  ë°ì´í„° ì‹œê°í™”ë„ ë°”ë¡œ ì§€ì›í•œë‹¤. <br>\n",
    "streamlit run app.py ëª…ë ¹ìœ¼ë¡œ ë¡œì»¬ ì›¹ ì„œë²„ë¥¼ ì‹¤í–‰í•´ ê²°ê³¼ë¥¼ ë¸Œë¼ìš°ì €ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.<br>\n",
    "\n",
    "- https://streamlit.io/  <br>\n",
    "https://velog.io/@euisuk-chung/Streamlit-%EC%86%8C%EA%B0%9C-%EB%B0%8F-%ED%99%9C%EC%9A%A9-%EA%B0%80%EC%9D%B4%EB%93%9C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b81fe6-11eb-4d85-b8d7-f14f1ef70ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# streamlit ëª¨ë“ˆ ì„¤ì¹˜\n",
    "# ! pip install streamlit\n",
    "\n",
    "# ì½”ë“œ ì‹¤í–‰ ë°©ë²• : Jupyter Notebookì—ì„œëŠ” ì‹¤í–‰ ì•ˆë˜ê³  í„°ë¯¸ë„ ì°½(Anaconda Prompt)ì—ì„œë§Œ ì‹¤í–‰ ê°€ëŠ¥\n",
    "# ì‹¤í–‰ ëª…ë ¹ ì˜ˆ) streamlit run streamlit_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a535b9b7-822a-4db6-94a4-c54db8be2c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "# import os\n",
    "\n",
    "# # .env íŒŒì¼ì˜ ë‚´ìš© ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# load_dotenv(\"C:/env/.env\")\n",
    "\n",
    "# # í™˜ê²½ ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°\n",
    "# API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# from openai import OpenAI\n",
    "# client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0eb4698-2ce0-447b-914f-f7f1dfaf50c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting streamlit_test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile streamlit_test.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env íŒŒì¼ì˜ ë‚´ìš© ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "load_dotenv(\"C:/env/.env\")\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "# ======================\n",
    "# 1. OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "# ======================\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "# ======================\n",
    "# 2. Streamlit í˜ì´ì§€ ì„¤ì •\n",
    "# ======================\n",
    "st.set_page_config(page_title=\"OpenAI Chatbot\", page_icon=\"ğŸ¤–\", layout=\"centered\")\n",
    "st.title(\"ğŸ¤– OpenAI Chatbot with Streamlit\")\n",
    "st.markdown(\"ê°„ë‹¨í•œ **ëŒ€í™”í˜• ì±—ë´‡** ì˜ˆì œì…ë‹ˆë‹¤. ëª¨ë¸ ì„ íƒ, temperature ì¡°ì ˆ, ëŒ€í™” ê¸°ë¡ ì €ì¥ ê¸°ëŠ¥ì„ í¬í•¨í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# ======================\n",
    "# 3. ì‚¬ì´ë“œë°” ì˜µì…˜\n",
    "# ======================\n",
    "st.sidebar.header(\"âš™ï¸ ì„¤ì •\")\n",
    "model = st.sidebar.selectbox(\n",
    "    \"ëª¨ë¸ ì„ íƒ\",\n",
    "    [\"gpt-4o-mini\", \"gpt-4o\", \"gpt-3.5-turbo\"],\n",
    "    index=0\n",
    ")\n",
    "temperature = st.sidebar.slider(\"ì°½ì˜ì„± (temperature)\", 0.0, 1.5, 0.7, 0.1)\n",
    "max_tokens = st.sidebar.slider(\"ìµœëŒ€ í† í° ìˆ˜\", 50, 1000, 300, 50)\n",
    "\n",
    "# ======================\n",
    "# 4. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ëŒ€í™” ê¸°ë¡)\n",
    "# ======================\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# ======================\n",
    "# 5. ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ì¶œë ¥\n",
    "# ======================\n",
    "for msg in st.session_state.messages:\n",
    "    with st.chat_message(msg[\"role\"]):\n",
    "        st.markdown(msg[\"content\"])\n",
    "\n",
    "# ======================\n",
    "# 6. ì‚¬ìš©ì ì…ë ¥\n",
    "# ======================\n",
    "if user_input := st.chat_input(\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...\"):\n",
    "    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(user_input)\n",
    "\n",
    "    # OpenAI API í˜¸ì¶œ\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"ğŸ¤” ë‹µë³€ ìƒì„± ì¤‘...\"):\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": m[\"role\"], \"content\": m[\"content\"]} for m in st.session_state.messages],\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens\n",
    "            )\n",
    "            answer = response.choices[0].message.content\n",
    "            st.markdown(answer)\n",
    "\n",
    "    # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì €ì¥\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "\n",
    "    # í† í° ì‚¬ìš©ëŸ‰ í‘œì‹œ\n",
    "    if hasattr(response, \"usage\"):\n",
    "        st.sidebar.markdown(\"---\")\n",
    "        st.sidebar.markdown(f\"**ğŸ”¢ ì‚¬ìš©ëœ í† í°**\")\n",
    "        st.sidebar.markdown(f\"- prompt_tokens: {response.usage.prompt_tokens}\")\n",
    "        st.sidebar.markdown(f\"- completion_tokens: {response.usage.completion_tokens}\")\n",
    "        st.sidebar.markdown(f\"- total_tokens: {response.usage.total_tokens}\")\n",
    "\n",
    "# ìœˆë„ìš° íƒìƒ‰ê¸°ì—ì„œ C:/ ê²½ë¡œì— streamlit_test.py íŒŒì¼ì„ ë³µì‚¬\n",
    "# Anaconda Prompt ì‹¤í–‰\n",
    "# cd c:/\n",
    "# streamlit run streamlit_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a859d412-8fd7-477d-8645-41552c702748",
   "metadata": {},
   "source": [
    "### Streamlit ìœ¼ë¡œ Langchain ì—ì´ì „íŠ¸ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97ceb998-1890-4ba2-9ee4-0139363831c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting streamlit_langchain_test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile streamlit_langchain_test.py\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import streamlit as st\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 0. í™˜ê²½ì„¤ì •\n",
    "# -------------------------------------------------------\n",
    "load_dotenv(\"C:/env/.env\")\n",
    "\n",
    "st.set_page_config(page_title=\"LangChain AI Agent Web App\", page_icon=\"ğŸ¤–\")\n",
    "st.title(\"ğŸ¤– LangChain AI Agent Web App\")\n",
    "st.markdown(\"LangChain v1.0 + Streamlit ì˜ˆì œ\")\n",
    "\n",
    "user_input = st.text_input(\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:\", \"\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 1. Tool ì •ì˜\n",
    "# -------------------------------------------------------\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"ë‘ ìˆ˜ë¥¼ ê³±í•œ ê°’ì„ ë°˜í™˜í•œë‹¤.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"ë„ì‹œ ì´ë¦„ì„ ë°›ì•„ ì˜ˆì‹œìš© ë‚ ì”¨ë¥¼ ë°˜í™˜í•œë‹¤.\"\"\"\n",
    "    return f\"{city}ì˜ ë‚ ì”¨ëŠ” ë§‘ìŒì´ë‹¤.\"\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2. LLM ë° ì—ì´ì „íŠ¸ êµ¬ì„±\n",
    "# -------------------------------------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[multiply, get_weather],\n",
    "    system_prompt=(\n",
    "        \"ë„ˆëŠ” ì‚¬ìš©ìì˜ ìš”ì²­ì„ í•´ê²°í•˜ê¸° ìœ„í•´ í•„ìš”ì‹œ ì œê³µëœ ë„êµ¬ë¥¼ ë°˜ë“œì‹œ í˜¸ì¶œí•´ì•¼ í•˜ëŠ” ì—ì´ì „íŠ¸ì´ë‹¤. \"\n",
    "        \"ë„êµ¬ë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì§€ ì•Šê³  ì„ì˜ë¡œ ê²°ê³¼ë¥¼ ë§Œë“¤ì–´ë‚´ì§€ ì•ŠëŠ”ë‹¤.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3. ì‹¤í–‰ ë° ì¶œë ¥\n",
    "# -------------------------------------------------------\n",
    "if st.button(\"ì—ì´ì „íŠ¸ ì‹¤í–‰\") and user_input.strip():\n",
    "    with st.spinner(\"ì—ì´ì „íŠ¸ê°€ ì‘ë‹µ ì¤‘ì…ë‹ˆë‹¤...\"):\n",
    "        result = agent.invoke({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": user_input}\n",
    "            ]\n",
    "        })\n",
    "        st.subheader(\"ê²°ê³¼:\")\n",
    "        st.write(result[\"messages\"][-1].content)\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ:\n",
    "#  \"ë¶€ì‚°ì˜ ë‚ ì”¨ë¥¼ ì•Œë ¤ì¤˜\"\n",
    "#  \"2ì™€ 5ë¥¼ ê³±í•œ ê²°ê³¼ëŠ”?\"\n",
    "#  \"ì„œìš¸ì˜ ë‚ ì”¨ì™€ 3Ã—7 ê²°ê³¼ë¥¼ ì•Œë ¤ì¤˜\"\n",
    "\n",
    "# ìœˆë„ìš° íƒìƒ‰ê¸°ì—ì„œ C:/ ê²½ë¡œì— streamlit_langchain_test.py íŒŒì¼ì„ ë³µì‚¬  \n",
    "# Anaconda Prompt ì‹¤í–‰\n",
    "# cd c:/\n",
    "# streamlit run streamlit_langchain_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee2f9e7-95a9-45ee-90da-b31d7a0e4385",
   "metadata": {},
   "source": [
    "## Streamlit ì‚¬ìš©í”¼ë“œë°± ë£¨í”„í˜• ì›Œí¬í”Œë¡œìš° ì—ì´ì „íŠ¸ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4a10696-4f67-4097-9c1f-162291c50600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing agents_feedback_graph.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile agents_feedback_graph.py\n",
    "\n",
    "# agents_feedback_graph.py\n",
    "# ==============================================================\n",
    "# LangGraph ê¸°ë°˜ í”¼ë“œë°± ë£¨í”„í˜• ì›Œí¬í”Œë¡œìš°\n",
    "# ==============================================================\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# í™˜ê²½ ì„¤ì •\n",
    "load_dotenv(\"C:/env/.env\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ìƒíƒœ ì •ì˜\n",
    "# --------------------------------------------------------------\n",
    "class AgentState(TypedDict):\n",
    "    idea: str\n",
    "    analysis: str\n",
    "    content: str\n",
    "    review: str\n",
    "    feedback: str\n",
    "    revised: str\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Analyzer Node\n",
    "# --------------------------------------------------------------\n",
    "def analyzer_node(state: AgentState) -> AgentState:\n",
    "    prompt = f\"\"\"\n",
    "    ë‹¤ìŒ ì•„ì´ë””ì–´ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ê³ , í•µì‹¬ í‚¤ì›Œë“œ 3ê°œë¥¼ ì¶”ì¶œí•˜ë¼.\n",
    "    ì•„ì´ë””ì–´: {state['idea']}\n",
    "    \"\"\"\n",
    "    result = llm.invoke(prompt)\n",
    "    state[\"analysis\"] = result.content.strip()\n",
    "    return state\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Writer Node (1ì°¨ ì‘ì„±)\n",
    "# --------------------------------------------------------------\n",
    "def writer_node(state: AgentState) -> AgentState:\n",
    "    prompt = f\"\"\"\n",
    "    ì•„ë˜ ë¶„ì„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ 3ë¬¸ì¥ ì´ë‚´ì˜ í™ë³´ ë¬¸êµ¬ë¥¼ ì‘ì„±í•˜ë¼:\n",
    "    {state['analysis']}\n",
    "    \"\"\"\n",
    "    result = llm.invoke(prompt)\n",
    "    state[\"content\"] = result.content.strip()\n",
    "    return state\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Reviewer Node (1ì°¨ í‰ê°€)\n",
    "# --------------------------------------------------------------\n",
    "def reviewer_node(state: AgentState) -> AgentState:\n",
    "    prompt = f\"\"\"\n",
    "    ë‹¤ìŒ ë¬¸êµ¬ë¥¼ í‰ê°€í•˜ë¼.\n",
    "    - ëª…í™•ì„± (0~10)\n",
    "    - ì°½ì˜ì„± (0~10)\n",
    "    - ë¬¸ë²• ì •í™•ë„ (0~10)\n",
    "    - ê°œì„  ì œì•ˆì„ 1ë¬¸ì¥ìœ¼ë¡œ ì œì‹œí•˜ë¼.\n",
    "    ë¬¸êµ¬:\n",
    "    {state['content']}\n",
    "    \"\"\"\n",
    "    result = llm.invoke(prompt)\n",
    "    review_text = result.content.strip()\n",
    "    state[\"review\"] = review_text\n",
    "    # ê°œì„  ì œì•ˆë§Œ ì¶”ì¶œ\n",
    "    state[\"feedback\"] = review_text.split(\"\\n\")[-1]\n",
    "    return state\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Writer Node (í”¼ë“œë°± ë°˜ì˜ ì¬ì‘ì„±)\n",
    "# --------------------------------------------------------------\n",
    "def rewriter_node(state: AgentState) -> AgentState:\n",
    "    prompt = f\"\"\"\n",
    "    ë‹¤ìŒ í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ë¬¸êµ¬ë¥¼ ê°œì„ í•˜ë¼.\n",
    "    ê¸°ì¡´ ë¬¸êµ¬:\n",
    "    {state['content']}\n",
    "\n",
    "    í”¼ë“œë°±:\n",
    "    {state['feedback']}\n",
    "    \"\"\"\n",
    "    result = llm.invoke(prompt)\n",
    "    state[\"revised\"] = result.content.strip()\n",
    "    return state\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Reviewer Node (ìµœì¢… í‰ê°€)\n",
    "# --------------------------------------------------------------\n",
    "def final_reviewer_node(state: AgentState) -> AgentState:\n",
    "    prompt = f\"\"\"\n",
    "    ì•„ë˜ ìˆ˜ì •ëœ ë¬¸êµ¬ë¥¼ ë‹¤ì‹œ í‰ê°€í•˜ë¼.\n",
    "    - ëª…í™•ì„± / ì°½ì˜ì„± / ë¬¸ë²• ì •í™•ë„ ì ìˆ˜ë¥¼ ë‹¤ì‹œ ì œì‹œí•˜ë¼.\n",
    "    ë¬¸êµ¬:\n",
    "    {state['revised']}\n",
    "    \"\"\"\n",
    "    result = llm.invoke(prompt)\n",
    "    state[\"review\"] += \"\\n\\n[ìµœì¢… í‰ê°€]\\n\" + result.content.strip()\n",
    "    return state\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# LangGraph êµ¬ì„± (í”¼ë“œë°± ë£¨í”„ í¬í•¨)\n",
    "# --------------------------------------------------------------\n",
    "def build_feedback_workflow():\n",
    "    graph = StateGraph(AgentState)\n",
    "\n",
    "    graph.add_node(\"analyzer\", RunnableLambda(analyzer_node))\n",
    "    graph.add_node(\"writer\", RunnableLambda(writer_node))\n",
    "    graph.add_node(\"reviewer\", RunnableLambda(reviewer_node))\n",
    "    graph.add_node(\"rewriter\", RunnableLambda(rewriter_node))\n",
    "    graph.add_node(\"final_reviewer\", RunnableLambda(final_reviewer_node))\n",
    "\n",
    "    # íë¦„ ì—°ê²°\n",
    "    graph.add_edge(\"analyzer\", \"writer\")\n",
    "    graph.add_edge(\"writer\", \"reviewer\")\n",
    "    graph.add_edge(\"reviewer\", \"rewriter\")         # ë¦¬ë·° í›„ í”¼ë“œë°± ë°˜ì˜\n",
    "    graph.add_edge(\"rewriter\", \"final_reviewer\")   # ê°œì„  í›„ ìµœì¢… í‰ê°€\n",
    "    graph.set_entry_point(\"analyzer\")\n",
    "    graph.set_finish_point(\"final_reviewer\")\n",
    "\n",
    "    return graph.compile()\n",
    "\n",
    "feedback_workflow = build_feedback_workflow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26fbdc67-231e-4914-82e1-ff4cbb22dfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app_streamlit.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app_streamlit.py\n",
    "\n",
    "# app_streamlit.py\n",
    "import streamlit as st\n",
    "from agents_feedback_graph import feedback_workflow\n",
    "\n",
    "# í˜ì´ì§€ ì„¤ì •\n",
    "st.set_page_config(page_title=\"LangGraph í”¼ë“œë°± ë£¨í”„ ì—ì´ì „íŠ¸\", layout=\"centered\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# âœ¨ ì»¤ìŠ¤í…€ CSS (í°íŠ¸ í¬ê¸°, ì¤‘ì•™ ì •ë ¬, ì¤„ê°„ê²© ê°œì„ )\n",
    "# ------------------------------------------------------------\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    "    /* ì œëª© ì „ì²´ ì •ë ¬ */\n",
    "    .main-title {\n",
    "        text-align: center;\n",
    "        font-size: 2rem;             /* ê¸°ì¡´ë³´ë‹¤ ì‘ê²Œ */\n",
    "        font-weight: 700;\n",
    "        margin-bottom: 0.2em;\n",
    "        line-height: 1.2;\n",
    "    }\n",
    "\n",
    "    /* ë¶€ì œëª©(ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ í‘œì‹œ) */\n",
    "    .subtitle {\n",
    "        text-align: center;\n",
    "        font-size: 0.9rem;\n",
    "        color: #6c757d;\n",
    "        margin-bottom: 1.5em;\n",
    "    }\n",
    "\n",
    "    /* ì…ë ¥ ì•ˆë‚´ ë¬¸êµ¬ */\n",
    "    label[data-testid=\"stTextAreaLabel\"] {\n",
    "        font-weight: 600;\n",
    "        font-size: 1rem;\n",
    "    }\n",
    "\n",
    "    /* ë²„íŠ¼ ê°€ìš´ë° ì •ë ¬ */\n",
    "    div.stButton > button {\n",
    "        display: block;\n",
    "        margin: 0 auto;\n",
    "        width: 180px;\n",
    "    }\n",
    "\n",
    "    /* ê²°ê³¼ ì˜ì—­ ê°œì„  */\n",
    "    .stSuccess {\n",
    "        text-align: center;\n",
    "    }\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# ì œëª© + ë¶€ì œëª©\n",
    "# ------------------------------------------------------------\n",
    "st.markdown('<h1 class=\"main-title\">ğŸ”„ LangGraph í”¼ë“œë°± ë£¨í”„ ê¸°ë°˜ AI ì—ì´ì „íŠ¸</h1>', unsafe_allow_html=True)\n",
    "st.markdown('<div class=\"subtitle\">Analyzer â†’ Writer â†’ Reviewer â†’ Rewriter â†’ Final Reviewer ìˆœì„œë¡œ ìë™ ì‹¤í–‰</div>', unsafe_allow_html=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# ì…ë ¥ ì˜ì—­\n",
    "# ------------------------------------------------------------\n",
    "user_input = st.text_area(\"ğŸ’¡ ì•„ì´ë””ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”:\", height=100)\n",
    "\n",
    "if st.button(\"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰\"):\n",
    "    if not user_input.strip():\n",
    "        st.warning(\"ì•„ì´ë””ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "    else:\n",
    "        with st.spinner(\"ì—ì´ì „íŠ¸ê°€ í˜‘ì—… ì¤‘ì…ë‹ˆë‹¤...\"):\n",
    "            state = {\"idea\": user_input}\n",
    "\n",
    "            for event in feedback_workflow.stream(state):\n",
    "                if isinstance(event, tuple) and len(event) == 2:\n",
    "                    step, output = event\n",
    "                else:\n",
    "                    step, output = \"unknown\", event\n",
    "\n",
    "                if step == \"analyzer\":\n",
    "                    st.markdown(\"### ğŸ” Step 1: Analyzer ê²°ê³¼\")\n",
    "                    st.write(output.get(\"analysis\", \"ê²°ê³¼ ì—†ìŒ\"))\n",
    "                elif step == \"writer\":\n",
    "                    st.markdown(\"### âœï¸ Step 2: Writer (1ì°¨ ë¬¸êµ¬)\")\n",
    "                    st.write(output.get(\"content\", \"ê²°ê³¼ ì—†ìŒ\"))\n",
    "                elif step == \"reviewer\":\n",
    "                    st.markdown(\"### ğŸ§¾ Step 3: Reviewer (1ì°¨ í‰ê°€)\")\n",
    "                    st.write(output.get(\"review\", \"ê²°ê³¼ ì—†ìŒ\"))\n",
    "                elif step == \"rewriter\":\n",
    "                    st.markdown(\"### â™»ï¸ Step 4: Rewriter (í”¼ë“œë°± ë°˜ì˜)\")\n",
    "                    st.write(output.get(\"revised\", \"ê²°ê³¼ ì—†ìŒ\"))\n",
    "                elif step == \"final_reviewer\":\n",
    "                    st.markdown(\"### âœ… Step 5: Final Reviewer (ìµœì¢… í‰ê°€)\")\n",
    "                    st.write(output.get(\"review\", \"ê²°ê³¼ ì—†ìŒ\"))\n",
    "\n",
    "            # ìµœì¢… ê²°ê³¼ ì¶œë ¥\n",
    "            st.divider()\n",
    "            st.markdown(\"## ğŸ ìµœì¢… ê²°ê³¼ ìš”ì•½\")\n",
    "            result = feedback_workflow.invoke(state)\n",
    "            st.write(result.get(\"revised\", \"ìµœì¢… ìˆ˜ì •ëœ ë¬¸êµ¬ ì—†ìŒ\"))\n",
    "            st.write(result.get(\"review\", \"ìµœì¢… í‰ê°€ ì—†ìŒ\"))\n",
    "\n",
    "            st.success(\"ğŸ‰ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49704b0-1c2b-4f8c-88b0-d74bc566ea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœˆë„ìš° íƒìƒ‰ê¸°ì—ì„œ ìœ„ì—ì„œ ìƒì„±ëœ 2ê°œì˜ íŒŒì¼ì„ C:/ ê²½ë¡œì—ë³µì‚¬  \n",
    "# Anaconda Prompt ì‹¤í–‰\n",
    "# cd c:/\n",
    "# streamlit run app_streamlit.py\n",
    "\n",
    "# ì§ˆë¬¸ ì˜ˆì œ:\n",
    "# ì¹œí™˜ê²½ ì†Œì¬ë¡œ ë§Œë“  ê°€ë²¼ìš´ ë°±íŒ©ì„ í™ë³´í•˜ëŠ” ë¬¸êµ¬ë¥¼ ë§Œë“¤ì–´ì¤˜\n",
    "# í‡´ê·¼ê¸¸ ì‚¬ëŒë“¤ì—ê²Œ í¬ë§ì„ ì£¼ëŠ” ì§§ì€ ê´‘ê³  ë¬¸êµ¬ë¥¼ ë§Œë“¤ì–´ì¤˜\n",
    "# í”Œë¼ìŠ¤í‹± ì¤„ì´ê¸° í™˜ê²½ ìº í˜ì¸ì„ ìœ„í•œ SNS í™ë³´ ë¬¸êµ¬ë¥¼ ë§Œë“¤ì–´ì¤˜\n",
    "# í˜ˆë‹¹ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶„ì„í•´ì£¼ëŠ” ìŠ¤ë§ˆíŠ¸ì›Œì¹˜ ê¸°ëŠ¥ì„ í™ë³´í•˜ëŠ” ì§§ì€ ë¬¸êµ¬ë¥¼ ë§Œë“¤ì–´ì¤˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d455a2f-752b-4702-ada0-0adb340d5695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LangGraph êµ¬ì¡°ê°€ langgraph_workflow.json íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì´ ì†ŒìŠ¤ëŠ” Jupyter Notebookì—ì„œ ì‹¤í–‰\n",
    "\n",
    "# ==============================================================\n",
    "# LangGraph ì›Œí¬í”Œë¡œìš° ì‹œê°í™” JSON Export (ì™„ì „ í˜¸í™˜ ë²„ì „)\n",
    "# ==============================================================\n",
    "\n",
    "import json\n",
    "from agents_feedback_graph import build_feedback_workflow\n",
    "\n",
    "# LangGraph ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "workflow = build_feedback_workflow()\n",
    "\n",
    "# âœ… ë‚´ë¶€ ê·¸ë˜í”„ ê°ì²´ ê°€ì ¸ì˜¤ê¸°\n",
    "graph_obj = workflow.get_graph()  # Graph ê°ì²´\n",
    "\n",
    "graph_json = {\n",
    "    \"nodes\": [],\n",
    "    \"edges\": []\n",
    "}\n",
    "\n",
    "# âœ… ë…¸ë“œ ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘\n",
    "for node_name in graph_obj.nodes.keys():\n",
    "    graph_json[\"nodes\"].append({\n",
    "        \"id\": node_name,\n",
    "        \"type\": \"node\",\n",
    "        \"label\": node_name\n",
    "    })\n",
    "\n",
    "# âœ… ì—£ì§€ ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ (networkx í˜¸í™˜í˜• ì ‘ê·¼)\n",
    "try:\n",
    "    # ìµœì‹  ë²„ì „ì—ì„œëŠ” edges.data() ë¡œ ì—£ì§€ ìˆœíšŒ\n",
    "    for source, target, data in graph_obj.edges.data():\n",
    "        graph_json[\"edges\"].append({\n",
    "            \"source\": source,\n",
    "            \"target\": target\n",
    "        })\n",
    "except Exception:\n",
    "    # êµ¬ë²„ì „ ëŒ€ë¹„ fallback\n",
    "    for edge in graph_obj.edges:\n",
    "        if isinstance(edge, (tuple, list)):\n",
    "            source = edge[0]\n",
    "            target = edge[1] if len(edge) > 1 else None\n",
    "            if target:\n",
    "                graph_json[\"edges\"].append({\n",
    "                    \"source\": source,\n",
    "                    \"target\": target\n",
    "                })\n",
    "\n",
    "# âœ… JSON íŒŒì¼ ì €ì¥\n",
    "with open(\"langgraph_workflow.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(graph_json, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"âœ… LangGraph êµ¬ì¡°ê°€ langgraph_workflow.json íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96b244bb-7e1f-423c-9c03-043950dcd5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```mermaid\n",
       "graph LR\n",
       "    __start__ --> analyzer\n",
       "    analyzer --> writer\n",
       "    reviewer --> rewriter\n",
       "    rewriter --> final_reviewer\n",
       "    writer --> reviewer\n",
       "    final_reviewer --> __end__\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Jupyter Notebookì—ì„œëŠ” ì‹¤í–‰\n",
    "# LangGraph ì¶œë ¥\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "with open(\"langgraph_workflow.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Mermaid ê·¸ë˜í”„ ë¬¸ìì—´ ìƒì„±\n",
    "mermaid = \"```mermaid\\ngraph LR\\n\"\n",
    "for edge in data[\"edges\"]:\n",
    "    mermaid += f\"    {edge['source']} --> {edge['target']}\\n\"\n",
    "mermaid += \"```\"\n",
    "\n",
    "display(Markdown(mermaid))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
