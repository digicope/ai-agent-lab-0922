{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ccf1d1a-8888-4b54-abaf-1ff2a4b7bfcd",
   "metadata": {},
   "source": [
    "### ëŒ€í™” ë©”ëª¨ë¦¬ ê´€ë¦¬\n",
    "- ëŒ€í™” ë©”ëª¨ë¦¬(MessageHistory)ëŠ” AI Agentê°€ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ë©”ì‹œì§€ ë‹¨ìœ„ë¡œ ì €ì¥í•˜ê³ ,\n",
    "ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ë§¥ë½(Context)**ì„ ìœ ì§€í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ì´ì–´ê°€ê¸° ìœ„í•œ êµ¬ì¡°ì´ë‹¤.\n",
    "- ë‹¨ìˆœí•œ â€œëŒ€í™” ì´ë ¥ ì €ì¥â€ì„ ë„˜ì–´ì„œ, ëŒ€í™” ìš”ì•½(Summarization)ê³¼ ì˜ë„ ì¶”ì (Context Tracking) ê¸°ëŠ¥ì„ í¬í•¨í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "704eacbc-ea4e-4fda-ba14-177faa371eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env íŒŒì¼ì˜ ë‚´ìš© ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "load_dotenv(\"C:/env/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088259f9-6c69-4b27-8cc0-dbd8d9d44a95",
   "metadata": {},
   "source": [
    "### [1] ConversationBufferMemory: êµ¬ë²„ì „  \n",
    " (LangChain â‰¥ 0.2.7 ì‹ ë²„ì „ì—ì„œ Deprecated, í˜„ì¬ ë²„ì „ì—ì„œ ì‹¤í–‰ ì˜¤ë¥˜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b26a98ef-169d-4b2f-8923-9ed2a9b16f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain.chains import ConversationChain\n",
    "# from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# # 1) LLM ëª¨ë¸ ì •ì˜\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "\n",
    "# # 2) ë©”ëª¨ë¦¬ ê°ì²´ ìƒì„±\n",
    "# # return_messages=True â†’ ê° ëŒ€í™”ë¥¼ ë©”ì‹œì§€ ê°ì²´ë¡œ ë°˜í™˜\n",
    "# memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "# # 3) ëŒ€í™” ì²´ì¸(ConversationChain) êµ¬ì„±\n",
    "# conversation = ConversationChain(\n",
    "#     llm=llm,\n",
    "#     memory=memory,\n",
    "#     verbose=True   # ë‚´ë¶€ ë™ì‘ ë¡œê·¸ ì¶œë ¥\n",
    "# )\n",
    "\n",
    "# # 4) ëŒ€í™” ì‹¤í–‰\n",
    "# print(\"=== ëŒ€í™” ì‹œì‘ ===\")\n",
    "# response1 = conversation.predict(input=\"ì•ˆë…•? ë‚˜ëŠ” í™ê¸¸ë™ì´ì•¼.\")\n",
    "# print(\"ğŸ¤–:\", response1)\n",
    "\n",
    "# response2 = conversation.predict(input=\"ë‚´ ì´ë¦„ì´ ë­ì§€?\")\n",
    "# print(\"ğŸ¤–:\", response2)\n",
    "\n",
    "# response3 = conversation.predict(input=\"ì¢‹ì•„í•˜ëŠ” ìŒì‹ì€ ë­ì•¼?\")\n",
    "# print(\"ğŸ¤–:\", response3)\n",
    "\n",
    "## 5) ë©”ëª¨ë¦¬ ë‚´ìš© í™•ì¸\n",
    "# print(\"\\n=== í˜„ì¬ ë©”ëª¨ë¦¬ ì €ì¥ ë‚´ìš© ===\")\n",
    "# print(memory.buffer)\n",
    "\n",
    "# C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7420\\1386141394.py:13: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
    "#   memory = ConversationBufferMemory(return_messages=True)\n",
    "# C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7420\\1386141394.py:16: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
    "#   conversation = ConversationChain("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2146da72-891d-44b0-b6b0-5fad05849eb8",
   "metadata": {},
   "source": [
    "### [2] RunnableWithMessageHistory : ìµœì‹  ë²„ì „ ìŠ¤íƒ€ì¼\n",
    "LangChain ìµœì‹  ëŒ€í™” ê´€ë¦¬ í´ë˜ìŠ¤ (â‰¥ 0.2.7) <br>\n",
    "LLM(ì˜ˆ: ChatOpenAI)ê³¼ ëŒ€í™” ê¸°ë¡(MessageHistory)ì„ ì—°ê²°í•´ ë©€í‹°í„´ ëŒ€í™”(ëŒ€í™” ë§¥ë½ ìœ ì§€)ë¥¼ ì§€ì›í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c83faeae-7198-482b-8b31-2b691af655e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ëŒ€í™” ì‹œì‘ ===\n",
      "ğŸ¤–: ì•ˆë…•í•˜ì„¸ìš”, í™ê¸¸ë™ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "ğŸ¤–: ë‹¹ì‹ ì˜ ì´ë¦„ì€ í™ê¸¸ë™ì…ë‹ˆë‹¤! ë‹¤ë¥¸ ì§ˆë¬¸ì´ë‚˜ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.\n",
      "ğŸ¤–: ì €ëŠ” ì¸ê³µì§€ëŠ¥ì´ë¼ ìŒì‹ì„ ë¨¹ê±°ë‚˜ ì¢‹ì•„í•  ìˆ˜ëŠ” ì—†ì§€ë§Œ, ë§ì€ ì‚¬ëŒë“¤ì´ ì¢‹ì•„í•˜ëŠ” ìŒì‹ì— ëŒ€í•´ ì´ì•¼ê¸°í•  ìˆ˜ ìˆì–´ìš”! ì˜ˆë¥¼ ë“¤ì–´, í”¼ì, ì´ˆë°¥, ê¹€ì¹˜ì°Œê°œ ê°™ì€ ìŒì‹ë“¤ì´ ì¸ê¸°ê°€ ë§ì£ . í™ê¸¸ë™ë‹˜ì€ ì–´ë–¤ ìŒì‹ì„ ì¢‹ì•„í•˜ì‹œë‚˜ìš”?\n",
      "\n",
      "=== í˜„ì¬ ëŒ€í™” íˆìŠ¤í† ë¦¬ ===\n",
      "ğŸ§‘ ì‚¬ìš©ì: ì•ˆë…•? ë‚˜ëŠ” í™ê¸¸ë™ì´ì•¼!\n",
      "ğŸ¤– AI: ì•ˆë…•í•˜ì„¸ìš”, í™ê¸¸ë™ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "ğŸ§‘ ì‚¬ìš©ì: ë‚´ ì´ë¦„ì´ ë­ì§€?\n",
      "ğŸ¤– AI: ë‹¹ì‹ ì˜ ì´ë¦„ì€ í™ê¸¸ë™ì…ë‹ˆë‹¤! ë‹¤ë¥¸ ì§ˆë¬¸ì´ë‚˜ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.\n",
      "ğŸ§‘ ì‚¬ìš©ì: ì¢‹ì•„í•˜ëŠ” ìŒì‹ì€ ë­ì•¼?\n",
      "ğŸ¤– AI: ì €ëŠ” ì¸ê³µì§€ëŠ¥ì´ë¼ ìŒì‹ì„ ë¨¹ê±°ë‚˜ ì¢‹ì•„í•  ìˆ˜ëŠ” ì—†ì§€ë§Œ, ë§ì€ ì‚¬ëŒë“¤ì´ ì¢‹ì•„í•˜ëŠ” ìŒì‹ì— ëŒ€í•´ ì´ì•¼ê¸°í•  ìˆ˜ ìˆì–´ìš”! ì˜ˆë¥¼ ë“¤ì–´, í”¼ì, ì´ˆë°¥, ê¹€ì¹˜ì°Œê°œ ê°™ì€ ìŒì‹ë“¤ì´ ì¸ê¸°ê°€ ë§ì£ . í™ê¸¸ë™ë‹˜ì€ ì–´ë–¤ ìŒì‹ì„ ì¢‹ì•„í•˜ì‹œë‚˜ìš”?\n"
     ]
    }
   ],
   "source": [
    "#  LangChain ìµœì‹  ë©”ëª¨ë¦¬ êµ¬ì¡° ì˜ˆì œ\n",
    "# ConversationChain â†’ RunnableWithMessageHistoryë¡œ ë³€ê²½ë¨\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# 1) LLM ëª¨ë¸ ì •ì˜\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "\n",
    "# 2) ì„¸ì…˜ë³„ ëŒ€í™” ê¸°ë¡ ì €ì¥ì†Œ\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    \"\"\"ì„¸ì…˜ IDë³„ë¡œ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# 3) RunnableWithMessageHistory êµ¬ì„±\n",
    "conversation = RunnableWithMessageHistory(\n",
    "    llm,\n",
    "    get_session_history\n",
    ")\n",
    "\n",
    "# 4) ì„¸ì…˜ ID ì„¤ì •\n",
    "config = {\"configurable\": {\"session_id\": \"chat-001\"}}\n",
    "\n",
    "# 5) ëŒ€í™” ì‹¤í–‰\n",
    "print(\"=== ëŒ€í™” ì‹œì‘ ===\")\n",
    "response1 = conversation.invoke([HumanMessage(content=\"ì•ˆë…•? ë‚˜ëŠ” í™ê¸¸ë™ì´ì•¼!\")], config=config)\n",
    "print(\"ğŸ¤–:\", response1.content)\n",
    "\n",
    "response2 = conversation.invoke([HumanMessage(content=\"ë‚´ ì´ë¦„ì´ ë­ì§€?\")], config=config)\n",
    "print(\"ğŸ¤–:\", response2.content)\n",
    "\n",
    "response3 = conversation.invoke([HumanMessage(content=\"ì¢‹ì•„í•˜ëŠ” ìŒì‹ì€ ë­ì•¼?\")], config=config)\n",
    "print(\"ğŸ¤–:\", response3.content)\n",
    "\n",
    "# 6) í˜„ì¬ ë©”ëª¨ë¦¬(ëŒ€í™” íˆìŠ¤í† ë¦¬) í™•ì¸\n",
    "history = get_session_history(\"chat-001\")\n",
    "print(\"\\n=== í˜„ì¬ ëŒ€í™” íˆìŠ¤í† ë¦¬ ===\")\n",
    "for msg in history.messages:\n",
    "    role = \"ğŸ§‘ ì‚¬ìš©ì\" if msg.type == \"human\" else \"ğŸ¤– AI\"\n",
    "    print(f\"{role}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b34e51-33c6-48a8-8433-b3da545fc4e0",
   "metadata": {},
   "source": [
    "### [3] InMemoryChatMessageHistory\n",
    "- ëŒ€í™” ê¸°ë¡(Chat Messages)ì„ ë©”ëª¨ë¦¬(RAM)ì— ì €ì¥í•˜ëŠ” ê¸°ë³¸ í´ë˜ìŠ¤\n",
    "- í•œ ì„¸ì…˜(session_id) ë™ì•ˆ ì‚¬ìš©ì ë©”ì‹œì§€ì™€ AI ì‘ë‹µì„ ìˆœì°¨ì ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³´ê´€\n",
    "- í”„ë¡œê·¸ë¨ì´ ì¢…ë£Œë˜ë©´ ê¸°ë¡ì´ ì‚¬ë¼ì§€ëŠ” íœ˜ë°œì„±(Volatile) êµ¬ì¡°\n",
    "- RunnableWithMessageHistoryì™€ í•¨ê»˜ ì‚¬ìš©í•´ ë©€í‹°í„´ ëŒ€í™” ê´€ë¦¬ì— í™œìš©ë¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10739d49-185b-420d-9a92-ffc23434beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# 1) ë©”ëª¨ë¦¬ ê°ì²´ ìƒì„±\n",
    "history = InMemoryChatMessageHistory()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
