{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ccf1d1a-8888-4b54-abaf-1ff2a4b7bfcd",
   "metadata": {},
   "source": [
    "### 대화 메모리 관리\n",
    "- 대화 메모리(MessageHistory)는 AI Agent가 이전 대화 내용을 메시지 단위로 저장하고,\n",
    "이를 바탕으로 **맥락(Context)**을 유지하여 자연스러운 대화를 이어가기 위한 구조이다.\n",
    "- 단순한 “대화 이력 저장”을 넘어서, 대화 요약(Summarization)과 의도 추적(Context Tracking) 기능을 포함한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "704eacbc-ea4e-4fda-ba14-177faa371eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일의 내용 불러오기\n",
    "load_dotenv(\"C:/env/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088259f9-6c69-4b27-8cc0-dbd8d9d44a95",
   "metadata": {},
   "source": [
    "### [1] ConversationBufferMemory: 구버전  \n",
    " (LangChain ≥ 0.2.7 신버전에서 Deprecated, 현재 버전에서 실행 오류)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b26a98ef-169d-4b2f-8923-9ed2a9b16f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain.chains import ConversationChain\n",
    "# from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# # 1) LLM 모델 정의\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "\n",
    "# # 2) 메모리 객체 생성\n",
    "# # return_messages=True → 각 대화를 메시지 객체로 반환\n",
    "# memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "# # 3) 대화 체인(ConversationChain) 구성\n",
    "# conversation = ConversationChain(\n",
    "#     llm=llm,\n",
    "#     memory=memory,\n",
    "#     verbose=True   # 내부 동작 로그 출력\n",
    "# )\n",
    "\n",
    "# # 4) 대화 실행\n",
    "# print(\"=== 대화 시작 ===\")\n",
    "# response1 = conversation.predict(input=\"안녕? 나는 홍길동이야.\")\n",
    "# print(\"🤖:\", response1)\n",
    "\n",
    "# response2 = conversation.predict(input=\"내 이름이 뭐지?\")\n",
    "# print(\"🤖:\", response2)\n",
    "\n",
    "# response3 = conversation.predict(input=\"좋아하는 음식은 뭐야?\")\n",
    "# print(\"🤖:\", response3)\n",
    "\n",
    "## 5) 메모리 내용 확인\n",
    "# print(\"\\n=== 현재 메모리 저장 내용 ===\")\n",
    "# print(memory.buffer)\n",
    "\n",
    "# C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7420\\1386141394.py:13: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
    "#   memory = ConversationBufferMemory(return_messages=True)\n",
    "# C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7420\\1386141394.py:16: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
    "#   conversation = ConversationChain("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2146da72-891d-44b0-b6b0-5fad05849eb8",
   "metadata": {},
   "source": [
    "### [2] RunnableWithMessageHistory : 최신 버전 스타일\n",
    "LangChain 최신 대화 관리 클래스 (≥ 0.2.7) <br>\n",
    "LLM(예: ChatOpenAI)과 대화 기록(MessageHistory)을 연결해 멀티턴 대화(대화 맥락 유지)를 지원한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c83faeae-7198-482b-8b31-2b691af655e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 대화 시작 ===\n",
      "🤖: 안녕하세요, 홍길동님! 만나서 반갑습니다. 어떻게 도와드릴까요?\n",
      "🤖: 당신의 이름은 홍길동입니다! 다른 질문이나 궁금한 점이 있으면 말씀해 주세요.\n",
      "🤖: 저는 인공지능이라 음식을 먹거나 좋아할 수는 없지만, 많은 사람들이 좋아하는 음식에 대해 이야기할 수 있어요! 예를 들어, 피자, 초밥, 김치찌개 같은 음식들이 인기가 많죠. 홍길동님은 어떤 음식을 좋아하시나요?\n",
      "\n",
      "=== 현재 대화 히스토리 ===\n",
      "🧑 사용자: 안녕? 나는 홍길동이야!\n",
      "🤖 AI: 안녕하세요, 홍길동님! 만나서 반갑습니다. 어떻게 도와드릴까요?\n",
      "🧑 사용자: 내 이름이 뭐지?\n",
      "🤖 AI: 당신의 이름은 홍길동입니다! 다른 질문이나 궁금한 점이 있으면 말씀해 주세요.\n",
      "🧑 사용자: 좋아하는 음식은 뭐야?\n",
      "🤖 AI: 저는 인공지능이라 음식을 먹거나 좋아할 수는 없지만, 많은 사람들이 좋아하는 음식에 대해 이야기할 수 있어요! 예를 들어, 피자, 초밥, 김치찌개 같은 음식들이 인기가 많죠. 홍길동님은 어떤 음식을 좋아하시나요?\n"
     ]
    }
   ],
   "source": [
    "#  LangChain 최신 메모리 구조 예제\n",
    "# ConversationChain → RunnableWithMessageHistory로 변경됨\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# 1) LLM 모델 정의\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "\n",
    "# 2) 세션별 대화 기록 저장소\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    \"\"\"세션 ID별로 대화 기록을 저장하고 불러오는 함수\"\"\"\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# 3) RunnableWithMessageHistory 구성\n",
    "conversation = RunnableWithMessageHistory(\n",
    "    llm,\n",
    "    get_session_history\n",
    ")\n",
    "\n",
    "# 4) 세션 ID 설정\n",
    "config = {\"configurable\": {\"session_id\": \"chat-001\"}}\n",
    "\n",
    "# 5) 대화 실행\n",
    "print(\"=== 대화 시작 ===\")\n",
    "response1 = conversation.invoke([HumanMessage(content=\"안녕? 나는 홍길동이야!\")], config=config)\n",
    "print(\"🤖:\", response1.content)\n",
    "\n",
    "response2 = conversation.invoke([HumanMessage(content=\"내 이름이 뭐지?\")], config=config)\n",
    "print(\"🤖:\", response2.content)\n",
    "\n",
    "response3 = conversation.invoke([HumanMessage(content=\"좋아하는 음식은 뭐야?\")], config=config)\n",
    "print(\"🤖:\", response3.content)\n",
    "\n",
    "# 6) 현재 메모리(대화 히스토리) 확인\n",
    "history = get_session_history(\"chat-001\")\n",
    "print(\"\\n=== 현재 대화 히스토리 ===\")\n",
    "for msg in history.messages:\n",
    "    role = \"🧑 사용자\" if msg.type == \"human\" else \"🤖 AI\"\n",
    "    print(f\"{role}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b34e51-33c6-48a8-8433-b3da545fc4e0",
   "metadata": {},
   "source": [
    "### [3] InMemoryChatMessageHistory\n",
    "- 대화 기록(Chat Messages)을 메모리(RAM)에 저장하는 기본 클래스\n",
    "- 한 세션(session_id) 동안 사용자 메시지와 AI 응답을 순차적으로 리스트 형태로 보관\n",
    "- 프로그램이 종료되면 기록이 사라지는 휘발성(Volatile) 구조\n",
    "- RunnableWithMessageHistory와 함께 사용해 멀티턴 대화 관리에 활용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10739d49-185b-420d-9a92-ffc23434beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# 1) 메모리 객체 생성\n",
    "history = InMemoryChatMessageHistory()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
