{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c300e74-fdbc-4e10-b490-e7209c154c42",
   "metadata": {},
   "source": [
    "# 텍스트 분할(Text Splitter)\n",
    "LangChain의 텍스트 분할(Text Splitter) 은 긴 문서(예: PDF, 웹페이지, 텍스트 파일 등)를 벡터 임베딩(Vector Embedding) 단계 전에 <br>\n",
    "적절한 크기의 조각(Chunk) 으로 나누기 위한 핵심 도구이다. <br>\n",
    "RAG(Retrieval-Augmented Generation) 파이프라인의 성능은 이 “문서 분할 전략”에 크게 좌우된다. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb9df291-b41b-40ed-b87c-2b6ab4f1db01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일의 내용 불러오기\n",
    "load_dotenv(\"C:/env/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856ad033-6a9c-4f97-aae8-aeb28ea8eb28",
   "metadata": {},
   "source": [
    "### [1] CharacterTextSplitter\n",
    ": CharacterTextSplitter 는 텍스트를 문자(Character) 단위로 단순하게 자르는 기본 분할기(Text Splitter) 이다. <br>\n",
    "이 클래스는 문장을 “특정 구분자(separator)” 기준으로 쪼개고, 각 조각(chunk)을 지정된 크기(chunk_size)로 묶는 방식으로 동작한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d69d99cc-3336-49f2-826b-84b95cc508e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 81, which is longer than the specified 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청크 1: LangChain은 LLM 애플리케이션 개발을 위한 프레임워크입니다.\n",
      "청크 2: 문서 로드, 텍스트 분할, 임베딩, 검색, 체인 등의 기능을 제공합니다.\n",
      "청크 3: CharacterTextSplitter 는 텍스트를 문자(Character) 단위로 단순하게 자르는 기본 분할기(Text Splitter) 이다.\n",
      "청크 4: 이 클래스는 문장을 “특정 구분자(separator)” 기준으로 쪼개고, 각 조각(chunk)을 지정된 크기(chunk_size)로 묶는 방식으로 동작한다\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text = \"\"\"\n",
    "LangChain은 LLM 애플리케이션 개발을 위한 프레임워크입니다.\n",
    "문서 로드, 텍스트 분할, 임베딩, 검색, 체인 등의 기능을 제공합니다.\n",
    "CharacterTextSplitter 는 텍스트를 문자(Character) 단위로 단순하게 자르는 기본 분할기(Text Splitter) 이다.\n",
    "이 클래스는 문장을 “특정 구분자(separator)” 기준으로 쪼개고, 각 조각(chunk)을 지정된 크기(chunk_size)로 묶는 방식으로 동작한다\n",
    "\"\"\"\n",
    "\n",
    "# Character 단위 분할기 생성\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",      # 줄바꿈 기준으로 분할\n",
    "    chunk_size=40,       # 각 청크 최대 40자    --> 실제는 81\n",
    "    chunk_overlap=10     # 앞뒤 청크 10자 겹치기\n",
    ")\n",
    "\n",
    "# 분할 실행\n",
    "chunks = splitter.split_text(text)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "     print(f\"청크 {i+1}:\", chunk)\n",
    "\n",
    "# Created a chunk of size 81, which is longer than the specified 40\n",
    "# LangChain의 CharacterTextSplitter 동작 방식의 핵심 특징 :\n",
    "# “chunk_size는 엄격한 자르기 기준이 아니라 목표 크기(target)”이기 때문이다.\n",
    "# 만약 하나의 구분자 사이 텍스트가 이미 chunk_size보다 길면,\n",
    "# LangChain은 그 문장을 자르지 않고 그대로 하나의 청크로 유지한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b3d46da-babc-4098-9e03-bb1cec931281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청크 1: LangChain은 LLM 애플리케이션 개발을 위한 프레임워크입니다.\n",
      "청크 2: 프레임워크입니다.\n",
      "문서 로드, 텍스트 분할, 임베딩, 검색, 체인 등의\n",
      "청크 3: 검색, 체인 등의 기능을 제공합니다.\n",
      "CharacterTextSplitt\n",
      "청크 4: TextSplitter 는 텍스트를 문자(Character) 단위로 단순\n",
      "청크 5: er) 단위로 단순하게 자르는 기본 분할기(Text Splitter) 이\n",
      "청크 6: plitter) 이다.\n",
      "이 클래스는 문장을 “특정 구분자(separato\n",
      "청크 7: 자(separator)” 기준으로 쪼개고, 각 조각(chunk)을 지정된\n",
      "청크 8: hunk)을 지정된 크기(chunk_size)로 묶는 방식으로 동작한다\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text = \"\"\"\n",
    "LangChain은 LLM 애플리케이션 개발을 의 기능을 제공합니다.\n",
    "CharacterTextSplitter 는 텍스트를 문자(Character) 단위위한 프레임워크입니다.\n",
    "문서 로드, 텍스트 분할, 임베딩, 검색, 체인 등로 단순하게 자르는 기본 분할기(Text Splitter) 이다.\n",
    "이 클래스는 문장을 “특정 구분자(separator)” 기준으로 쪼개고, 각 조각(chunk)을 지정된 크기(chunk_size)로 묶는 방식으로 동작한다\n",
    "\"\"\"\n",
    "\n",
    "# Character 단위 분할기 생성\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=\"\",        # 문서를 개별 문자를 단위로 나누기 \n",
    "    chunk_size=40,       # 각 청크 최대 40자   --> 40개로 나누어짐 \n",
    "    chunk_overlap=10     # 앞뒤 청크 10자 겹치기\n",
    ")\n",
    "\n",
    "# 분할 실행\n",
    "chunks = splitter.split_text(text)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "     print(f\"청크 {i+1}:\", chunk)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceb9f61-fc04-49bb-aad0-0a16f0c60627",
   "metadata": {},
   "source": [
    "### [2] RecursiveCharacterTextSplitter\n",
    ": RecursiveCharacterTextSplitter 는 LangChain에서 가장 지능적인 텍스트 분할기(Text Splitter) 이다 <br>\n",
    "긴 문서를 문맥 손실 없이, LLM 입력 제한(token limit) 에 맞게 잘게 나누기 위해 설계된 클래스이다. <br>\n",
    "가장 많이 쓰이고, RAG 파이프라인의 핵심. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2be0bd9-bc3d-401b-bc31-ccfd116f84db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청크 1: LangChain은 LLM 애플리케이션 개발을 위한 프레임워크입니다.\n",
      "청크 2: 문서 로드, 텍스트 분할, 임베딩, 검색, 체인 등의 기능을\n",
      "청크 3: 체인 등의 기능을 제공합니다.\n",
      "청크 4: LangChain의 핵심 구성 요소는 체인, 메모리, 에이전트입니다.\n",
      "청크 5: RecursiveCharacterTextSplitter 는\n",
      "청크 6: 는 LangChain에서 가장 지능적인 텍스트 분할기(Text\n",
      "청크 7: 분할기(Text Splitter) 이다\n",
      "청크 8: 긴 문서를 문맥 손실 없이, LLM 입력 제한(token limit)\n",
      "청크 9: limit) 에 맞게 잘게 나누기 위해 설계된 클래스이다.\n",
      "청크 10: 가장 많이 쓰이고, RAG 파이프라인의 핵심.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text = \"\"\"\n",
    "LangChain은 LLM 애플리케이션 개발을 위한 프레임워크입니다.\n",
    "문서 로드, 텍스트 분할, 임베딩, 검색, 체인 등의 기능을 제공합니다.\n",
    "LangChain의 핵심 구성 요소는 체인, 메모리, 에이전트입니다.\n",
    "RecursiveCharacterTextSplitter 는 LangChain에서 가장 지능적인 텍스트 분할기(Text Splitter) 이다\n",
    "긴 문서를 문맥 손실 없이, LLM 입력 제한(token limit) 에 맞게 잘게 나누기 위해 설계된 클래스이다.\n",
    "가장 많이 쓰이고, RAG 파이프라인의 핵심.\n",
    "\"\"\"\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=40,          # 청크 최대 40자\n",
    "    chunk_overlap=10,        # 앞뒤로 10자씩 겹침\n",
    "    \n",
    "    # 문자열 길이를 계산하는 함수를 지정합니다.\n",
    "    length_function=len,\n",
    "    \n",
    "    # 구분자로 정규식을 사용할지 여부를 설정합니다.\n",
    "    is_separator_regex=False,    \n",
    ")\n",
    "\n",
    "# 분할 실행\n",
    "chunks = splitter.split_text(text)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "     print(f\"청크 {i+1}:\", chunk)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b56b37a-ace5-4804-8969-e15b8595a388",
   "metadata": {},
   "source": [
    "### [3] TokenTextSplitter\n",
    ": TokenTextSplitter는 텍스트를 문자 수가 아니라 토큰 단위로 나누는 클래스이다. <br>\n",
    "모델의 토큰 한도(예: 8192 tokens)를 초과하지 않게 문서를 나누고, 모델의 비용/속도/성능 최적화에 유용하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45641483-a50e-44a5-8ef6-c373afc2e688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청크 1: \n",
      "LangChain은 LLM 애플리케이션 개발을 단순화하는 프레임워크입니다.\n",
      "문서 �\n",
      "\n",
      "청크 2: �.\n",
      "문서 로딩, 텍스트 분할, 임베딩, 검색, 체인 구성 등의 기능을 제�\n",
      "\n",
      "청크 3: �능을 제공합니다.\n",
      "TokenTextSplitter는 텍스트를 문자 수가 아니라 토큰 단위로 나�\n",
      "\n",
      "청크 4: 위로 나누는 클래스이다.\n",
      "모델의 토큰 한도를 초과하지 않게 문서�\n",
      "\n",
      "청크 5: �� 문서를 나누고, 모델의 비용/속도/성능 최적화에 유용하다.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "text = \"\"\"\n",
    "LangChain은 LLM 애플리케이션 개발을 단순화하는 프레임워크입니다.\n",
    "문서 로딩, 텍스트 분할, 임베딩, 검색, 체인 구성 등의 기능을 제공합니다.\n",
    "TokenTextSplitter는 텍스트를 문자 수가 아니라 토큰 단위로 나누는 클래스이다.\n",
    "모델의 토큰 한도를 초과하지 않게 문서를 나누고, 모델의 비용/속도/성능 최적화에 유용하다.\n",
    "\"\"\"\n",
    "\n",
    "splitter = TokenTextSplitter(\n",
    "    chunk_size=80,       # 최대 80토큰\n",
    "    chunk_overlap=10     # 앞뒤 10토큰 겹치기\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(text)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"청크 {i+1}: {chunk}\\n\")\n",
    "\n",
    "# 출력된 � 기호는 청크를 자르는 과정에서 한글이 두 바이트 \n",
    "# 이상으로 인코딩된 상태에서 중간이 잘려버린 현상 때문이다.\n",
    "# 해결방법은 -> RecursiveCharacterTextSplitter 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d172b9a-7d2b-42be-8284-a5aa5ba4a4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
