{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30d80f0d-8e13-4ce9-9fd0-624cf3e9e510",
   "metadata": {},
   "source": [
    "# 문서 로더(document Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07a536a1-f554-4204-b653-3a53b7eeab34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일의 내용 불러오기\n",
    "load_dotenv(\"C:/env/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2e93a6-cd39-41a9-b515-42e1d893c699",
   "metadata": {},
   "source": [
    "### Document 객체\n",
    ": LangChain에서 Document 객체는 모든 데이터의 기본 단위이며, <br>\n",
    "  Loader로 불러온 텍스트를 모델이 이해할 수 있는 표준 구조로 정리한 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90de8ae5-dcb2-471a-9664-f115656bd808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n",
      "page_content: 이 문서는 LangChain의 Document 객체 설명입니다.\n",
      "metadata: {'source': 'lecture_note', 'page': 1}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "doc = Document(\n",
    "    page_content=\"이 문서는 LangChain의 Document 객체 설명입니다.\",\n",
    "    metadata={\"source\": \"lecture_note\", \"page\": 1}\n",
    ")\n",
    "print(type(doc))\n",
    "\n",
    "print('page_content:',doc.page_content)\n",
    "print('metadata:',doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3066307e-4266-4c57-a2d5-82df8614389c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='1장. LangChain 개요...' metadata={'source': 'data/guide.pdf', 'page': 1}\n",
      "page_content='2장. Document Loader의 종류...' metadata={'source': 'data/guide.pdf', 'page': 2}\n"
     ]
    }
   ],
   "source": [
    "docs = \\\n",
    "[\n",
    "  Document(\n",
    "    page_content=\"1장. LangChain 개요...\",\n",
    "    metadata={\"source\": \"data/guide.pdf\", \"page\": 1}\n",
    "  ),\n",
    "  Document(\n",
    "    page_content=\"2장. Document Loader의 종류...\",\n",
    "    metadata={\"source\": \"data/guide.pdf\", \"page\": 2}\n",
    "  ),\n",
    "]\n",
    "print(docs[0])\n",
    "print(docs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998993df-e7f1-40bd-b4d1-1f78beec8d74",
   "metadata": {},
   "source": [
    "## 문서 로더(Document Loader)\n",
    ": LangChain의 Document Loader는 외부 문서(파일, 웹, 데이터베이스 등)를 읽어서  <br>\n",
    "LangChain이 처리할 수 있는 Document 객체(list[Document]) 형태로 변환하는 구성요소이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01027b29-6400-4f93-966a-aed562f4fa88",
   "metadata": {},
   "source": [
    "###  [1] TextLoader\n",
    ": TextLoader 는 LangChain에서 가장 기본적인 문서 로더(Document Loader) 로, <br>\n",
    "일반 텍스트 파일(.txt)을 읽어들여 Document 객체로 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d0d97ea-1e49-491a-97d2-c5ab162b0625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sample.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile sample.txt\n",
    "이 문서는 LangChain TextLoader 예시입니다.\n",
    "여러 줄의 텍스트를 포함합니다.\n",
    "TextLoader 는 LangChain에서 가장 기본적인 Document Loader이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "456fba62-ef46-4015-9db1-0c90edf35d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n",
      "page_content='이 문서는 LangChain의 Document 객체 설명입니다.' metadata={'source': 'lecture_note', 'page': 1}\n",
      "총 4 개의 청크가 저장되었습니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'sample.txt'}, page_content='이 문서는 LangChain TextLoader 예시입니다.'),\n",
       " Document(metadata={'source': 'sample.txt'}, page_content='여러 줄의 텍스트를 포함합니다.'),\n",
       " Document(metadata={'source': 'sample.txt'}, page_content='TextLoader 는 LangChain에서 가장 기본적인 Document'),\n",
       " Document(metadata={'source': 'sample.txt'}, page_content='Document Loader이다')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# 1) 텍스트 로드\n",
    "loader = TextLoader(\"sample.txt\",encoding=\"utf-8\")\n",
    "docs = loader.load()\n",
    "\n",
    "print(type(doc))  # Document 객체\n",
    "print(doc)\n",
    "\n",
    "# 2) 청크 단위로 나누기\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=50,chunk_overlap=10)\n",
    "split_docs = splitter.split_documents(docs)\n",
    "\n",
    "# 3) 임베딩 생성 및 벡터 저장\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = FAISS.from_documents(split_docs,embeddings)\n",
    "\n",
    "print(\"총\", len(split_docs), \"개의 청크가 저장되었습니다.\")\n",
    "split_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a458f34b-fa21-4030-9b49-d032e4c9b5f7",
   "metadata": {},
   "source": [
    "###  [2] DirectoryLoader\n",
    ": DirectoryLoader는 폴더(디렉터리) 안의 여러 파일을 자동으로 탐색하여 <br>\n",
    "각 파일을 개별 Document 객체로 읽어들이는 문서 로더(Document Loader) 이다. <br>\n",
    "이 클래스는 실제 프로젝트에서 대규모 문서 일괄 처리 시 거의 항상 사용되는 핵심 도구이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4240ca5-64bc-4aa6-bef0-dc5d8fe2496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85dfae6c-4128-443c-be2b-920c6c1d2c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sample1.txt 파일 생성 완료\n",
      " sample2.txt 파일 생성 완료\n",
      " sample3.txt 파일 생성 완료\n",
      "\n",
      "📂 'data' 폴더에 3개의 샘플 텍스트 파일이 준비되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 1. data 폴더 생성 (이미 존재하면 무시)\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# 2. 샘플 텍스트 데이터\n",
    "samples = {\n",
    "    \"sample1.txt\": \"\"\"LangChain은 LLM(대규모 언어모델)을 활용한 파이프라인 구축을 위한 오픈소스 프레임워크입니다.\n",
    "Document Loader를 통해 다양한 외부 데이터를 로드하고,\n",
    "Text Splitter로 문서를 나눈 후, Embedding 및 VectorStore를 이용해 RAG 시스템을 구성할 수 있습니다.\"\"\",\n",
    "\n",
    "    \"sample2.txt\": \"\"\"FAISS는 Facebook AI Research에서 개발한 벡터 검색 라이브러리입니다.\n",
    "LangChain에서는 문서 임베딩을 벡터로 변환한 후,\n",
    "FAISS를 이용해 빠른 유사도 검색을 수행합니다.\"\"\",\n",
    "\n",
    "    \"sample3.txt\": \"\"\"pgvector는 PostgreSQL 데이터베이스에서 벡터 데이터를 저장하고 검색할 수 있게 해주는 확장 모듈입니다.\n",
    "LangChain은 pgvector를 통해 RAG 시스템을 SQL 기반 환경에서도 구현할 수 있습니다.\"\"\"\n",
    "}\n",
    "\n",
    "# 3. 파일 생성 및 저장\n",
    "for filename, content in samples.items():\n",
    "    path = os.path.join(\"data\", filename)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "    print(f\" {filename} 파일 생성 완료\")\n",
    "\n",
    "print(\"\\n📂 'data' 폴더에 3개의 샘플 텍스트 파일이 준비되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "975b3cd0-57c9-42ba-9b8a-0880d4f8d6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████████████████████████▌                                                           | 3/6 [00:00<00:00, 431.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 개의 문서를 불러왔습니다.\n",
      "\n",
      "문서 1:\n",
      " page_content='LangChain은 LLM(대규모 언어모델)을 활용한 파이프라인 구축을 위한 오픈소스 프레임워크입니다.\n",
      "Document Loader를 통해 다양한 외부 데이터를 로드하고,\n",
      "Text Splitter로 문서를 나눈 후, Embedding 및 VectorStore를 이용해 RAG 시스템을 구성할 수 있습니다.' metadata={'source': 'data\\\\sample1.txt'}\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "문서 2:\n",
      " page_content='FAISS는 Facebook AI Research에서 개발한 벡터 검색 라이브러리입니다.\n",
      "LangChain에서는 문서 임베딩을 벡터로 변환한 후,\n",
      "FAISS를 이용해 빠른 유사도 검색을 수행합니다.' metadata={'source': 'data\\\\sample2.txt'}\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "문서 3:\n",
      " page_content='pgvector는 PostgreSQL 데이터베이스에서 벡터 데이터를 저장하고 검색할 수 있게 해주는 확장 모듈입니다.\n",
      "LangChain은 pgvector를 통해 RAG 시스템을 SQL 기반 환경에서도 구현할 수 있습니다.' metadata={'source': 'data\\\\sample3.txt'}\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    \"data/\",\n",
    "    glob=\"**/*.txt\",\n",
    "    loader_cls=lambda path : TextLoader(path,autodetect_encoding=True), #  자동 인코딩 감지\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "print(len(docs), \"개의 문서를 불러왔습니다.\\n\")\n",
    "\n",
    "for i,doc in enumerate(docs):\n",
    "    print(f'문서 {i+1}:\\n', doc)\n",
    "    print('-'*140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4302710-1bbe-40fc-8a8c-c15b3c28a542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\sample1.txt'}, page_content='LangChain은 LLM(대규모 언어모델)을 활용한 파이프라인 구축을 위한 오픈소스 프레임워크입니다.\\nDocument Loader를 통해 다양한 외부 데이터를 로드하고,\\nText Splitter로 문서를 나눈 후, Embedding 및 VectorStore를 이용해 RAG 시스템을 구성할 수 있습니다.'),\n",
       " Document(metadata={'source': 'data\\\\sample2.txt'}, page_content='FAISS는 Facebook AI Research에서 개발한 벡터 검색 라이브러리입니다.\\nLangChain에서는 문서 임베딩을 벡터로 변환한 후,\\nFAISS를 이용해 빠른 유사도 검색을 수행합니다.'),\n",
       " Document(metadata={'source': 'data\\\\sample3.txt'}, page_content='pgvector는 PostgreSQL 데이터베이스에서 벡터 데이터를 저장하고 검색할 수 있게 해주는 확장 모듈입니다.\\nLangChain은 pgvector를 통해 RAG 시스템을 SQL 기반 환경에서도 구현할 수 있습니다.')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs  # 리스트로 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becb9fe3-b89a-4acb-b084-51808df2a778",
   "metadata": {},
   "source": [
    "### [3] PDF Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7811d5ba-48cb-4aa4-9cb8-2ba80e0a23c8",
   "metadata": {},
   "source": [
    "####  (1) PyPDFLoader\n",
    ": PyPDFLoader는 PDF 파일을 텍스트로 변환하여 Document 객체로 만드는 로더입니다.<br>\n",
    "내부적으로 pypdf (이전 명칭 PyPDF2) 라이브러리를 사용하며,\n",
    "PDF의 각 페이지를 개별 Document 객체로 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bc5b297-0527-4977-a29d-76f5e5a5df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5dd37326-5c42-4b3f-9d10-aade9317df17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 16 페이지 로드됨\n",
      "강화학습을 이용한 하천 녹조 발생 저감 모형 연구   47한국빅데이터학회지\n",
      "제10권 제1호, 2025, pp. 47-62 https://doi.org/10.36498/kbigdt.2025.10.1.47\n",
      "유튜브 기반 사용자 콘텐츠에서의 리뷰 이상 탐지: \n",
      "사용자 생성 콘텐츠에서의 극단성과 허위성 분류 \n",
      "Decoding Review Anomalies: Classifying Extremity and Falsity in \n",
      "User-Generated Content\n",
      "가중정1⋅김엘레나2⋅최재원3†\n",
      "순천향대학교 경영학과1, 순천향대학교 경영학과2, 순천향대학교 경영학과3\n",
      "요  약\n",
      "본 연구는 YouTube 플랫폼의 호텔 리뷰를 대상으로 머신러닝과 자연어처리(NLP) 기법을 활용해 극단적 \n",
      "및 조작된 리뷰를 식별⋅필터링하고자 한다. 소셜 미디어는 소비자 구매 결정에 중요한 영향을 미치며, \n",
      "사용자 생성 리뷰는 마켓플레이스 신뢰도의 핵심 요소로 작용한다. 그러나 일부 판매자들의 평점 조작과 \n",
      "조작된 리\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"유튜브 기반 사용자 콘텐츠에서의 리뷰 이상 탐지.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "print(\"총\", len(docs), \"페이지 로드됨\")\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b98f0e3b-246a-4a3c-b91d-22450292ab2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 78 개의 문서(페이지) 로드 완료\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    \"./\",\n",
    "    glob=\"**/*.pdf\",\n",
    "    loader_cls=PyPDFLoader\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "print(\"총\", len(docs), \"개의 문서(페이지) 로드 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e4951ac-cbd1-4a38-9ece-2e071e04b717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF 문서가 벡터 DB로 성공적으로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# 1) PDF 로드\n",
    "loader = PyPDFLoader(\"유튜브 기반 사용자 콘텐츠에서의 리뷰 이상 탐지.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "# 2) 문서 분할\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=100)\n",
    "split_docs = splitter.split_documents(docs)\n",
    "\n",
    "# 3) 임베딩 및 벡터 저장\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "\n",
    "print(\"PDF 문서가 벡터 DB로 성공적으로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90c65a7b-6792-4c35-acfa-95033d506865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c027f3f-9afb-4b0f-80d3-12848e069045",
   "metadata": {},
   "source": [
    " #### (2) PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "115ae16b-ba3f-4810-ab53-1d89555d15aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61861804-f22c-4814-a0a7-ba1068548dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 16 페이지 로드됨\n",
      "강화학습을 이용한 하천 녹조 발생 저감 모형 연구   47\n",
      "한국빅데이터학회지\n",
      "제10권 제1호, 2025, pp. 47-62\n",
      "https://doi.org/10.36498/kbigdt.2025.10.1.47\n",
      "유튜브 기반 사용자 콘텐츠에서의 리뷰 이상 탐지: \n",
      "사용자 생성 콘텐츠에서의 극단성과 허위성 분류 \n",
      "Decoding Review Anomalies: Classifying Extremity and Falsity in \n",
      "User-Generated Content\n",
      "가중정1⋅김엘레나2⋅최재원3†\n",
      "순천향대학교 경영학과1, 순천향대학교 경영학과2, 순천향대학교 경영학과3\n",
      "요  약\n",
      "본 연구는 YouTube 플랫폼의 호텔 리뷰를 대상으로 머신러닝과 자연어처리(NLP) 기법을 활용해 극단적 \n",
      "및 조작된 리뷰를 식별⋅필터링하고자 한다. 소셜 미디어는 소비자 구매 결정에 중요한 영향을 미치며, \n",
      "사용자 생성 리뷰는 마켓플레이스 신뢰도의 핵심 요소로 작용한다. 그러나 일부 판매자들의 평점 조작과 \n",
      "조작된 \n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# PyMuPDF 로더 인스턴스 생성\n",
    "loader = PyMuPDFLoader(\"유튜브 기반 사용자 콘텐츠에서의 리뷰 이상 탐지.pdf\")\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "print(\"총\", len(docs), \"페이지 로드됨\")\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[10].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab3e11b-ac7c-4967-857a-b89a281008ba",
   "metadata": {},
   "source": [
    "#### (4) PDFPlumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0115678c-43a1-433f-b4ce-0d89e0d34358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61eab5b0-cfaf-4087-99fb-c187ea2b5ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 16 페이지 로드됨\n",
      "유튜브 기반 사용자 콘텐츠에서의 리뷰 이상 탐지 57\n",
      "추출된 토픽 주제의 해석력을 높이기 위해, 동시출현 네트워크는 사용자 리뷰의 다차원\n",
      "본 연구는 동시출현 점수(co-occurrence score)를 적인 토픽 구조를 보여준다. 다양한 색상의 토\n",
      "계산하여 각 토픽의 의미적 일관성을 평가하였 픽 노드는 여행 및 숙박 경험, 지역 리뷰, 동영상\n",
      "다. 이 점수는 특정 주제 내에서 키워드들이 동 콘텐츠 피드백 등과 같은 다양한 의미적 시나리\n",
      "일한 문서 내에 얼마나 자주 함께 등장하는지를 오를 다루며, 고빈도 키워드는 여러 토픽을 동\n",
      "수치화한 것으로, 주제어 간의 상호 연관성을 시 발생 관계를 통해 서로 연결하여 리뷰 콘텐\n",
      "측정하는 지표로 활용된다. 수치화한 것으로, 주 츠의 다양성과 집중도를 보여준다. <그림 2>는\n",
      "제어 간의 상호 연관성을 측정하는 지표로 활용 시각화 된 동시출현 네트워크를 나타낸다.\n",
      "된다. 동시출현 점수가 높을수록 키워드들이 밀 Word Cloud 시각화는 사용 시나리\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "\n",
    "# PDF 문서 로더 인스턴스 생성\n",
    "loader = PDFPlumberLoader(\"유튜브 기반 사용자 콘텐츠에서의 리뷰 이상 탐지.pdf\")\n",
    "\n",
    "# 문서 로딩\n",
    "docs = loader.load()\n",
    "print(\"총\", len(docs), \"페이지 로드됨\")\n",
    "\n",
    "# 첫 번째 문서 데이터 접근\n",
    "print(docs[10].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9d24e8-0713-432c-a1c1-b5356db91973",
   "metadata": {},
   "source": [
    "#### (5) PyPDFium2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d25aece7-2d13-4f42-888f-81d29416b468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 16 페이지 로드됨\n",
      "유튜브 기반 사용자 콘텐츠에서의 리뷰 이상 탐지 57\n",
      "추출된 토픽 주제의 해석력을 높이기 위해, \n",
      "본 연구는 동시출현 점수(co-occurrence score)를 \n",
      "계산하여 각 토픽의 의미적 일관성을 평가하였\n",
      "다. 이 점수는 특정 주제 내에서 키워드들이 동\n",
      "일한 문서 내에 얼마나 자주 함께 등장하는지를 \n",
      "수치화한 것으로, 주제어 간의 상호 연관성을 \n",
      "측정하는 지표로 활용된다. 수치화한 것으로, 주\n",
      "제어 간의 상호 연관성을 측정하는 지표로 활용\n",
      "된다. 동시출현 점수가 높을수록 키워드들이 밀\n",
      "접하게 연결되어 있는 일관된 주제를 형성하며, \n",
      "예를 들어 ‘호텔 시설’, ‘청결’, ‘침대’, ‘조식’ 등\n",
      "이 함께 자주 등장하는 경우, 해당 리뷰는 특정 \n",
      "호텔의 물리적 조건에 집중된 논의임을 시사한\n",
      "다. 반면, 동시출현 점수가 낮은 토픽은 단어 간 \n",
      "맥락적 연결성이 약하거나, 리뷰 작성자들이 다\n",
      "양한 맥락에서 단어를 더 자유롭게 사용하는 경\n",
      "향이 있음을 나타낸다. 이는 주제가 분산되어 \n",
      "있거나\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFium2Loader\n",
    "\n",
    "# PyPDFium2 로더 인스턴스 생성\n",
    "loader = PyPDFium2Loader(\"유튜브 기반 사용자 콘텐츠에서의 리뷰 이상 탐지.pdf\")\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "print(\"총\", len(docs), \"페이지 로드됨\")\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[10].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8cb2e9-25a1-4cd3-8685-1a21a8b4157f",
   "metadata": {},
   "source": [
    "### [4] CSVLoader 와 DataFrameLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e796e61-1777-4aa8-87dc-3e2223b4c38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n",
      "{'source': 'WHO_first9cols.csv', 'row': 0}\n",
      "page_content='Country: Afghanistan\n",
      "CountryID: 1\n",
      "Continent: 1\n",
      "Adolescent fertility rate (%): 151\n",
      "Adult literacy rate (%): 28\n",
      "Gross national income per capita (PPP international $): \n",
      "Net primary school enrolment ratio female (%): \n",
      "Net primary school enrolment ratio male (%): \n",
      "Population (in thousands) total: 26088' metadata={'source': 'WHO_first9cols.csv', 'row': 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "# CSV 로더 생성\n",
    "loader = CSVLoader(file_path= \"WHO_first9cols.csv\")\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))\n",
    "print(docs[0].metadata)\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c7a9a3e-2260-4409-980c-6f9a296d0a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>CountryID</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Adolescent fertility rate (%)</th>\n",
       "      <th>Adult literacy rate (%)</th>\n",
       "      <th>Gross national income per capita (PPP international $)</th>\n",
       "      <th>Net primary school enrolment ratio female (%)</th>\n",
       "      <th>Net primary school enrolment ratio male (%)</th>\n",
       "      <th>Population (in thousands) total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>151.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>98.7</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>3172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>69.9</td>\n",
       "      <td>5940.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>33351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>146.0</td>\n",
       "      <td>67.4</td>\n",
       "      <td>3890.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>16557.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>198</td>\n",
       "      <td>6</td>\n",
       "      <td>25.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>86206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>West Bank and Gaza</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>83.0</td>\n",
       "      <td>54.1</td>\n",
       "      <td>2090.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>21732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>201</td>\n",
       "      <td>3</td>\n",
       "      <td>161.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>11696.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>202</td>\n",
       "      <td>3</td>\n",
       "      <td>101.0</td>\n",
       "      <td>89.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>13228.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Country  CountryID  Continent  Adolescent fertility rate (%)  \\\n",
       "0           Afghanistan          1          1                          151.0   \n",
       "1               Albania          2          2                           27.0   \n",
       "2               Algeria          3          3                            6.0   \n",
       "3               Andorra          4          2                            NaN   \n",
       "4                Angola          5          3                          146.0   \n",
       "..                  ...        ...        ...                            ...   \n",
       "197             Vietnam        198          6                           25.0   \n",
       "198  West Bank and Gaza        199          1                            NaN   \n",
       "199               Yemen        200          1                           83.0   \n",
       "200              Zambia        201          3                          161.0   \n",
       "201            Zimbabwe        202          3                          101.0   \n",
       "\n",
       "     Adult literacy rate (%)  \\\n",
       "0                       28.0   \n",
       "1                       98.7   \n",
       "2                       69.9   \n",
       "3                        NaN   \n",
       "4                       67.4   \n",
       "..                       ...   \n",
       "197                     90.3   \n",
       "198                      NaN   \n",
       "199                     54.1   \n",
       "200                     68.0   \n",
       "201                     89.5   \n",
       "\n",
       "     Gross national income per capita (PPP international $)  \\\n",
       "0                                                  NaN        \n",
       "1                                               6000.0        \n",
       "2                                               5940.0        \n",
       "3                                                  NaN        \n",
       "4                                               3890.0        \n",
       "..                                                 ...        \n",
       "197                                             2310.0        \n",
       "198                                                NaN        \n",
       "199                                             2090.0        \n",
       "200                                             1140.0        \n",
       "201                                                NaN        \n",
       "\n",
       "     Net primary school enrolment ratio female (%)  \\\n",
       "0                                              NaN   \n",
       "1                                             93.0   \n",
       "2                                             94.0   \n",
       "3                                             83.0   \n",
       "4                                             49.0   \n",
       "..                                             ...   \n",
       "197                                           91.0   \n",
       "198                                            NaN   \n",
       "199                                           65.0   \n",
       "200                                           94.0   \n",
       "201                                           88.0   \n",
       "\n",
       "     Net primary school enrolment ratio male (%)  \\\n",
       "0                                            NaN   \n",
       "1                                           94.0   \n",
       "2                                           96.0   \n",
       "3                                           83.0   \n",
       "4                                           51.0   \n",
       "..                                           ...   \n",
       "197                                         96.0   \n",
       "198                                          NaN   \n",
       "199                                         85.0   \n",
       "200                                         90.0   \n",
       "201                                         87.0   \n",
       "\n",
       "     Population (in thousands) total  \n",
       "0                            26088.0  \n",
       "1                             3172.0  \n",
       "2                            33351.0  \n",
       "3                               74.0  \n",
       "4                            16557.0  \n",
       "..                               ...  \n",
       "197                          86206.0  \n",
       "198                              NaN  \n",
       "199                          21732.0  \n",
       "200                          11696.0  \n",
       "201                          13228.0  \n",
       "\n",
       "[202 rows x 9 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv(\"WHO_first9cols.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68ecaec5-6bf2-4b50-9203-546642215e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afghanistan\n",
      "{'CountryID': 1, 'Continent': 1, 'Adolescent fertility rate (%)': 151.0, 'Adult literacy rate (%)': 28.0, 'Gross national income per capita (PPP international $)': nan, 'Net primary school enrolment ratio female (%)': nan, 'Net primary school enrolment ratio male (%)': nan, 'Population (in thousands) total': 26088.0}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "\n",
    "# 데이터 프레임 로더 설정, 페이지 내용 컬럼 지정\n",
    "loader = DataFrameLoader(df, page_content_column=\"Country\")\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 데이터 출력\n",
    "print(docs[0].page_content)\n",
    "\n",
    "# 메타데이터 출력\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501cdeb7-5dfe-44ae-a1a4-e01ceed79e85",
   "metadata": {},
   "source": [
    "### [5] JSONLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b08b623-2222-4c92-bc6f-9159be795be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing employee.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile employee.json\n",
    "[\n",
    "    {\n",
    "        \"name\": \"홍길동\",\n",
    "        \"age\": 30,\n",
    "        \"address\": \"서울특별시 강남구\",\n",
    "        \"phoneNumbers\": [\n",
    "            {\n",
    "                \"type\": \"mobile\",\n",
    "                \"number\": \"010-1234-5678\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"home\",\n",
    "                \"number\": \"02-987-6543\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"김철수\",\n",
    "        \"age\": 25,\n",
    "        \"address\": \"부산광역시 해운대구\",\n",
    "        \"phoneNumbers\": [\n",
    "            {\n",
    "                \"type\": \"mobile\",\n",
    "                \"number\": \"010-1111-2222\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"이영희\",\n",
    "        \"age\": 28,\n",
    "        \"address\": \"대구광역시 수성구\",\n",
    "        \"phoneNumbers\": [\n",
    "            {\n",
    "                \"type\": \"mobile\",\n",
    "                \"number\": \"010-3333-4444\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"work\",\n",
    "                \"number\": \"053-555-6666\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97f38eb9-1b17-4989-9a82-aa72d9f6c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb6c4752-836d-409c-9249-f7f0a08b08b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\storm\\\\바탕 화면\\\\AI_Agent_Lab_PM\\\\04_LangChain 기본\\\\employee.json', 'seq_num': 1}, page_content='[{\"type\": \"mobile\", \"number\": \"010-1234-5678\"}, {\"type\": \"home\", \"number\": \"02-987-6543\"}]'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\storm\\\\바탕 화면\\\\AI_Agent_Lab_PM\\\\04_LangChain 기본\\\\employee.json', 'seq_num': 2}, page_content='[{\"type\": \"mobile\", \"number\": \"010-1111-2222\"}]'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\storm\\\\바탕 화면\\\\AI_Agent_Lab_PM\\\\04_LangChain 기본\\\\employee.json', 'seq_num': 3}, page_content='[{\"type\": \"mobile\", \"number\": \"010-3333-4444\"}, {\"type\": \"work\", \"number\": \"053-555-6666\"}]')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "# JSONLoader 생성\n",
    "loader = JSONLoader(\n",
    "    file_path=\"employee.json\",\n",
    "    jq_schema=\".[].phoneNumbers\",\n",
    "    text_content=False,\n",
    ")\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 결과 출력\n",
    "docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644c727b-314e-47a6-a835-547b19fa0bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
