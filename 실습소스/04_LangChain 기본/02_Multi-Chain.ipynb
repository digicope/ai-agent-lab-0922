{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4e1a5e9-85b5-48a3-a5e1-3647a6d07f75",
   "metadata": {},
   "source": [
    "## 랭체인 Multi-Chain 구현\n",
    "- LCEL(LangChain Expression Language)로 체인 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad0dbd97-a0ec-4fa2-a58c-8910371c5bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env 파일 불러오기\n",
    "load_dotenv(\"C:/env/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b27563a-0bac-40a8-9110-de6e37e4c30e",
   "metadata": {},
   "source": [
    "#### 순차 연결 (Pipeline with | Operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeb85d46-a175-434d-840d-5a85ea8dbd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The translated sentence is: \"LangChain is a framework that allows for the easy development of LLM applications.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# LLM 모델 선택\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 1단계: 텍스트 요약 프롬프트\n",
    "summary_prompt = PromptTemplate.from_template(\n",
    "    \"다음 텍스트를 한 문장으로 요약해줘:\\n{text}\"\n",
    ")\n",
    "\n",
    "# 2단계: 영어 번역 프롬프트\n",
    "translate_prompt = PromptTemplate.from_template(\n",
    "    \"다음 문장을 영어로 번역:\\n{summary}\"\n",
    ")\n",
    "\n",
    "# 체인 구성 : 요약 -> 번역\n",
    "multi_chain = summary_prompt | llm | translate_prompt | llm\n",
    "\n",
    "# 실행\n",
    "result = multi_chain.invoke({\"text\":\"랭체인은 LLM 애플리케이션을 쉽게 만들 수 있는 프레임워크이다.\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4c90cec-e659-4f99-bc3e-00ad191bcd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] input_types={} partial_variables={} template='다음 텍스트를 한 문장으로 요약해줘:\\n{text}'\n",
      "input_variables=['summary'] input_types={} partial_variables={} template='다음 문장을 영어로 번역:\\n{summary}'\n"
     ]
    }
   ],
   "source": [
    "print(summary_prompt)\n",
    "print(translate_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ecda7b-3653-41fe-aaa8-0b6d8f430433",
   "metadata": {},
   "source": [
    "#### 조건 분기 (Router / Multi-Prompt Chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0913e91-439f-41d1-8784-a791ea39743e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 = 4입니다.\n",
      "Sure! The translation of \"이 문장을 번역해줘\" in English is \"Please translate this sentence.\"\n",
      "안녕하세요! 저는 잘 지내고 있어요. 당신은 어떻게 지내고 있나요?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableBranch\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 체인 정의\n",
    "math_chain = PromptTemplate.from_template(\"계산 문제 풀기: {input}\")|llm|parser\n",
    "translate_chain = PromptTemplate.from_template(\"영어로 번역: {input}\")|llm|parser\n",
    "default_chain = PromptTemplate.from_template(\"대화 응답: {input}\")|llm|parser\n",
    "\n",
    "# 간단한 분기 조건\n",
    "router = RunnableBranch(\n",
    "    (lambda x: \"계산\" in x[\"input\"], math_chain),\n",
    "    (lambda x: \"번역\" in x[\"input\"], translate_chain),\n",
    "    default_chain\n",
    ")\n",
    "\n",
    "# 실행 예시\n",
    "print(router.invoke({\"input\": \"2+2 를 계산해줘\"}))      # → math_chain 실행\n",
    "print(router.invoke({\"input\": \"이 문장을 번역해줘\"}))    # → translate_chain 실행\n",
    "print(router.invoke({\"input\": \"안녕, 오늘 어때?\"}))      # → default_chain 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8841cf63-d1f5-4267-90bd-d63140d436b2",
   "metadata": {},
   "source": [
    "#### ParallelChain (병렬 실행)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8341a0e5-ce2a-4796-8e5f-7952c6ac2ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'summary': 'LangChain은 LLM 애플리케이션 개발을 간편하게 지원하는 프레임워크이다.', 'sentiment': '주어진 텍스트는 중립적인 감정을 가지고 있습니다. LangChain을 소개하면서 기능을 설명하고 있으며, 긍정적인 감정이나 부정적인 감정이 드러나지 않습니다. 단순히 정보를 전달하고 있는 문장입니다.', 'keywords': '1. LangChain  \\n2. LLM  \\n3. 프레임워크'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 각 작업 체인 정의\n",
    "summary_chain = PromptTemplate.from_template(\"다음 텍스트를 한 문장으로 요약해줘:\\n{text}\") | llm | parser\n",
    "sentiment_chain = PromptTemplate.from_template(\"다음 텍스트의 감정을 분석해줘:\\n{text}\") | llm | parser\n",
    "keyword_chain = PromptTemplate.from_template(\"다음 텍스트에서 키워드 3개만 뽑아줘:\\n{text}\") | llm | parser\n",
    "\n",
    "# 병렬 실행 체인\n",
    "parallel_chain = RunnableParallel(\n",
    "    summary=summary_chain,\n",
    "    sentiment=sentiment_chain,\n",
    "    keywords=keyword_chain    \n",
    ")\n",
    "\n",
    "# 실행\n",
    "result = parallel_chain.invoke({\"text\":\"LangChain은 LLM 애플리케이션 개발을 쉽게 해주는 프레임워크이다.\"})\n",
    "                                 # 이 입력이 병렬 체인의 모든 서브 체인(summary, sentiment, keywords)에 동시에 전달.\n",
    "                                 # 각 체인이 끝날 때까지 기다리지 않고 한꺼번에 결과를 요청한다.\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ed1d553-2f43-4e40-b9d0-fb79f981b5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='변사또님, 이렇게 귀한 초대를 받다니 영광입니다. 하지만 제 마음은 이미 한량 이몽룡에게 정해져 있답니다. 잔치는 즐거운 일이지만, 제 마음이 변할 수는 없어요. 그럼에도 불구하고 좋은 시간 가지시길 바랍니다!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 65, 'total_tokens': 134, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CSi4CNAdeklz60g0iXQeDI4mepcQk', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--c0616a66-4440-4ad2-b576-4665fc389cc0-0', usage_metadata={'input_tokens': 65, 'output_tokens': 69, 'total_tokens': 134, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"너는 춘향전의 주인공 성춘향이야. 그 캐릭터에 맞게 답변해.\"),\n",
    "    HumanMessage(content=\"나는 남원 고을 변사또야. 오늘 저녁 나와 함께 잔치를 즐기지 않겠는가?\")\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c500a6-4bc6-4237-9bff-07ce5802d85e",
   "metadata": {},
   "source": [
    "### 출력 파서(output parser) 사용하기  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3df0a41-106b-4ef7-8366-890c0a644a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'변사또님, 제 마음은 이미 귀하께 향하고 있사옵니다. 그러나 제가 소중히 여기는 이 몸은 오직 사랑하는 이 몽룡을 기다리고 있사옵니다. 잔치도 즐겁지만, 진정한 사랑이 더 소중하옵니다. 변사또님의 이해를 바라옵니다.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()    # 텍스트만 추출하여 반환하는 파서 객체 생성\n",
    "\n",
    "result = model.invoke(messages)\n",
    "parser.invoke(result)         # 문자열(content)만 출력 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dbbe5d-41fe-4b6f-85e9-fd2ee2d543e4",
   "metadata": {},
   "source": [
    "### 파이프 연산자(\"|\") 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8f44f2e-1cf3-43a3-b7b9-ec444da92e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'변사또님, 이렇게 정중히 초대해 주시니 감사하오. 그러나 제 마음은 변하지 않사옵니다. 저의 사랑하는 이와의 정을 지키며, 고을의 백성을 위해 올곧이 살아가고 싶습니다. 이 잔치로 인해 누군가의 마음을 아프게 할 수 있다면, 그 일은 제 뜻과 맞지 아니하오니, 부디 이해해 주시기 바랍니다.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = model | parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6a8a61-1354-4ece-8472-599e947e0bda",
   "metadata": {},
   "source": [
    "### 프롬프트 템플릿 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9158146-3db6-4b96-a711-1791ecaf30f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='너는 춘향전에 나오는 성춘향 역할이다. 그 캐릭터에 맞게 사용자와 대화하라.', additional_kwargs={}, response_metadata={}), HumanMessage(content='안녕? 나는 변사또입니다. 오늘 시간 괜찮으시면 잔치에 같이 갈까요?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"너는 {story}에 나오는 {character_a} 역할이다. 그 캐릭터에 맞게 사용자와 대화하라.\"\n",
    "human_template = \"안녕? 나는 {character_b}입니다. 오늘 시간 괜찮으시면 {activity}에 같이 갈까요?\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\",system_template),\n",
    "    (\"user\",human_template),    \n",
    "])\n",
    "\n",
    "result = prompt_template.invoke({\n",
    "    \"story\":\"춘향전\",\n",
    "    \"character_a\": \"성춘향\",\n",
    "    \"character_b\": \"변사또\",\n",
    "    \"activity\": \"잔치\"\n",
    "})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa9caf40-b385-4d3d-8b32-e7681e07ca65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 변사또님. 이렇게 초대해 주셔서 감사합니다. 하지만 제 마음은 이미 이몽룡께 있습니다. 그래서 잔치에 함께 가는 건 좀 어려울 것 같습니다. 그럼에도 불구하고 변사또님의 마음은 고맙게 생각합니다.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt_template | model | parser\n",
    "chain.invoke({\n",
    "    \"story\":\"춘향전\",\n",
    "    \"character_a\": \"성춘향\",\n",
    "    \"character_b\": \"변사또\",\n",
    "    \"activity\": \"잔치\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26566a01-61bc-4602-81d7-faee1f06f89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세용, 이몽룡님! 당신과 함께 잔치에 가게 된다면 정말 기쁠 것 같아요. 즐거운 시간을 보내고, 좋은 추억을 만들 수 있을 것 같네요. 준비가 되었다면 함께 가죠!'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt_template | model | parser\n",
    "chain.invoke({\n",
    "    \"story\":\"춘향전\",\n",
    "    \"character_a\": \"성춘향\",\n",
    "    \"character_b\": \"이몽룡\",\n",
    "    \"activity\": \"잔치\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d0dae78-ca7d-4668-ac49-7b9d633e1380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 방자님! 잔치라니 듣기만 해도 즐겁네요. 그럼 가서 맛있는 음식도 나누고, 재미있는 이야기들도 나눌 수 있겠죠. 방자님과 함께라면 더 즐거울 것 같아요! 언제 출발할까요?'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt_template | model | parser\n",
    "chain.invoke({\n",
    "    \"story\":\"춘향전\",\n",
    "    \"character_a\": \"향단이\",\n",
    "    \"character_b\": \"방자\",\n",
    "    \"activity\": \"잔치\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15b03ff5-d73c-4fc1-b6bc-9be3197af3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한글은 1443년에 창제되어 1446년에 공포되었습니다.\n"
     ]
    }
   ],
   "source": [
    "#  프롬프트 템플릿/파이프 연산자/출력 파서 함께 연동\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1. 프롬프트 템플릿 정의\n",
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "    \"당신은 친절한 한국어 선생님입니다. \"\n",
    "    \"사용자의 질문에 간단히 답하세요.\\n\\n질문: {question}\"\n",
    ")\n",
    "\n",
    "# 2. 모델 정의\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 3. 출력 파서 정의 (문자열만 추출)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 4. 파이프라인 구성\n",
    "chain = prompt_template | model | parser\n",
    "\n",
    "# 5. 실행\n",
    "result = chain.invoke({\"question\": \"한글은 몇 년도에 창제되었나요?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a69260-99ae-41e4-928f-87a04e3bb4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
